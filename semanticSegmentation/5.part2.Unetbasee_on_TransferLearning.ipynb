{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is part 2 for this competitions submit  \n",
    "U-net base on ResNet34 transfer learning  \n",
    "This kernel use Unet Base on ResNet34 model  \n",
    "For pre data process and data augumatation reference by Kevin's kernel  \n",
    "Use bce_log+dice_loss for ResNet34+Unet loss function  \n",
    "ResNet34+ Unet model reference by this GITHUB  \n",
    "Part1 - Simple tansfer learning to detect ship exist  \n",
    "https://www.kaggle.com/super13579/simple-transfer-learning-detect-ship-exist-keras  \n",
    "Part3 - Submittion result with predict ship + Unet34 (0.628)  \n",
    "https://www.kaggle.com/super13579/unet34-predict-result  \n",
    "\n",
    "\n",
    "https://www.kaggle.com/super13579/u-net-base-on-resnet34-transfer-learning-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231723 masks found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  0001124c7.jpg                                                NaN\n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "#from skimage.util.montage import montage2d as montage\n",
    "path = \"/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship Detection Challenge/\"\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "\n",
    "train = pd.read_csv(os.path.join(path + 'train_ship_segmentations_v2.csv'))\n",
    "\n",
    "print(train.shape[0],'masks found')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Parameters\n",
    "We might want to adjust these later (or do some hyperparameter optimizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "EDGE_CROP = 16\n",
    "NB_EPOCHS = 5\n",
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# downsampling inside the network\n",
    "NET_SCALING = None\n",
    "# downsampling in preprocessing\n",
    "IMG_SCALING = (1, 1)\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 400\n",
    "# maximum number of steps_per_epoch in training\n",
    "MAX_TRAIN_STEPS = 200\n",
    "AUGMENT_BRIGHTNESS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import montage2d as montage\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ship_dir = path \n",
    "train_image_dir = os.path.join(ship_dir, 'train_v2')\n",
    "test_image_dir = os.path.join(ship_dir, 'test_v2')\n",
    "import gc; gc.enable() # memory is tight\n",
    "\n",
    "from skimage.morphology import label\n",
    "def multi_rle_encode(img):\n",
    "    labels = label(img[:, :, 0])\n",
    "    return [rle_encode(labels==k) for k in np.unique(labels[labels>0])]\n",
    "\n",
    "# ref: https://www.kaggle.com/paulorzp/run-length-encode-and-decode\n",
    "def rle_encode(img):\n",
    "    '''\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = img.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(768, 768)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T  # Needed to align to RLE direction\n",
    "\n",
    "def masks_as_image(in_mask_list):\n",
    "    # Take the individual ship masks and create a single mask array for all ships\n",
    "    all_masks = np.zeros((768, 768), dtype = np.int16)\n",
    "    #if isinstance(in_mask_list, list):\n",
    "    for mask in in_mask_list:\n",
    "        if isinstance(mask, str):\n",
    "            all_masks += rle_decode(mask)\n",
    "    return np.expand_dims(all_masks, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231723 masks found\n",
      "192556\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  0001124c7.jpg                                                NaN\n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks = pd.read_csv(os.path.join(path,\n",
    "                                 'train_ship_segmentations_v2.csv'))\n",
    "print(masks.shape[0], 'masks found')\n",
    "print(masks['ImageId'].value_counts().shape[0])\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training and validation groups\n",
    "\n",
    "We stratify by the number of boats appearing so we have nice balances in each set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>has_ship_vec</th>\n",
       "      <th>file_size_kb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104934</th>\n",
       "      <td>8b912b47d.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>103.580078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110164</th>\n",
       "      <td>9271eb839.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>110.807617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89494</th>\n",
       "      <td>76d311f7f.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>122.270508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69041</th>\n",
       "      <td>5bd3b8058.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>113.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95955</th>\n",
       "      <td>7f9ae4d3d.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>219.289062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ImageId  ships  has_ship has_ship_vec  file_size_kb\n",
       "104934  8b912b47d.jpg      0       0.0        [0.0]    103.580078\n",
       "110164  9271eb839.jpg      0       0.0        [0.0]    110.807617\n",
       "89494   76d311f7f.jpg      1       1.0        [1.0]    122.270508\n",
       "69041   5bd3b8058.jpg      0       0.0        [0.0]    113.281250\n",
       "95955   7f9ae4d3d.jpg      0       0.0        [0.0]    219.289062"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "# some files are too small/corrupt\n",
    "unique_img_ids['file_size_kb'] = unique_img_ids['ImageId'].map(lambda c_img_id: \n",
    "                                                               os.stat(os.path.join(train_image_dir, \n",
    "                                                                                    c_img_id)).st_size/1024)\n",
    "unique_img_ids = unique_img_ids[unique_img_ids['file_size_kb']>50] # keep only 50kb files\n",
    "unique_img_ids['file_size_kb'].hist()\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "unique_img_ids.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161048 training masks\n",
      "69034 validation masks\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.3, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersample Empty Images¶\n",
    "Here we undersample the empty images to get a better balanced group with more ships to try and segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f8548f8ce10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['grouped_ship_count'] = train_df['ships'].map(lambda x: (x+1)//2).clip(0, 7)\n",
    "def sample_ships(in_df, base_rep_val=1500):\n",
    "    if in_df['ships'].values[0]==0:\n",
    "        return in_df.sample(base_rep_val//3) # even more strongly undersample no ships\n",
    "    else:\n",
    "        return in_df.sample(base_rep_val, replace=(in_df.shape[0]<base_rep_val))\n",
    "    \n",
    "balanced_train_df = train_df.groupby('grouped_ship_count').apply(sample_ships)\n",
    "balanced_train_df['ships'].hist(bins=np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_train_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decode all the RLEs into Images\n",
    "We make a generator to produce batches of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_image_gen(in_df, batch_size = BATCH_SIZE):\n",
    "    all_batches = list(in_df.groupby('ImageId'))\n",
    "    out_rgb = []\n",
    "    out_mask = []\n",
    "    while True:\n",
    "        np.random.shuffle(all_batches)\n",
    "        for c_img_id, c_masks in all_batches:\n",
    "            rgb_path = os.path.join(train_image_dir, c_img_id)\n",
    "            c_img = imread(rgb_path)\n",
    "            c_mask = masks_as_image(c_masks['EncodedPixels'].values)\n",
    "            if IMG_SCALING is not None:\n",
    "                c_img = c_img[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "                c_mask = c_mask[::IMG_SCALING[0], ::IMG_SCALING[1]]\n",
    "            out_rgb += [c_img]\n",
    "            out_mask += [c_mask]\n",
    "            if len(out_rgb)>=batch_size:\n",
    "                yield np.stack(out_rgb, 0)/255.0, np.stack(out_mask, 0)\n",
    "                out_rgb, out_mask=[], []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the Validation Set¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 768, 768, 3) (400, 768, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "valid_x, valid_y = next(make_image_gen(valid_df, VALID_IMG_COUNT))\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 15, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last')\n",
    "# brightness can be problematic since it seems to change the labels differently from the images \n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args[' brightness_range'] = [0.5, 1.5]\n",
    "image_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "if AUGMENT_BRIGHTNESS:\n",
    "    dg_args.pop('brightness_range')\n",
    "label_gen = ImageDataGenerator(**dg_args)\n",
    "\n",
    "def create_aug_gen(in_gen, seed = None):\n",
    "    np.random.seed(seed if seed is not None else np.random.choice(range(9999)))\n",
    "    for in_x, in_y in in_gen:\n",
    "        seed = np.random.choice(range(9999))\n",
    "        # keep the seeds syncronized otherwise the augmentation to the images is different from the masks\n",
    "        g_x = image_gen.flow(255*in_x, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "        g_y = label_gen.flow(in_y, \n",
    "                             batch_size = in_x.shape[0], \n",
    "                             seed = seed, \n",
    "                             shuffle=True)\n",
    "\n",
    "        yield next(g_x)/255.0, next(g_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build ResNet34+ Unet Model¶\n",
    "Here we use a slight deviation on the U-Net standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import six\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout,BatchNormalization\n",
    "from keras.layers import Conv2D, Concatenate, MaxPooling2D\n",
    "from keras.layers import UpSampling2D, Dropout, BatchNormalization\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import initializers\n",
    "from keras import regularizers\n",
    "from keras import constraints\n",
    "from keras.utils import conv_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.engine import InputSpec\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.engine.topology import Input\n",
    "from keras.engine.training import Model\n",
    "from keras.layers.convolutional import Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.core import Activation, SpatialDropout2D\n",
    "from keras.layers.merge import concatenate,add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Upsample layer¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import UpSampling2D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "\n",
    "def handle_block_names_decode(stage):\n",
    "    conv_name = 'decoder_stage{}_conv'.format(stage)\n",
    "    bn_name = 'decoder_stage{}_bn'.format(stage)\n",
    "    relu_name = 'decoder_stage{}_relu'.format(stage)\n",
    "    up_name = 'decoder_stage{}_upsample'.format(stage)\n",
    "    return conv_name, bn_name, relu_name, up_name\n",
    "\n",
    "\n",
    "def Upsample2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n",
    "                     batchnorm=False, skip=None):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "\n",
    "        conv_name, bn_name, relu_name, up_name = handle_block_names_decode(stage)\n",
    "\n",
    "        x = UpSampling2D(size=upsample_rate, name=up_name)(input_tensor)\n",
    "\n",
    "        if skip is not None:\n",
    "            x = Concatenate()([x, skip])\n",
    "\n",
    "        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'1')(x)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'1')(x)\n",
    "        x = Activation('relu', name=relu_name+'1')(x)\n",
    "\n",
    "        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'2')(x)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'2')(x)\n",
    "        x = Activation('relu', name=relu_name+'2')(x)\n",
    "\n",
    "        return x\n",
    "    return layer\n",
    "\n",
    "\n",
    "def Transpose2D_block(filters, stage, kernel_size=(3,3), upsample_rate=(2,2),\n",
    "                      transpose_kernel_size=(4,4), batchnorm=False, skip=None):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "\n",
    "        conv_name, bn_name, relu_name, up_name = handle_block_names_decode(stage)\n",
    "\n",
    "        x = Conv2DTranspose(filters, transpose_kernel_size, strides=upsample_rate,\n",
    "                            padding='same', name=up_name)(input_tensor)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'1')(x)\n",
    "        x = Activation('relu', name=relu_name+'1')(x)\n",
    "\n",
    "        if skip is not None:\n",
    "            x = Concatenate()([x, skip])\n",
    "\n",
    "        x = Conv2D(filters, kernel_size, padding='same', name=conv_name+'2')(x)\n",
    "        if batchnorm:\n",
    "            x = BatchNormalization(name=bn_name+'2')(x)\n",
    "        x = Activation('relu', name=relu_name+'2')(x)\n",
    "\n",
    "        return x\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Unet model (Decoder)¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(backbone, classes, last_block_filters, skip_layers,\n",
    "               n_upsample_blocks=5, upsample_rates=(2,2,2,2,2),\n",
    "               block_type='upsampling', activation='sigmoid',\n",
    "               **kwargs):\n",
    "\n",
    "    input = backbone.input\n",
    "    x = backbone.output\n",
    "    print(x)\n",
    "    if block_type == 'transpose':\n",
    "        up_block = Transpose2D_block\n",
    "    else:\n",
    "        up_block = Upsample2D_block\n",
    "\n",
    "    # convert layer names to indices\n",
    "    skip_layers = ([get_layer_number(backbone, l) if isinstance(l, str) else l\n",
    "                    for l in skip_layers])\n",
    "    for i in range(n_upsample_blocks):\n",
    "\n",
    "        # check if there is a skip connection\n",
    "        if i < len(skip_layers):\n",
    "            print(backbone.layers[skip_layers[i]])\n",
    "            print(backbone.layers[skip_layers[i]].output)\n",
    "            skip = backbone.layers[skip_layers[i]].output\n",
    "        else:\n",
    "            skip = None\n",
    "\n",
    "        up_size = (upsample_rates[i], upsample_rates[i])\n",
    "        filters = last_block_filters * 2**(n_upsample_blocks-(i+1))\n",
    "\n",
    "        x = up_block(filters, i, upsample_rate=up_size, skip=skip, **kwargs)(x)\n",
    "\n",
    "    if classes < 2:\n",
    "        activation = 'sigmoid'\n",
    "\n",
    "    x = Conv2D(classes, (3,3), padding='same', name='final_conv')(x)\n",
    "    x = Activation(activation, name=activation)(x)\n",
    "\n",
    "    model = Model(input, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built ResNet34 model¶\n",
    "Reference this github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Add\n",
    "from keras.layers import ZeroPadding2D\n",
    "\n",
    "def handle_block_names(stage, block):\n",
    "    name_base = 'stage{}_unit{}_'.format(stage + 1, block + 1)\n",
    "    conv_name = name_base + 'conv'\n",
    "    bn_name = name_base + 'bn'\n",
    "    relu_name = name_base + 'relu'\n",
    "    sc_name = name_base + 'sc'\n",
    "    return conv_name, bn_name, relu_name, sc_name\n",
    "\n",
    "\n",
    "def basic_identity_block(filters, stage, block):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        conv_params = get_conv_params()\n",
    "        bn_params = get_bn_params()\n",
    "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
    "        x = Activation('relu', name=relu_name + '1')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), name=conv_name + '1', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '2')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
    "\n",
    "        x = Add()([x, input_tensor])\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def basic_conv_block(filters, stage, block, strides=(2, 2)):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        conv_params = get_conv_params()\n",
    "        bn_params = get_bn_params()\n",
    "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
    "        x = Activation('relu', name=relu_name + '1')(x)\n",
    "        shortcut = x\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '1', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '2')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
    "\n",
    "        shortcut = Conv2D(filters, (1, 1), name=sc_name, strides=strides, **conv_params)(shortcut)\n",
    "        x = Add()([x, shortcut])\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def conv_block(filters, stage, block, strides=(2, 2)):\n",
    "    def layer(input_tensor):\n",
    "        conv_params = get_conv_params()\n",
    "        bn_params = get_bn_params()\n",
    "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
    "        x = Activation('relu', name=relu_name + '1')(x)\n",
    "        shortcut = x\n",
    "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '2')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), strides=strides, name=conv_name + '2', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '3')(x)\n",
    "        x = Conv2D(filters*4, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
    "\n",
    "        shortcut = Conv2D(filters*4, (1, 1), name=sc_name, strides=strides, **conv_params)(shortcut)\n",
    "        x = Add()([x, shortcut])\n",
    "        return x\n",
    "\n",
    "    return layer\n",
    "\n",
    "\n",
    "def identity_block(filters, stage, block):\n",
    "\n",
    "    def layer(input_tensor):\n",
    "        conv_params = get_conv_params()\n",
    "        bn_params = get_bn_params()\n",
    "        conv_name, bn_name, relu_name, sc_name = handle_block_names(stage, block)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '1', **bn_params)(input_tensor)\n",
    "        x = Activation('relu', name=relu_name + '1')(x)\n",
    "        x = Conv2D(filters, (1, 1), name=conv_name + '1', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '2', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '2')(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "        x = Conv2D(filters, (3, 3), name=conv_name + '2', **conv_params)(x)\n",
    "\n",
    "        x = BatchNormalization(name=bn_name + '3', **bn_params)(x)\n",
    "        x = Activation('relu', name=relu_name + '3')(x)\n",
    "        x = Conv2D(filters*4, (1, 1), name=conv_name + '3', **conv_params)(x)\n",
    "\n",
    "        x = Add()([x, input_tensor])\n",
    "        return x\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_params(**params):\n",
    "    default_conv_params = {\n",
    "        'kernel_initializer': 'glorot_uniform',\n",
    "        'use_bias': False,\n",
    "        'padding': 'valid',\n",
    "    }\n",
    "    default_conv_params.update(params)\n",
    "    return default_conv_params\n",
    "\n",
    "\n",
    "def get_bn_params(**params):\n",
    "    default_bn_params = {\n",
    "        'axis': 3,\n",
    "        'momentum': 0.99,\n",
    "        'epsilon': 2e-5,\n",
    "        'center': True,\n",
    "        'scale': True,\n",
    "    }\n",
    "    default_bn_params.update(params)\n",
    "    return default_bn_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Activation\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.engine import get_source_inputs\n",
    "\n",
    "import keras\n",
    "from distutils.version import StrictVersion\n",
    "\n",
    "if StrictVersion(keras.__version__) < StrictVersion('2.2.0'):\n",
    "    from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "else:\n",
    "    from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "    \n",
    "def build_resnet(\n",
    "     repetitions=(2, 2, 2, 2),\n",
    "     include_top=True,\n",
    "     input_tensor=None,\n",
    "     input_shape=None,\n",
    "     classes=1000,\n",
    "     block_type='usual'):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=197,\n",
    "                                      data_format='channels_last',\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape, name='data')\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    \n",
    "    # get parameters for model layers\n",
    "    no_scale_bn_params = get_bn_params(scale=False)\n",
    "    bn_params = get_bn_params()\n",
    "    conv_params = get_conv_params()\n",
    "    init_filters = 64\n",
    "\n",
    "    if block_type == 'basic':\n",
    "        conv_block = basic_conv_block\n",
    "        identity_block = basic_identity_block\n",
    "    else:\n",
    "        conv_block = usual_conv_block\n",
    "        identity_block = usual_identity_block\n",
    "    \n",
    "    # resnet bottom\n",
    "    x = BatchNormalization(name='bn_data', **no_scale_bn_params)(img_input)\n",
    "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
    "    x = Conv2D(init_filters, (7, 7), strides=(2, 2), name='conv0', **conv_params)(x)\n",
    "    x = BatchNormalization(name='bn0', **bn_params)(x)\n",
    "    x = Activation('relu', name='relu0')(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='pooling0')(x)\n",
    "    \n",
    "    # resnet body\n",
    "    for stage, rep in enumerate(repetitions):\n",
    "        for block in range(rep):\n",
    "            \n",
    "            filters = init_filters * (2**stage)\n",
    "            \n",
    "            # first block of first stage without strides because we have maxpooling before\n",
    "            if block == 0 and stage == 0:\n",
    "                x = conv_block(filters, stage, block, strides=(1, 1))(x)\n",
    "                \n",
    "            elif block == 0:\n",
    "                x = conv_block(filters, stage, block, strides=(2, 2))(x)\n",
    "                \n",
    "            else:\n",
    "                x = identity_block(filters, stage, block)(x)\n",
    "                \n",
    "    x = BatchNormalization(name='bn1', **bn_params)(x)\n",
    "    x = Activation('relu', name='relu1')(x)\n",
    "\n",
    "    # resnet top\n",
    "    if include_top:\n",
    "        x = GlobalAveragePooling2D(name='pool1')(x)\n",
    "        x = Dense(classes, name='fc1')(x)\n",
    "        x = Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    # Ensure that the model takes into account any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "        \n",
    "    # Create model.\n",
    "    model = Model(inputs, x)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrain Weight by using ImageNet trained¶\n",
    "Reference this GITHUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import get_file\n",
    "\n",
    "\n",
    "def find_weights(weights_collection, model_name, dataset, include_top):\n",
    "    w = list(filter(lambda x: x['model'] == model_name, weights_collection))\n",
    "    w = list(filter(lambda x: x['dataset'] == dataset, w))\n",
    "    w = list(filter(lambda x: x['include_top'] == include_top, w))\n",
    "    return w\n",
    "\n",
    "\n",
    "def load_model_weights(weights_collection, model, dataset, classes, include_top):\n",
    "    weights = find_weights(weights_collection, model.name, dataset, include_top)\n",
    "\n",
    "    if weights:\n",
    "        weights = weights[0]\n",
    "\n",
    "        if include_top and weights['classes'] != classes:\n",
    "            raise ValueError('If using `weights` and `include_top`'\n",
    "                             ' as true, `classes` should be {}'.format(weights['classes']))\n",
    "\n",
    "        weights_path = get_file(weights['name'],\n",
    "                                weights['url'],\n",
    "                                cache_subdir='models',\n",
    "                                md5_hash=weights['md5'])\n",
    "\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('There is no weights for such configuration: ' +\n",
    "                         'model = {}, dataset = {}, '.format(model.name, dataset) +\n",
    "                         'classes = {}, include_top = {}.'.format(classes, include_top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_collection = [\n",
    "\n",
    "    # ResNet34\n",
    "    {\n",
    "        'model': 'resnet34',\n",
    "        'dataset': 'imagenet',\n",
    "        'classes': 1000,\n",
    "        'include_top': True,\n",
    "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000.h5',\n",
    "        'name': 'resnet34_imagenet_1000.h5',\n",
    "        'md5': '2ac8277412f65e5d047f255bcbd10383',\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'model': 'resnet34',\n",
    "        'dataset': 'imagenet',\n",
    "        'classes': 1000,\n",
    "        'include_top': False,\n",
    "        'url': 'https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5',\n",
    "        'name': 'resnet34_imagenet_1000_no_top.h5',\n",
    "        'md5': '8caaa0ad39d927cb8ba5385bf945d582',\n",
    "    }]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buil Unet model base on ResNet34¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze Encoder weight if needed\n",
    "\n",
    "def freeze_model(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UResNet34(input_shape=(None, None, 3), classes=1, decoder_filters=16, decoder_block_type='upsampling',\n",
    "                       encoder_weights=None, input_tensor=None, activation='sigmoid', **kwargs):\n",
    "\n",
    "    backbone = build_resnet(input_tensor=None,\n",
    "                         input_shape=input_shape,\n",
    "                         repetitions=(3, 4, 6, 3),\n",
    "                         classes=classes,\n",
    "                         include_top=False,\n",
    "                         block_type='basic')\n",
    "    backbone.name = 'resnet34'\n",
    "    \n",
    "    if encoder_weights == True:\n",
    "        load_model_weights(weights_collection, backbone , dataset= 'imagenet', classes = 1, include_top=False)\n",
    "    \n",
    "    skip_connections = list([129, 74, 37, 5]) # for resnet 34\n",
    "    model = build_unet(backbone, classes, decoder_filters,\n",
    "                       skip_connections, block_type=decoder_block_type,\n",
    "                       activation=activation, **kwargs)\n",
    "    model.name = 'u-resnet34'\n",
    "    \n",
    "    #freeze_model(backbone)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"relu1/Relu:0\", shape=(None, 24, 24, 512), dtype=float32)\n",
      "<keras.layers.core.Activation object at 0x7f8534c89e80>\n",
      "Tensor(\"stage4_unit1_relu1/Relu:0\", shape=(None, 48, 48, 256), dtype=float32)\n",
      "<keras.layers.core.Activation object at 0x7f853c57ad30>\n",
      "Tensor(\"stage3_unit1_relu1/Relu:0\", shape=(None, 96, 96, 128), dtype=float32)\n",
      "<keras.layers.core.Activation object at 0x7f85379d8240>\n",
      "Tensor(\"stage2_unit1_relu1/Relu:0\", shape=(None, 192, 192, 64), dtype=float32)\n",
      "<keras.layers.core.Activation object at 0x7f8534e85e80>\n",
      "Tensor(\"relu0/Relu:0\", shape=(None, 384, 384, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "seg_model = UResNet34(input_shape=(768,768,3),encoder_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"u-resnet34\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 768, 768, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 768, 768, 3)  9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 774, 774, 3)  0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 384, 384, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 384, 384, 64) 256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 384, 384, 64) 0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 386, 386, 64) 0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 192, 192, 64) 0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 192, 192, 64) 256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 192, 192, 64) 0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 194, 194, 64) 0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 192, 192, 64) 256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 192, 192, 64) 0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 194, 194, 64) 0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 192, 192, 64) 4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 192, 192, 64) 0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 192, 192, 64) 256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 192, 192, 64) 0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 194, 194, 64) 0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 192, 192, 64) 256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 192, 192, 64) 0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 194, 194, 64) 0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 192, 192, 64) 0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn1 (BatchNormaliz (None, 192, 192, 64) 256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu1 (Activation) (None, 192, 192, 64) 0           stage1_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 194, 194, 64) 0           stage1_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv1 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_bn2 (BatchNormaliz (None, 192, 192, 64) 256         stage1_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_relu2 (Activation) (None, 192, 192, 64) 0           stage1_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 194, 194, 64) 0           stage1_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit3_conv2 (Conv2D)     (None, 192, 192, 64) 36864       zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 192, 192, 64) 0           stage1_unit3_conv2[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 192, 192, 64) 256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 192, 192, 64) 0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 194, 194, 64) 0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 96, 96, 128)  73728       zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 96, 96, 128)  512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 96, 96, 128)  0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 96, 96, 128)  8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 96, 96, 128)  0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 96, 96, 128)  512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 96, 96, 128)  0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 96, 96, 128)  512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 96, 96, 128)  0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 96, 96, 128)  0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn1 (BatchNormaliz (None, 96, 96, 128)  512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu1 (Activation) (None, 96, 96, 128)  0           stage2_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv1 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_bn2 (BatchNormaliz (None, 96, 96, 128)  512         stage2_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_relu2 (Activation) (None, 96, 96, 128)  0           stage2_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit3_conv2 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 96, 96, 128)  0           stage2_unit3_conv2[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn1 (BatchNormaliz (None, 96, 96, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu1 (Activation) (None, 96, 96, 128)  0           stage2_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv1 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_15[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_bn2 (BatchNormaliz (None, 96, 96, 128)  512         stage2_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_relu2 (Activation) (None, 96, 96, 128)  0           stage2_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPadding2 (None, 98, 98, 128)  0           stage2_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit4_conv2 (Conv2D)     (None, 96, 96, 128)  147456      zero_padding2d_16[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 96, 96, 128)  0           stage2_unit4_conv2[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 96, 96, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 96, 96, 128)  0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPadding2 (None, 98, 98, 128)  0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 48, 48, 256)  294912      zero_padding2d_17[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_18[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 48, 48, 256)  32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 48, 48, 256)  0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 48, 48, 256)  0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit3_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 48, 48, 256)  0           stage3_unit3_conv2[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit4_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit4_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit4_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit4_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit4_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit4_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 48, 48, 256)  0           stage3_unit4_conv2[0][0]         \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit5_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit5_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit5_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit5_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit5_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit5_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 48, 48, 256)  0           stage3_unit5_conv2[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu1 (Activation) (None, 48, 48, 256)  0           stage3_unit6_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit6_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv1 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_bn2 (BatchNormaliz (None, 48, 48, 256)  1024        stage3_unit6_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_relu2 (Activation) (None, 48, 48, 256)  0           stage3_unit6_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, 50, 50, 256)  0           stage3_unit6_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit6_conv2 (Conv2D)     (None, 48, 48, 256)  589824      zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 48, 48, 256)  0           stage3_unit6_conv2[0][0]         \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 48, 48, 256)  1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 48, 48, 256)  0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, 50, 50, 256)  0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 24, 24, 512)  1179648     zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 24, 24, 512)  2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 24, 24, 512)  0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 24, 24, 512)  131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 24, 24, 512)  0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 24, 24, 512)  2048        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 24, 24, 512)  0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 24, 24, 512)  2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 24, 24, 512)  0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 24, 24, 512)  0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn1 (BatchNormaliz (None, 24, 24, 512)  2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu1 (Activation) (None, 24, 24, 512)  0           stage4_unit3_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit3_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv1 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_bn2 (BatchNormaliz (None, 24, 24, 512)  2048        stage4_unit3_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_relu2 (Activation) (None, 24, 24, 512)  0           stage4_unit3_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPadding2 (None, 26, 26, 512)  0           stage4_unit3_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit3_conv2 (Conv2D)     (None, 24, 24, 512)  2359296     zero_padding2d_34[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 24, 24, 512)  0           stage4_unit3_conv2[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 24, 24, 512)  2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 24, 24, 512)  0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_upsample (UpSamp (None, 48, 48, 512)  0           relu1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 48, 48, 768)  0           decoder_stage0_upsample[0][0]    \n",
      "                                                                 stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv1 (Conv2D)   (None, 48, 48, 256)  1769728     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu1 (Activatio (None, 48, 48, 256)  0           decoder_stage0_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_conv2 (Conv2D)   (None, 48, 48, 256)  590080      decoder_stage0_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage0_relu2 (Activatio (None, 48, 48, 256)  0           decoder_stage0_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_upsample (UpSamp (None, 96, 96, 256)  0           decoder_stage0_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96, 96, 384)  0           decoder_stage1_upsample[0][0]    \n",
      "                                                                 stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv1 (Conv2D)   (None, 96, 96, 128)  442496      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu1 (Activatio (None, 96, 96, 128)  0           decoder_stage1_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_conv2 (Conv2D)   (None, 96, 96, 128)  147584      decoder_stage1_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage1_relu2 (Activatio (None, 96, 96, 128)  0           decoder_stage1_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_upsample (UpSamp (None, 192, 192, 128 0           decoder_stage1_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 192, 192, 192 0           decoder_stage2_upsample[0][0]    \n",
      "                                                                 stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv1 (Conv2D)   (None, 192, 192, 64) 110656      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu1 (Activatio (None, 192, 192, 64) 0           decoder_stage2_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_conv2 (Conv2D)   (None, 192, 192, 64) 36928       decoder_stage2_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage2_relu2 (Activatio (None, 192, 192, 64) 0           decoder_stage2_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_upsample (UpSamp (None, 384, 384, 64) 0           decoder_stage2_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 384, 384, 128 0           decoder_stage3_upsample[0][0]    \n",
      "                                                                 relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv1 (Conv2D)   (None, 384, 384, 32) 36896       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu1 (Activatio (None, 384, 384, 32) 0           decoder_stage3_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_conv2 (Conv2D)   (None, 384, 384, 32) 9248        decoder_stage3_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage3_relu2 (Activatio (None, 384, 384, 32) 0           decoder_stage3_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_upsample (UpSamp (None, 768, 768, 32) 0           decoder_stage3_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv1 (Conv2D)   (None, 768, 768, 16) 4624        decoder_stage4_upsample[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu1 (Activatio (None, 768, 768, 16) 0           decoder_stage4_conv1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_conv2 (Conv2D)   (None, 768, 768, 16) 2320        decoder_stage4_relu1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "decoder_stage4_relu2 (Activatio (None, 768, 768, 16) 0           decoder_stage4_conv2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "final_conv (Conv2D)             (None, 768, 768, 1)  145         decoder_stage4_relu2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "sigmoid (Activation)            (None, 768, 768, 1)  0           final_conv[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 24,453,178\n",
      "Trainable params: 24,437,812\n",
      "Non-trainable params: 15,366\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seg_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from keras import backend as K\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    y_pred_f = K.cast(K.greater(K.flatten(y_pred), 0.5), 'float32')\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = 2. * K.sum(intersection) / (K.sum(y_true_f) + K.sum(y_pred_f))\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def bce_logdice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - K.log(1. - dice_loss(y_true, y_pred))\n",
    "\n",
    "def weighted_bce_loss(y_true, y_pred, weight):\n",
    "    epsilon = 1e-7\n",
    "    y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "    logit_y_pred = K.log(y_pred / (1. - y_pred))\n",
    "    loss = weight * (logit_y_pred * (1. - y_true) + \n",
    "                     K.log(1. + K.exp(-K.abs(logit_y_pred))) + K.maximum(-logit_y_pred, 0.))\n",
    "    return K.sum(loss) / K.sum(weight)\n",
    "\n",
    "def weighted_dice_loss(y_true, y_pred, weight):\n",
    "    smooth = 1.\n",
    "    w, m1, m2 = weight, y_true, y_pred\n",
    "    intersection = (m1 * m2)\n",
    "    score = (2. * K.sum(w * intersection) + smooth) / (K.sum(w * m1) + K.sum(w * m2) + smooth)\n",
    "    loss = 1. - K.sum(score)\n",
    "    return loss\n",
    "\n",
    "def weighted_bce_dice_loss(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, 'float32')\n",
    "    y_pred = K.cast(y_pred, 'float32')\n",
    "    # if we want to get same size of output, kernel size must be odd\n",
    "    averaged_mask = K.pool2d(\n",
    "            y_true, pool_size=(50, 50), strides=(1, 1), padding='same', pool_mode='avg')\n",
    "    weight = K.ones_like(averaged_mask)\n",
    "    w0 = K.sum(weight)\n",
    "    weight = 5. * K.exp(-5. * K.abs(averaged_mask - 0.5))\n",
    "    w1 = K.sum(weight)\n",
    "    weight *= (w0 / w1)\n",
    "    loss = weighted_bce_loss(y_true, y_pred, weight) + dice_loss(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    intersection = K.sum(y_true * y_pred, axis=[1,2,3])\n",
    "    union = K.sum(y_true, axis=[1,2,3]) + K.sum(y_pred, axis=[1,2,3])\n",
    "    return K.mean( (2. * intersection + smooth) / (union + smooth), axis=0)\n",
    "def dice_p_bce(in_gt, in_pred):\n",
    "    return 1e-3*binary_crossentropy(in_gt, in_pred) - dice_coef(in_gt, in_pred)\n",
    "def true_positive_rate(y_true, y_pred):\n",
    "    return K.sum(K.flatten(y_true)*K.flatten(K.round(y_pred)))/K.sum(y_true)\n",
    "#seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=dice_p_bce, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Training Check Point¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/keras/callbacks/callbacks.py:998: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_dice_coef', verbose=1, \n",
    "                             save_best_only=True, mode='max', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_dice_coef', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='max', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_dice_coef\", \n",
    "                      mode=\"max\", \n",
    "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comiple model¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model.compile(optimizer=Adam(1e-4, decay=1e-6), loss=bce_logdice_loss, metrics=[dice_coef, 'binary_accuracy', true_positive_rate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nweight_path=\"{}_weights.best.hdf5\".format(\\'seg_model\\')\\n\\nearly_stopping = EarlyStopping(patience=10, verbose=1)\\nmodel_checkpoint = ModelCheckpoint(weight_path, save_best_only=True, verbose=1)\\nreduce_lr = ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001, verbose=1)\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "weight_path=\"{}_weights.best.hdf5\".format('seg_model')\n",
    "\n",
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(weight_path, save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=4, min_lr=0.00001, verbose=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 134s 672ms/step - loss: 2.8225 - dice_coef: 0.1183 - binary_accuracy: 0.9463 - true_positive_rate: 0.5485 - val_loss: 5.3100 - val_dice_coef: 0.1204 - val_binary_accuracy: 0.9993 - val_true_positive_rate: nan\n",
      "\n",
      "Epoch 00001: val_dice_coef improved from -inf to 0.12039, saving model to seg_model_weights.best.hdf5\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 113s 565ms/step - loss: 1.5819 - dice_coef: 0.2133 - binary_accuracy: 0.9934 - true_positive_rate: 0.5189 - val_loss: 5.8631 - val_dice_coef: 0.0440 - val_binary_accuracy: 0.9993 - val_true_positive_rate: nan\n",
      "\n",
      "Epoch 00002: val_dice_coef did not improve from 0.12039\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 112s 560ms/step - loss: 1.3618 - dice_coef: 0.2569 - binary_accuracy: 0.9949 - true_positive_rate: nan - val_loss: 5.8811 - val_dice_coef: 0.0610 - val_binary_accuracy: 0.9993 - val_true_positive_rate: nan\n",
      "\n",
      "Epoch 00003: val_dice_coef did not improve from 0.12039\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 110s 551ms/step - loss: 1.2791 - dice_coef: 0.2833 - binary_accuracy: 0.9951 - true_positive_rate: 0.5611 - val_loss: 4.4703 - val_dice_coef: 0.1792 - val_binary_accuracy: 0.9993 - val_true_positive_rate: nan\n",
      "\n",
      "Epoch 00004: val_dice_coef improved from 0.12039 to 0.17921, saving model to seg_model_weights.best.hdf5\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 111s 555ms/step - loss: 1.3412 - dice_coef: 0.2908 - binary_accuracy: 0.9911 - true_positive_rate: 0.6011 - val_loss: 3.0422 - val_dice_coef: 0.3535 - val_binary_accuracy: 0.9993 - val_true_positive_rate: nan\n",
      "\n",
      "Epoch 00005: val_dice_coef improved from 0.17921 to 0.35346, saving model to seg_model_weights.best.hdf5\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "\n",
    "step_count = min(MAX_TRAIN_STEPS, balanced_train_df.shape[0]//BATCH_SIZE)\n",
    "aug_gen = create_aug_gen(make_image_gen(balanced_train_df))\n",
    "loss_history = [seg_model.fit_generator(aug_gen,\n",
    "                            steps_per_epoch=step_count,\n",
    "                            validation_data=(valid_x, valid_y), \n",
    "                            epochs=5,\n",
    "                            callbacks=callbacks_list,shuffle=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model.load_weights(weight_path)\n",
    "seg_model.save(path + '/models/seg_model_unet34.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot loss history¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'DICE')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x720 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epich = np.cumsum(np.concatenate(\n",
    "    [np.linspace(0.5, 1, len(mh.epoch)) for mh in loss_history]))\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(22, 10))\n",
    "_ = ax1.plot(epich,\n",
    "             np.concatenate([mh.history['loss'] for mh in loss_history]),\n",
    "             'b-',\n",
    "             epich, np.concatenate(\n",
    "        [mh.history['val_loss'] for mh in loss_history]), 'r-')\n",
    "ax1.legend(['Training', 'Validation'])\n",
    "ax1.set_title('Loss')\n",
    "\n",
    "_ = ax2.plot(epich, np.concatenate(\n",
    "    [mh.history['dice_coef'] for mh in loss_history]), 'b-',\n",
    "                 epich, np.concatenate(\n",
    "        [mh.history['val_dice_coef'] for mh in loss_history]),\n",
    "                 'r-')\n",
    "ax2.legend(['Training', 'Validation'])\n",
    "ax2.set_title('DICE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Full Resolution Model¶\n",
    "Here we account for the scaling so everything can happen in the model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMG_SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "if IMG_SCALING is not None:\n",
    "    fullres_model = models.Sequential()\n",
    "    fullres_model.add(layers.AvgPool2D(IMG_SCALING, input_shape = (None, None, 3)))\n",
    "    fullres_model.add(seg_model)\n",
    "    fullres_model.add(layers.UpSampling2D(IMG_SCALING))\n",
    "else:\n",
    "    fullres_model = seg_model\n",
    "fullres_model.save(path+ '/models/fullres_model_unet34.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "average_pooling2d_1 (Average (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "u-resnet34 (Model)           multiple                  24453178  \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, None, None, 1)     0         \n",
      "=================================================================\n",
      "Total params: 24,453,178\n",
      "Trainable params: 24,437,812\n",
      "Non-trainable params: 15,366\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fullres_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the test data¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15606 test images found\n"
     ]
    }
   ],
   "source": [
    "test_paths = os.listdir(test_image_dir)\n",
    "print(len(test_paths), 'test images found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " Size 1 must be non-negative, not -21\n\t [[{{node u-resnet34/bn_data/batchnorm/mul-1-ReshapeNHWCToNCHW-LayoutOptimizer}}]] [Op:__inference_keras_scratch_graph_57257]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c07a5eb60210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_img_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_axs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageId\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mfirst_seg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_img_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Image: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc_img_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-c07a5eb60210>\u001b[0m in \u001b[0;36mraw_prediction\u001b[0;34m(img, path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mc_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_img_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mc_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcur_seg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullres_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcur_seg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  Size 1 must be non-negative, not -21\n\t [[{{node u-resnet34/bn_data/batchnorm/mul-1-ReshapeNHWCToNCHW-LayoutOptimizer}}]] [Op:__inference_keras_scratch_graph_57257]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAA2lCAYAAADYTMbFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzXwQ3AIBDAsNL9dz5mIB+EZE+Qb9bMzAcAAMCR/3YAAADAi8wUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAAAIzBQAAEBgpgAAAAIzBQAAEJgpAACAwEwBAAAEZgoAACAwUwAAAIGZAgAACMwUAABAYKYAAAACMwUAABCYKQAAgMBMAQAABGYKAAAgMFMAAACBmQIAAAjMFAAAQGCmAAAAAjMFAAAQmCkAAIDATAEAAARmCgAAIDBTAAAAgZkCAGCzX8cCAAAAAIP8reewuywCBpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKe7XHvkAACAASURBVAAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAGCQKQAAgEGmAAAABpkCAAAYZAoAAKD261gAAAAAYJC/9Rx2l0WDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAoDHXuwAACHRJREFUMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwyBQAAMMgUAADAIFMAAACDTAEAAAwBbrMfRkJ+VVAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x4608 with 64 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def raw_prediction(img, path=test_image_dir):\n",
    "    c_img = imread(os.path.join(path, c_img_name))\n",
    "    c_img = np.expand_dims(c_img, 0)/255.0\n",
    "    cur_seg = fullres_model.predict(c_img)[0]\n",
    "    return cur_seg, c_img[0]\n",
    "\n",
    "def smooth(cur_seg):\n",
    "    return binary_opening(cur_seg>0.99, np.expand_dims(disk(2), -1))\n",
    "\n",
    "def predict(img, path=test_image_dir):\n",
    "    cur_seg, c_img = raw_prediction(img, path=path)\n",
    "    return smooth(cur_seg), c_img\n",
    "\n",
    "## Get a sample of each group of ship count\n",
    "samples = valid_df.groupby('ships').apply(lambda x: x.sample(1))\n",
    "fig, m_axs = plt.subplots(samples.shape[0], 4, figsize = (15, samples.shape[0]*4))\n",
    "[c_ax.axis('off') for c_ax in m_axs.flatten()]\n",
    "\n",
    "for (ax1, ax2, ax3, ax4), c_img_name in zip(m_axs, samples.ImageId.values):\n",
    "    first_seg, first_img = raw_prediction(c_img_name, train_image_dir)\n",
    "    ax1.imshow(first_img)\n",
    "    ax1.set_title('Image: ' + c_img_name)\n",
    "    ax2.imshow(first_seg[:, :, 0], cmap=get_cmap('jet'))\n",
    "    ax2.set_title('Model Prediction')\n",
    "    reencoded = masks_as_color(multi_rle_encode(smooth(first_seg)[:, :, 0]))\n",
    "    ax3.imshow(reencoded)\n",
    "    ax3.set_title('Prediction Masks')\n",
    "    ground_truth = masks_as_color(masks.query('ImageId==\"{}\"'.format(c_img_name))['EncodedPixels'])\n",
    "    ax4.imshow(ground_truth)\n",
    "    ax4.set_title('Ground Truth')\n",
    "    \n",
    "fig.savefig('./pic/validation.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission¶\n",
    "We merge part1 trainsfer learning for detect ship exist result to generate submit result\n",
    "Please refer the submission result kernel : https://www.kaggle.com/super13579/unet34-predict-result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
