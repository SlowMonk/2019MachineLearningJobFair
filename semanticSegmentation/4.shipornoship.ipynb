{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "Rather than trying to segment, we start off by making a model that simply tries to identify if any boat shows up in the image. For this model we can see roughly how it performs in the compititon by guessing the whole image (as an RLE) if any boat shows up (not a very smart startegy, but might provide some interesting results).\n",
    "\n",
    "Beyond\n",
    "The model could also be useful as a quick way (low resolution images) to screen through lots of images to see if they are likely to have a boat and if they are then run a much more expensive full-resolution U-Net on that sample\n",
    "\n",
    "Model Parameters\n",
    "We might want to adjust these later (or do some hyperparameter optimizations). It is slightly easier to keep track of parallel notebooks with different parameters if they are all at the beginning in a clear (machine readable format, see Kaggling with Kaggle (https://www.kaggle.com/kmader/kaggling-with-kaggle). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, applications\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231723 masks found\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels\n",
       "0  00003e153.jpg                                                NaN\n",
       "1  0001124c7.jpg                                                NaN\n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...\n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...\n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "#from skimage.util.montage import montage2d as montage\n",
    "path = \"/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship Detection Challenge/\"\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "\n",
    "masks = pd.read_csv(os.path.join(path + 'train_ship_segmentations_v2.csv'))\n",
    "\n",
    "print(masks.shape[0],'masks found')\n",
    "\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAUSSIAN_NOISE = 0.1\n",
    "UPSAMPLE_MODE = 'SIMPLE'\n",
    "# number of validation images to use\n",
    "VALID_IMG_COUNT = 1000\n",
    "# maximum number of training images\n",
    "MAX_TRAIN_IMAGES = 15000 \n",
    "BASE_MODEL='DenseNet169' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121']\n",
    "IMG_SIZE = (299, 299) # [(224, 224), (384, 384), (512, 512), (640, 640)]\n",
    "BATCH_SIZE = 64 # [1, 8, 16, 24]\n",
    "DROPOUT = 0.5\n",
    "DENSE_COUNT = 128\n",
    "LEARN_RATE = 1e-4\n",
    "RGB_FLIP = 1 # should rgb be flipped when rendering images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import montage2d as montage\n",
    "montage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\n",
    "ship_dir = path\n",
    "train_image_dir = os.path.join(path, 'train_v2')\n",
    "test_image_dir = os.path.join(path, 'test_v2')\n",
    "import gc; gc.enable() # memory is tight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00003e153.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0001124c7.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000155de5.jpg</td>\n",
       "      <td>264661 17 265429 33 266197 33 266965 33 267733...</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>360486 1 361252 4 362019 5 362785 8 363552 10 ...</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000194a2d.jpg</td>\n",
       "      <td>51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ImageId                                      EncodedPixels  \\\n",
       "0  00003e153.jpg                                                NaN   \n",
       "1  0001124c7.jpg                                                NaN   \n",
       "2  000155de5.jpg  264661 17 265429 33 266197 33 266965 33 267733...   \n",
       "3  000194a2d.jpg  360486 1 361252 4 362019 5 362785 8 363552 10 ...   \n",
       "4  000194a2d.jpg  51834 9 52602 9 53370 9 54138 9 54906 9 55674 ...   \n",
       "\n",
       "                                                path  \n",
       "0  /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...  \n",
       "1  /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...  \n",
       "2  /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...  \n",
       "3  /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...  \n",
       "4  /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks['path'] = masks['ImageId'].map(lambda x: os.path.join(train_image_dir, x))\n",
    "masks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training and validation groups¶\n",
    "We stratify by the number of boats appearing so we have nice balances in each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162201 training masks\n",
      "69522 validation masks\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "masks['ships'] = masks['EncodedPixels'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "unique_img_ids = masks.groupby('ImageId').agg({'ships': 'sum'}).reset_index()\n",
    "unique_img_ids['has_ship'] = unique_img_ids['ships'].map(lambda x: 1.0 if x>0 else 0.0)\n",
    "unique_img_ids['has_ship_vec'] = unique_img_ids['has_ship'].map(lambda x: [x])\n",
    "masks.drop(['ships'], axis=1, inplace=True)\n",
    "train_ids, valid_ids = train_test_split(unique_img_ids, \n",
    "                 test_size = 0.3, \n",
    "                 stratify = unique_img_ids['ships'])\n",
    "train_df = pd.merge(masks, train_ids)\n",
    "valid_df = pd.merge(masks, valid_ids)\n",
    "print(train_df.shape[0], 'training masks')\n",
    "print(valid_df.shape[0], 'validation masks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Number of Ship Images\n",
    "Here we examine how often ships appear and replace the ones without any ships with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000 (162201, 6)\n"
     ]
    }
   ],
   "source": [
    "print(MAX_TRAIN_IMAGES,train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(min(MAX_TRAIN_IMAGES, train_df.shape[0])) # limit size of training set (otherwise it takes too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>EncodedPixels</th>\n",
       "      <th>path</th>\n",
       "      <th>ships</th>\n",
       "      <th>has_ship</th>\n",
       "      <th>has_ship_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39458</th>\n",
       "      <td>3e73dc08d.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48497</th>\n",
       "      <td>4cb67f9bf.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31215</th>\n",
       "      <td>3183fe988.jpg</td>\n",
       "      <td>448078 1 448844 4 449610 6 450377 8 451143 10 ...</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77613</th>\n",
       "      <td>7a310295a.jpg</td>\n",
       "      <td>290920 1 291687 3 292453 5 293220 7 293987 9 2...</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122152</th>\n",
       "      <td>c099dfb65.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115697</th>\n",
       "      <td>b63595563.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71265</th>\n",
       "      <td>706cb7d96.jpg</td>\n",
       "      <td>87617 1 88384 4 89151 6 89919 8 90686 10 91453...</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4534</th>\n",
       "      <td>07205f6ed.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98112</th>\n",
       "      <td>9aacf5ecd.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142753</th>\n",
       "      <td>e172eaaa2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ImageId                                      EncodedPixels  \\\n",
       "39458   3e73dc08d.jpg                                                NaN   \n",
       "48497   4cb67f9bf.jpg                                                NaN   \n",
       "31215   3183fe988.jpg  448078 1 448844 4 449610 6 450377 8 451143 10 ...   \n",
       "77613   7a310295a.jpg  290920 1 291687 3 292453 5 293220 7 293987 9 2...   \n",
       "122152  c099dfb65.jpg                                                NaN   \n",
       "...               ...                                                ...   \n",
       "115697  b63595563.jpg                                                NaN   \n",
       "71265   706cb7d96.jpg  87617 1 88384 4 89151 6 89919 8 90686 10 91453...   \n",
       "4534    07205f6ed.jpg                                                NaN   \n",
       "98112   9aacf5ecd.jpg                                                NaN   \n",
       "142753  e172eaaa2.jpg                                                NaN   \n",
       "\n",
       "                                                     path  ships  has_ship  \\\n",
       "39458   /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      0       0.0   \n",
       "48497   /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      0       0.0   \n",
       "31215   /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      5       1.0   \n",
       "77613   /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      8       1.0   \n",
       "122152  /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      0       0.0   \n",
       "...                                                   ...    ...       ...   \n",
       "115697  /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      0       0.0   \n",
       "71265   /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      9       1.0   \n",
       "4534    /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      0       0.0   \n",
       "98112   /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      0       0.0   \n",
       "142753  /mnt/3CE35B99003D727B/input/kaggle/Airbus Ship...      0       0.0   \n",
       "\n",
       "       has_ship_vec  \n",
       "39458         [0.0]  \n",
       "48497         [0.0]  \n",
       "31215         [1.0]  \n",
       "77613         [1.0]  \n",
       "122152        [0.0]  \n",
       "...             ...  \n",
       "115697        [0.0]  \n",
       "71265         [1.0]  \n",
       "4534          [0.0]  \n",
       "98112         [0.0]  \n",
       "142753        [0.0]  \n",
       "\n",
       "[15000 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f43142d9d68>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f42374b8b00>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[['ships','has_ship']].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "if BASE_MODEL=='VGG16':\n",
    "    from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='RESNET52':\n",
    "    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='InceptionV3':\n",
    "    from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='Xception':\n",
    "    from keras.applications.xception import Xception as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='DenseNet169': \n",
    "    from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='DenseNet121':\n",
    "    from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\n",
    "else:\n",
    "    raise ValueError('Unknown model: {}'.format(BASE_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "dg_args = dict(featurewise_center = False, \n",
    "                  samplewise_center = False,\n",
    "                  rotation_range = 45, \n",
    "                  width_shift_range = 0.1, \n",
    "                  height_shift_range = 0.1, \n",
    "                  shear_range = 0.01,\n",
    "                  zoom_range = [0.9, 1.25],  \n",
    "                  brightness_range = [0.5, 1.5],\n",
    "                  horizontal_flip = True, \n",
    "                  vertical_flip = True,\n",
    "                  fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last',\n",
    "              preprocessing_function = preprocess_input)\n",
    "valid_args = dict(fill_mode = 'reflect',\n",
    "                   data_format = 'channels_last',\n",
    "                  preprocessing_function = preprocess_input)\n",
    "\n",
    "core_idg = ImageDataGenerator(**dg_args)\n",
    "valid_idg = ImageDataGenerator(**valid_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways')\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 15000 images\n"
     ]
    }
   ],
   "source": [
    "train_gen = flow_from_dataframe(core_idg, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'has_ship_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Ignore next message from keras, values are replaced anyways\n",
      "Found 0 images belonging to 0 classes.\n",
      "Reinserting dataframe: 69522 images\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-26b3a3a98978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                             \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                              \u001b[0mcolor_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                             batch_size = VALID_IMG_COUNT)) # one big batch\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# The transformation of images is not under thread lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# so it can be done in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mfilepaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             img = load_img(filepaths[j],\n\u001b[0m\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# used a fixed dataset for evaluating the algorithm\n",
    "valid_x, valid_y = next(flow_from_dataframe(valid_idg, \n",
    "                               valid_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'has_ship_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = VALID_IMG_COUNT)) # one big batch\n",
    "print(valid_x.shape, valid_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
