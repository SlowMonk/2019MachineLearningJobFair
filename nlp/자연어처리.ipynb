{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jake/venv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import multiprocessing # 여러 개의 일꾼 (cpu)들에게 작업을 분산시키는 역할\n",
    "from multiprocessing import Pool \n",
    "from functools import partial # 함수가 받는 인자들 중 몇개를 고정 시켜서 새롭게 파생된 함수를 형성하는 역할\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib # 모델을 저장하고 불러오는 역할\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn import *\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Komoran\n",
    "from konlpy.tag import Twitter\n",
    "from time import time\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "from future.utils import iteritems\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "#from tensorflow import set_random_seed\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense,Dropout,Embedding,LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "\n",
    "from collections import namedtuple\n",
    "from gensim.models import doc2vec\n",
    "from konlpy.tag import Twitter\n",
    "import multiprocessing\n",
    "from pprint import pprint\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import common_texts\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문제의 정의 \n",
    "\n",
    "![Screenshot from 2020-02-05 08-51-17](https://user-images.githubusercontent.com/33189954/73798021-e9e65480-47f4-11ea-964e-6ef01cb6917a.png)\n",
    "\n",
    "\n",
    "### 문제의 정의 와 접근 방법 \n",
    "\n",
    "전처리 임배딩 방법. \n",
    " * TF-IDF(상대 빈도 분석)  \n",
    " * one-hot-encoding \n",
    " * word2vec : 비슷한 단어는 비슷한 패던(백터)를 가지게 하기  \n",
    " * Glove :  word2vec은 단어간의 동시 등장할 때의 확률을 고려하지 않음 동시 등장확률을 예측하도록 개선함 \n",
    " * FasetText: 원래 단어를 부분 단어들의 벡터들로 표현한다는 점이 다름  \n",
    " * Cove: 원래 단어를 부분 단어들의 벡터들로 표현한다. \n",
    " * Cove: 다른 번역 모델에서 학습된 인코더를 붙여서 문맥 정보를 표현 \n",
    " * Elmo: 여러층의 인코더로 구성된 모델로 학습하여 합한 가중치를 이용하여 문백 정보를 표혀현함  \n",
    "\n",
    "\n",
    "일단 문제자체는 특이했다 중요한 문자 자체가 특수문자로 가려져 있었고 문장길이도 그렇게 길지 않지만 \n",
    "각 언어들(dic = [\"array\",\"c\",\"c++\",\"java\",\"javascript\",\"python\"])의 특성이 분명히 있고 \n",
    "그런것들의 TF(term frequency)로 보면 좋지 않을까해서 자연어에서 TF-IDF분석이 있어서 일단 실행해 봤다. \n",
    "간단한 stopword를 제거해주고 적정한 tokenizer를 찾은후 0.70정도의 결과 가 나왔다. \n",
    "\n",
    "그후에 든 생각은 좀더 문장자체를 벡터화 해줘서 새로운 문장이 나오면 좋지 않을까라고 생각했다. \n",
    "문제의 특성상 이접근이 좋을지는 장담할수없었다(문장 길이도 짧고 특성단어왜에는 질문이 비슷할거라고 생각했다)\n",
    "하지만 예상과는 다르게 doc2vec를 학습시키고 windows사이즈를 조정해주면서 실험결과 대략 0.78~ 0.83 까지의 결과가 나왔다.\n",
    "\n",
    "그후에 가장 많이 등장하지 않는 단어들을 stopwords에 추가 해주었지만 성능 향상은 미미했고\n",
    "Doc2vec의 vocab들을 보면서 similarity를 비교해가면서 좀 필요없는 단어들을 몇개 stopwords에 추가해줘봤지만 성능 향상은 미미했다. \n",
    "\n",
    "마지막으로 skt-bert를 처음 써보려고 했는데 아직 익숙하지가 않아서 에러를 해결하지는 못했다. \n",
    "다른 데이터 셋은 실행해봤는데 메모리도 로컬 머신으로는 부족하고 나중에 좀더 해봐야겠다\n",
    "버트는 단어간의 연관정보를 좀더 명확하게 얻는것이라고 알고있지만 결과는 보지 못했다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "데이터는 총 (2591,3) 이고 test는 (500,2) 이다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "content    0\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "path = '/mnt/3CE35B99003D727B/input/jabfair2019/nlp/'\n",
    "\n",
    "train = pd.read_csv(path + 'hashcode_classification2020_train.csv')\n",
    "test = pd.read_csv(path + 'hashcode_classification2020_test.csv')\n",
    "sample = pd.read_csv(path + 'hashcode_classification2020_sample.csv')\n",
    "\n",
    "train.loc[train.content.isnull()]\n",
    "train.dropna(how='any',inplace=True)\n",
    "test.dropna(how='any',inplace=True)\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2591, 3) (500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title과 content를 함께 분석해주기 위해서 두가지를 합쳐 준다.\n",
    "train['document'] = train['title']+ ' ' + train['content']\n",
    "test['document'] = test['title']+ ' ' + test['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장에서 등장하는 stopwords정의 \n",
    "stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도',\n",
    "           '를','으로','자','에','와','한','하다','요','및','에서','게','을',\n",
    "           '입니다','로','하는','것','된','할','못','그','두'\n",
    "          ,'서','고','때','하고','ㅜ+','ㅠ+','과']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문장 분석 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "twitter = Twitter()\n",
    "def tokenizer_twitter_morphs(doc):\n",
    "    return twitter.morphs(doc)\n",
    "\n",
    "def tokenizer_twitter_noun(doc):\n",
    "    return twitter.nouns(doc)\n",
    "\n",
    "def tokenizer_twitter_pos(doc):\n",
    "    return twitter.pos(doc, norm=True, stem=True)\n",
    "\n",
    "komoran = Komoran()\n",
    "def tokenizer_noun(doc):\n",
    "    return komoran.nouns(doc)\n",
    "\n",
    "def tokenizer_morphs(doc):\n",
    "    return komoran.morphs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = [\"array\",\"c\",\"c++\",\"java\",\"javascript\",\"python\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_02 = train[train.label==2]\n",
    "train_03 = train[train.label==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/jake/venv/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_02['document_token'] = train_02['document'].apply(tokenizer_twitter_morphs)\n",
    "train_03['document_token'] = train_03['document'].apply(tokenizer_twitter_morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_02 = [ t for d in train_02['document_token'] for t in d]\n",
    "tokens_02=[word for word in tokens_02 if not word in stopwords] # 불용어 제거\n",
    "\n",
    "tokens_03 = [ t for d in train_03['document_token'] for t in d]\n",
    "tokens_03=[word for word in tokens_03 if not word in stopwords] # 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_02 = nltk.Text(tokens_02, name='NMSC')\n",
    "text_03 = nltk.Text(tokens_03, name='NMSC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('\\n', 2108), (';', 1793), ('(', 1729), ('.', 1366), (',', 1364), ('_', 1125), ('\\n\\t', 1111), ('\\n\\n', 1068), ('=', 1044), ('{', 927), ('<<', 834), ('int', 821), ('}', 804), (')', 758), ('\\n\\t\\t', 687), (');', 629), ('1', 621), ('[', 596), ('0', 576), ('\"', 538), ('i', 511), ('//', 492), ('<', 480), ('::', 459), (':', 435), ('\\n    ', 428), ('```', 421), ('2', 411), ('()', 380), ('cout', 373)]\n",
      "=============================================================================================\n",
      "[('.', 13360), ('(', 6270), ('=', 4015), ('\\n', 3852), (';', 3242), ('}', 2895), ('{', 2667), (',', 2628), ('\\n        ', 2474), (')', 2472), ('_', 2282), ('\\n                ', 2267), (');', 2249), ('\\n\\n', 2152), ('\"', 1856), ('1', 1644), (':', 1558), ('new', 1349), ('();', 1336), ('String', 1319), ('\\n    ', 1316), ('int', 1254), ('public', 1248), ('<', 1247), ('i', 1227), ('-', 1104), ('>', 1075), ('[', 1040), ('?', 1020), ('2', 1013)]\n",
      "=============================================================================================\n",
      "[('도와주실', 1), ('담고싶은데', 1), ('끊어서', 1), ('현상', 1), ('커지는', 1), ('오히려', 1), ('잡혀서', 1), ('010100111', 1), ('하는데까지는', 1), ('짯는데', 1), ('형변환', 1), ('multimap', 1), ('돌아서', 1), ('...*/', 1), ('blah', 1), ('/*...', 1), ('이었는데', 1), ('돌면', 1), ('http://www.cocos2d-x.org/', 1)]\n",
      "=============================================================================================\n",
      "[('바깥', 1), ('세부', 1), ('드려는데', 1), ('https://res.cloudinary.com/eightcruz/image/upload/v1505887566/ovvdxcjimzxmz4cnziue.png', 1), ('초록색', 1), ('자린이', 1), ('////////////', 1), ('///////////////////', 1), ('getCode', 1), ('ATA', 1), ('MMS', 1), ('LMS', 1), ('filled', 1), ('mandatory', 1), ('시크릿', 1), ('////////////////////////////////////', 1), ('만든거고요', 1), ('/////////////////////', 1), ('±¼¸²', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 일단 2개의 label문장에서 가장 많이 등장하는 30개 단어와 가장 적게 등장하는단어 20개를 나타내주었다\n",
    "# 일단 가장 많이 등장하는 단어도 사람이 봐서는 알기가 어렵다. \n",
    "print(text_02.vocab().most_common(30))\n",
    "print(\"=============================================================================================\")\n",
    "print(text_03.vocab().most_common(30))\n",
    "print(\"=============================================================================================\")\n",
    "print(text_02.vocab().most_common()[:-20:-1])\n",
    "print(\"=============================================================================================\")\n",
    "print(text_03.vocab().most_common()[:-20:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-942cb2a30789>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# javascript같은 경우도 문장 특성내에서 javascript를 정의할만한 말들이 없다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"====================================================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "# javascript같은 경우도 문장 특성내에서 javascript를 정의할만한 말들이 없다. \n",
    "num = 3\n",
    "print([dic[y_train[num]]])\n",
    "print(\"====================================================================\")\n",
    "print(X_train[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python']\n",
      "====================================================================\n",
      "$$$ 2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요? ```\n",
      ">>>dict['name']\n",
      "胡安·马塔\n",
      ">>>json.dumps(dict['name']).replace(\"\\\\\",\"\\\\\\\\\")\n",
      "\"\\\\u80e1\\\\u5b89\\\\u00b7\\\\u9a6c\\\\u5854\"\n",
      ">>>\"Player name is '{}'\".format(dict['name'])\n",
      "UnicodeEncodeError 'ascii' codec can't encode character\n",
      ">>>\"Player name is '{}'\".format(json.dumps(dict['name']))\n",
      "UnicodeEncodeError 'ascii' codec can't encode character\n",
      "```\n",
      "다른 중국 단어들은 잘 들어가는데 胡安·马塔 이 단어에서 인코드 에러가 발생하네요... 중국어가 문제가 아니라 가운데 점이 문제인거같은데 혹시 이 경우 어떻게 포멧팅 해야하나요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# python의 특징이 조금 두드러진다. 2.7같은 단어나 3.X 가 중요할것으로 보여지는데....\n",
    "num = 4\n",
    "print([dic[y_train[num]]])\n",
    "print(\"====================================================================\")\n",
    "print(X_train[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c++']\n",
      "====================================================================\n",
      "$$$ 에서 음악 정보를 가져오는 법에 대해 질문드립니다 제가 현재 $$$ 에서 자료구조 공부를 하며 음악 관련 프로그램을 짜고 있습니다\n",
      "\n",
      "현재는 콘솔창에서 사용자로부터 제목이나 앨범 가수 등을 직접 입력받는 형식인데\n",
      "\n",
      "콘솔창에서 사용자로부터 음악의 제목만 입력받으면 실제 음원 파일이 있을시에\n",
      "\n",
      "그 음원파일로부터 정보를 가져와 저절로 입력이 되도록 하고 싶습니다\n",
      "\n",
      "또한 폴더 안에 음악 파일이 여러개 있으면 폴더명을 입력할시 그 안에 있는 모든 음악 파일의\n",
      "\n",
      "정보를 가져와서 각 자료구조에 저장이 되도록 하고 싶은데 뭘 사용해야 될지를 잘모르겠습니다\n",
      "\n",
      "다른 라이브러리가 필요한지 아니면 $$$ 내에 있는 기능만으로 가능한지 여쭤봅니다\n"
     ]
    }
   ],
   "source": [
    "# c++같은 경우도 마땅히 이 문장만 봐서는 c++인지는 알기 어렵다 \n",
    "num = 777\n",
    "print([dic[y_train[num]]])\n",
    "print(\"====================================================================\")\n",
    "print(X_train[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c']\n",
      "====================================================================\n",
      "자연수 n을 입력 받아 이를 n보다 작은 자연수들의 합으로 나타내는 방법 가지수를 출력하는 프로그램을 재귀 호출을 사용하여 작성하시오($$$) 자연수 n을 입력 받아 이를 n보다 작은 자연수들의 합으로 나타내는 방법 가지수를 출력하는 프로그램을 재귀 호출을 사용하여 작성하시오.'라는 문제가 있어요  $$$로 명쾌한 해답 내주세요 \n",
      "\n",
      "ex)n=4\n",
      "\n",
      "1+1+1+1\n",
      "\n",
      "1+1+2\n",
      "\n",
      "1+1+2\n",
      "\n",
      "1+2+1\n",
      "\n",
      "2+1+1\n",
      "\n",
      "2+2\n",
      "\n",
      "3+1\n",
      "\n",
      "1+3\n",
      "\n",
      "이므로 출력결과가 '7가지'라고 나오는 $$$ 코드 좀 알려주세요  \n",
      "제발 부탁드립니다 프로그래머님들!!!\n"
     ]
    }
   ],
   "source": [
    "# 이정도 문장은 사람이 분석해도 뭔가 어렵다고 생각이 든다.\n",
    "num = 779\n",
    "print([dic[y_train[num]]])\n",
    "print(\"====================================================================\")\n",
    "print(X_train[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "TF(term frequency)는 특정한 단어가 문서 내에서 얼마나 자주 등장하는 지에대해서 나타내주려고 선택했다. \n",
    "일단 걱정은 한글과 영어를 토크나이징을 잘하는 토크나이져를 선택하는 일이었고   \n",
    "문서 자체에 너무 문법적인 질문외에 일반적인 질문이 나오면 오분류 할수있겠다는 문제가 있지만 일단 테스트해보기로 했고 \n",
    "validation acc는 0.76정도 나오고 test acc는 0.70정도 나왔다. \n",
    "나쁘지 않은 결과 였지만 좀더 전체 문장을 벡터로 만들어서 비교하는 Doc2vec를 사용하면 좋을 것같다고 생각했다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/konlpy/tag/_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    }
   ],
   "source": [
    "twitter = Twitter()\n",
    "def tokenizer_twitter_morphs(doc):\n",
    "    return twitter.morphs(doc)\n",
    "\n",
    "def tokenizer_twitter_noun(doc):\n",
    "    return twitter.nouns(doc)\n",
    "\n",
    "def tokenizer_twitter_pos(doc):\n",
    "    return twitter.pos(doc, norm=True, stem=True)\n",
    "\n",
    "komoran = Komoran()\n",
    "def tokenizer_noun(doc):\n",
    "    return komoran.nouns(doc)\n",
    "\n",
    "def tokenizer_morphs(doc):\n",
    "    return komoran.morphs(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(' +', ' ',test.document[0])\n",
    "train.document=train.document.apply(lambda x: re.sub(' +', ' ',x))\n",
    "test.document=test.document.apply(lambda x: re.sub(' +', ' ',x))\n",
    "\n",
    "train.document=train.document.apply(lambda x: re.sub('ㅜ+', ' ',x))\n",
    "test.document=test.document.apply(lambda x: re.sub('ㅜ+', ' ',x))\n",
    "\n",
    "train.document=train.document.apply(lambda x: re.sub('ㅠ+', ' ',x))\n",
    "test.document=test.document.apply(lambda x: re.sub('ㅠ+', ' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.loc[:, 'document'].values\n",
    "y_train = train.loc[:, 'label'].values\n",
    "\n",
    "y_test = test.loc[:,'document'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenizer_morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(\n",
    "    C=1.0,\n",
    "    class_weight='balanced',\n",
    "    dual=True,\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=1,\n",
    "    loss='squared_hinge',\n",
    "    max_iter=1000,\n",
    "    multi_class='ovr',\n",
    "    penalty='l2',\n",
    "    random_state=0,\n",
    "    tol=1e-05, \n",
    "    verbose=0\n",
    ")\n",
    "tfidf = CountVectorizer(\n",
    "    input='content',\n",
    "    encoding='utf-8',\n",
    "    decode_error='strict',\n",
    "    strip_accents=None,\n",
    "    lowercase=True,\n",
    "    preprocessor=None,\n",
    "    tokenizer=None,\n",
    "    stop_words=None,\n",
    "    token_pattern=r\"(?u)\\b\\w\\w+\\b\",\n",
    "    ngram_range=(1, 1),\n",
    "    analyzer='word',\n",
    "    max_df=1.0,\n",
    "    min_df=1,\n",
    "    max_features=None,\n",
    "    vocabulary=None,\n",
    "    binary=False,\n",
    "    dtype=np.int64\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('svc', svc),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train = 1.0, Test = 0.766859344894027\n",
      "Train = 1.0, Test = 0.7625482625482626\n",
      "Train = 1.0, Test = 0.7644787644787645\n",
      "Train = 1.0, Test = 0.7567567567567568\n",
      "Train = 1.0, Test = 0.7413127413127413\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "X = train.loc[:, 'document'].values\n",
    "y = train.loc[:, 'label'].values\n",
    "\n",
    "for tr, te in skf.split(X, y):\n",
    "    pipeline.fit(X[tr], y[tr])\n",
    "    train_score = pipeline.score(X[tr], y[tr])\n",
    "    test_score = pipeline.score(X[te], y[te])\n",
    "    print(\"Train = {}, Test = {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train = 0.9995173745173745, Test = 0.7822736030828517\n",
      "Train = 0.9995176073323685, Test = 0.7644787644787645\n",
      "Train = 1.0, Test = 0.7702702702702703\n",
      "Train = 1.0, Test = 0.7413127413127413\n",
      "Train = 1.0, Test = 0.7644787644787645\n"
     ]
    }
   ],
   "source": [
    "sgd_clf = Pipeline([('vect', tfidf), ('sgd', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42))])\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "X = train.loc[:, 'document'].values\n",
    "y = train.loc[:, 'label'].values\n",
    "\n",
    "for tr, te in skf.split(X, y):\n",
    "    sgd_clf.fit(X[tr], y[tr])\n",
    "    train_score = sgd_clf.score(X[tr], y[tr])\n",
    "    test_score = sgd_clf.score(X[te], y[te])\n",
    "    print(\"Train = {}, Test = {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipeline.predict(y_test)\n",
    "submission = pd.DataFrame(data=y_pred)\n",
    "submission.to_csv('submissionTf-idf.csv',index=False) #제출 파일 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub(' +', ' ',test.document[0])\n",
    "def clean_df():\n",
    "    list=[' +','ㅜ+','ㅠ+','[$]+','[@]+','[#]+','\\n']\n",
    "    #list=[' +','ㅜ+','ㅠ+','\\n']\n",
    "    for i in list:\n",
    "        train.document=train.document.apply(lambda x: re.sub(i, ' ',x))\n",
    "        test.document=test.document.apply(lambda x: re.sub(i, ' ',x))\n",
    "clean_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_korean=['의','가','이','은','들','는','좀','잘','걍','과','도',\n",
    "           '를','으로','자','에','와','한','하다','요','및','에서','게','을',\n",
    "           '입니다','로','하는','것','된','할','못','그','두'\n",
    "          ,'서','고','때','하고','ㅜ+','ㅠ+','과','님']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = Twitter()\n",
    "def tokenizer_twitter_morphs(doc):\n",
    "    return twitter.morphs(doc)\n",
    "\n",
    "def tokenizer_twitter_noun(doc):\n",
    "    return twitter.nouns(doc)\n",
    "\n",
    "def tokenizer_twitter_pos(doc):\n",
    "    return twitter.pos(doc, norm=True, stem=True)\n",
    "\n",
    "komoran = Komoran()\n",
    "def tokenizer_noun(doc):\n",
    "    return komoran.nouns(doc)\n",
    "\n",
    "def tokenizer_morphs(doc):\n",
    "    return komoran.morphs(doc)\n",
    "\n",
    "train['token_review']=train.document.apply(tokenizer_twitter_morphs)\n",
    "test['token_review']=test.document.apply(tokenizer_twitter_morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_01 = train[train.label==1]\n",
    "train_02 = train[train.label==2]\n",
    "train_03 = train[train.label==3]\n",
    "train_04 = train[train.label==4]\n",
    "train_05 = train[train.label==5]\n",
    "\n",
    "tokens_01 = [ t for d in train_01['token_review'] for t in d]\n",
    "tokens_01=[word for word in tokens_01 if not word in stopwords_korean] # 불용어 제거\n",
    "\n",
    "tokens_02 = [ t for d in train_02['token_review'] for t in d]\n",
    "tokens_02=[word for word in tokens_02 if not word in stopwords_korean] # 불용어 제거\n",
    "\n",
    "tokens_03 = [ t for d in train_03['token_review'] for t in d]\n",
    "tokens_03=[word for word in tokens_03 if not word in stopwords_korean] # 불용어 제거\n",
    "\n",
    "tokens_04 = [ t for d in train_04['token_review'] for t in d]\n",
    "tokens_04=[word for word in tokens_04 if not word in stopwords_korean] # 불용어 제거\n",
    "\n",
    "tokens_05 = [ t for d in train_05['token_review'] for t in d]\n",
    "tokens_05=[word for word in tokens_05 if not word in stopwords_korean] # 불용어 제거\n",
    "\n",
    "\n",
    "text_01 = nltk.Text(tokens_01, name='NMSC')\n",
    "text_02 = nltk.Text(tokens_02, name='NMSC')\n",
    "\n",
    "text_03 = nltk.Text(tokens_03, name='NMSC')\n",
    "text_04 = nltk.Text(tokens_04, name='NMSC')\n",
    "\n",
    "text_05 = nltk.Text(tokens_05, name='NMSC')\n",
    "\n",
    "result = []\n",
    "limit = -20\n",
    "for i in text_01.vocab().most_common()[:limit:-1]:\n",
    "    #print(i[0])\n",
    "    result.append(i[0])\n",
    "for i in text_02.vocab().most_common()[:limit:-1]:\n",
    "    #print(i[0])\n",
    "    result.append(i[0])\n",
    "for i in text_03.vocab().most_common()[:limit:-1]:\n",
    "    #print(i[0])\n",
    "    result.append(i[0])\n",
    "for i in text_04.vocab().most_common()[:limit:-1]:\n",
    "    #print(i[0])\n",
    "    result.append(i[0])\n",
    "for i in text_05.vocab().most_common()[:limit:-1]:\n",
    "    #print(i[0])\n",
    "    result.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#stopwords.words('korean')\n",
    "add = ['모르겠습니다','뜨는데','2','받아','결과','시키면','개','등','박스','써야']\n",
    "stopwords =stopwords_korean +  list(stopwords.words('english')) + result + add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['의',\n",
       " '가',\n",
       " '이',\n",
       " '은',\n",
       " '들',\n",
       " '는',\n",
       " '좀',\n",
       " '잘',\n",
       " '걍',\n",
       " '과',\n",
       " '도',\n",
       " '를',\n",
       " '으로',\n",
       " '자',\n",
       " '에',\n",
       " '와',\n",
       " '한',\n",
       " '하다',\n",
       " '요',\n",
       " '및',\n",
       " '에서',\n",
       " '게',\n",
       " '을',\n",
       " '입니다',\n",
       " '로',\n",
       " '하는',\n",
       " '것',\n",
       " '된',\n",
       " '할',\n",
       " '못',\n",
       " '그',\n",
       " '두',\n",
       " '서',\n",
       " '고',\n",
       " '때',\n",
       " '하고',\n",
       " 'ㅜ+',\n",
       " 'ㅠ+',\n",
       " '과',\n",
       " '님',\n",
       " 'i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " '받았는데요',\n",
       " ')>(',\n",
       " 'Compare',\n",
       " '주어졌을',\n",
       " '첨자',\n",
       " '열의',\n",
       " 'ordered',\n",
       " '학년',\n",
       " '된다는것',\n",
       " '위상정렬',\n",
       " '희소행렬',\n",
       " '패닝',\n",
       " 'bfs',\n",
       " '받아들이겠습니다',\n",
       " '달',\n",
       " '피',\n",
       " '아픕니다',\n",
       " '무지막지',\n",
       " '400000005',\n",
       " '도와주실',\n",
       " '담고싶은데',\n",
       " '끊어서',\n",
       " '현상',\n",
       " '커지는',\n",
       " '오히려',\n",
       " '잡혀서',\n",
       " '010100111',\n",
       " '하는데까지는',\n",
       " '짯는데',\n",
       " '형변환',\n",
       " 'multimap',\n",
       " '돌아서',\n",
       " '...*/',\n",
       " 'blah',\n",
       " '/*...',\n",
       " '이었는데',\n",
       " '돌면',\n",
       " 'http://www.cocos2d-x.org/',\n",
       " '바깥',\n",
       " '세부',\n",
       " '드려는데',\n",
       " 'https://res.cloudinary.com/eightcruz/image/upload/v1505887566/ovvdxcjimzxmz4cnziue.png',\n",
       " '초록색',\n",
       " '자린이',\n",
       " '////////////',\n",
       " '///////////////////',\n",
       " 'getCode',\n",
       " 'ATA',\n",
       " 'MMS',\n",
       " 'LMS',\n",
       " 'filled',\n",
       " 'mandatory',\n",
       " '시크릿',\n",
       " '////////////////////////////////////',\n",
       " '만든거고요',\n",
       " '/////////////////////',\n",
       " '±¼¸²',\n",
       " '도와주실',\n",
       " '먹겠는데',\n",
       " '덤볐는데',\n",
       " '만든다고',\n",
       " '사이드바',\n",
       " '만들려고하는데요',\n",
       " '사이드',\n",
       " '다름이아니라',\n",
       " '올려져있어요',\n",
       " 'https://codepen.io/jeee/pen/XwVwzg',\n",
       " '자세한건',\n",
       " 'https://res.cloudinary.com/eightcruz/image/upload/v1558663139/hrguug3fmykvyijeclex.png',\n",
       " '상대',\n",
       " '먹어서',\n",
       " '넘어가는데',\n",
       " 'http://res.cloudinary.com/eightcruz/image/upload/v1478349599/bmyvj08e8fo047yo9cb8.jpg',\n",
       " 'http://res.cloudinary.com/eightcruz/image/upload/v1478349492/hojwrorkhbmgtj8s5pih.jpg',\n",
       " '좋을',\n",
       " '커뮤니티',\n",
       " '마땅',\n",
       " '찾아보았지만',\n",
       " '되어있어서',\n",
       " 'migate',\n",
       " '그러고서',\n",
       " '알맞게',\n",
       " '하려고하였습니다',\n",
       " '관성',\n",
       " '놓도록',\n",
       " '/`',\n",
       " '`/',\n",
       " 'freecreate',\n",
       " 'freeboard',\n",
       " 'wsgi',\n",
       " '궁금증',\n",
       " '웹게임',\n",
       " 'migration',\n",
       " '찾으려면',\n",
       " '\",\"!\"]`',\n",
       " '모르겠습니다',\n",
       " '뜨는데',\n",
       " '2',\n",
       " '받아',\n",
       " '결과',\n",
       " '시키면',\n",
       " '개',\n",
       " '등',\n",
       " '박스',\n",
       " '써야']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "stop words를 정의 해주었다 \n",
    "문장내에서 등장하지 않는 단어와 너무 관련이 없어 보이는 단어들도 추가 하였다. \n",
    "일단 왭개발 같은 중요한 단어도 보이지만 일단 추가 하였다. \n",
    "'''\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['token_review']=train['token_review'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "test['token_review']=test['token_review'].apply(lambda x: [item for item in x if item not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "      <th>token_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wait()과 sleep()의 차이점은 뭔가요</td>\n",
       "      <td>###발생하는 문제 및 실행환경\\nwait()과 sleep()의 차이점은 뭔가요</td>\n",
       "      <td>3</td>\n",
       "      <td>wait()과 sleep()의 차이점은 뭔가요  발생하는 문제 및 실행환경 wait...</td>\n",
       "      <td>[wait, (), sleep, (), 차이점, 뭔가, 발생, 문제, 실행, 환경,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$$$ 초보 외부 클래스 멤버 변수 사용 질문합니다.ㅠㅠ</td>\n",
       "      <td>1.헤더에, 사용할 멤버변수가 담긴 헤더 파일이 Include 되어있습니다.\\n예를...</td>\n",
       "      <td>2</td>\n",
       "      <td>초보 외부 클래스 멤버 변수 사용 질문합니다. 1.헤더에, 사용할 멤버변수가 담...</td>\n",
       "      <td>[초보, 외부, 클래스, 멤버, 변수, 사용, 질문, 합니다, ., 1, ., 헤더...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORM: Sequelize: 다대다 관계 쿼리</td>\n",
       "      <td>안녕하세요.\\n\\n어떻게 다대다 관계 쿼리를 해야하나요? 예를들어, `product...</td>\n",
       "      <td>4</td>\n",
       "      <td>ORM: Sequelize: 다대다 관계 쿼리 안녕하세요.  어떻게 다대다 관계 쿼...</td>\n",
       "      <td>[ORM, :, Sequelize, :, 다대, 다, 관계, 쿼리, 안녕하세요, ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$$$에서 숫자가 NaN인지 검사하려면 어떻게해야하죠?</td>\n",
       "      <td>```\\nparseFloat('geoff') == NaN;\\n\\nparseFloat...</td>\n",
       "      <td>4</td>\n",
       "      <td>에서 숫자가 NaN인지 검사하려면 어떻게해야하죠? ``` parseFloat('g...</td>\n",
       "      <td>[숫자, NaN, 인지, 검사, 하려면, 어떻게, 해야하죠, ?, ```, pars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$$$ 2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요?</td>\n",
       "      <td>```\\n&gt;&gt;&gt;dict['name']\\n胡安·马塔\\n&gt;&gt;&gt;json.dumps(dic...</td>\n",
       "      <td>5</td>\n",
       "      <td>2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요? ``` &gt;&gt;&gt;dict[...</td>\n",
       "      <td>[2.7, 중국어, ,, 특수문자, 인코딩, 방법, 뭔가, ?, ```, &gt;&gt;&gt;, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  \\\n",
       "0            wait()과 sleep()의 차이점은 뭔가요   \n",
       "1      $$$ 초보 외부 클래스 멤버 변수 사용 질문합니다.ㅠㅠ   \n",
       "2            ORM: Sequelize: 다대다 관계 쿼리   \n",
       "3       $$$에서 숫자가 NaN인지 검사하려면 어떻게해야하죠?   \n",
       "4  $$$ 2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요?   \n",
       "\n",
       "                                             content  label  \\\n",
       "0       ###발생하는 문제 및 실행환경\\nwait()과 sleep()의 차이점은 뭔가요      3   \n",
       "1  1.헤더에, 사용할 멤버변수가 담긴 헤더 파일이 Include 되어있습니다.\\n예를...      2   \n",
       "2  안녕하세요.\\n\\n어떻게 다대다 관계 쿼리를 해야하나요? 예를들어, `product...      4   \n",
       "3  ```\\nparseFloat('geoff') == NaN;\\n\\nparseFloat...      4   \n",
       "4  ```\\n>>>dict['name']\\n胡安·马塔\\n>>>json.dumps(dic...      5   \n",
       "\n",
       "                                            document  \\\n",
       "0  wait()과 sleep()의 차이점은 뭔가요  발생하는 문제 및 실행환경 wait...   \n",
       "1    초보 외부 클래스 멤버 변수 사용 질문합니다. 1.헤더에, 사용할 멤버변수가 담...   \n",
       "2  ORM: Sequelize: 다대다 관계 쿼리 안녕하세요.  어떻게 다대다 관계 쿼...   \n",
       "3   에서 숫자가 NaN인지 검사하려면 어떻게해야하죠? ``` parseFloat('g...   \n",
       "4    2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요? ``` >>>dict[...   \n",
       "\n",
       "                                        token_review  \n",
       "0  [wait, (), sleep, (), 차이점, 뭔가, 발생, 문제, 실행, 환경,...  \n",
       "1  [초보, 외부, 클래스, 멤버, 변수, 사용, 질문, 합니다, ., 1, ., 헤더...  \n",
       "2  [ORM, :, Sequelize, :, 다대, 다, 관계, 쿼리, 안녕하세요, ....  \n",
       "3  [숫자, NaN, 인지, 검사, 하려면, 어떻게, 해야하죠, ?, ```, pars...  \n",
       "4  [2.7, 중국어, ,, 특수문자, 인코딩, 방법, 뭔가, ?, ```, >>>, ...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "token_review라는 것을 만들어 준다. \n",
    "한글과 영어 wait()같은것도 잘 문류 하는 것을 볼수있고 \n",
    "2.7같이 파이턴을 나타내주는 중요한 지표가 잘 나타내주는것을 볼수잇다. \n",
    "'''\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python']\n",
      "==================================\n",
      "  DataFrame 관련 질문 드립니다.  에서 간단히 DataFrame의 데이터를 매핑하려고 합니다. 아래와 같이 M과 N DataFrame을 각각 생성하고, ``` import pandas as pd M = { 'x': ['a', 'b', 'c'], 'y': ['1', '2', '3'] } N = { 'i': ['3', '1', '2'] } M = pd.DataFrame(M) N = pd.DataFrame(N) ```  N의 i열의 특정 값과 동일한 값을 M의 y 열에서 찾은 후, 그와 대응하는(그와 같은 행에 있는) 값을 M의 x열에서 찾고 싶습니다. 예를 들어, N['i'][2]값*('2')*와 동일한 값이 M['y'][1]에 있으므로, 이에 대응하는 x열의 값, 즉 M['x'][1]값*('b')*를 찾는 것인데, 개별적으로는 아래와 같이 입력하면 'b'값을 얻을 수 있었습니다.  ``` M['x'][N['i'][2]==M['y']]  ``` 그런데, 이것을 일괄적으로 처리하여 N의 j열에 저장하고 싶은데, 아래와 같이 작성하니 j열 값이 [NaN, a, Nan]으로 표시됩니다. 원하는 것은 [c, a, b]로 표시되는 것입니다. ``` N['j'] = '' N['j'] = N.apply(lambda e: M['x'][e['i'] == M['y']], axis=1) ```  최종적으로 N의 j열에 아래와 같은 값을 저장하는 것이 목적입니다.  | M | - | - | N | - | |---|---|---|---|---| | x | y | | i | j | | a | 1 | | 3 | c | | b | 2 | | 1 | a | | c | 3 | | 2 | b |  어떻게 수정해야 제대로 동작할지 도움 부탁 드리겠습니다. \n"
     ]
    }
   ],
   "source": [
    "num = 99\n",
    "print([dic[y_train[num]]])\n",
    "print(\"==================================\")\n",
    "print(X_train[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.loc[:, 'document'].values\n",
    "y_train = train.loc[:, 'label'].values\n",
    "y_test = test.loc[:,'document'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec 만든는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "TaggedDocument_test = namedtuple('TaggedDocument','words')\n",
    "\n",
    "tagged_train_docs = [TaggedDocument((d), [c])for d, c in train[['token_review', 'label']].values]\n",
    "tagged_test_docs = [TaggedDocument_test(d) for d in test['token_review'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/gensim/models/doc2vec.py:574: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "doc_vectorizer = Doc2Vec(\n",
    "    dm=0,            # PV-DBOW / default 1\n",
    "    dbow_words=1,    # w2v simultaneous with DBOW d2v / default 0\n",
    "    window=8,        # distance between the predicted word and context words\n",
    "    size=300,        # vector size\n",
    "    alpha=0.025,     # learning-rate\n",
    "    seed=1234,\n",
    "    min_count=20,    # ignore with freq lower\n",
    "    min_alpha=0.025, # min learning-rate\n",
    "    workers=cores,   # multi cpu\n",
    "    hs = 1,          # hierarchical softmax / default 0\n",
    "    negative = 10   # negative sampling / default 5\n",
    "    #,stopwords = stopwords\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:46:59,241 : INFO : collecting all words and their counts\n",
      "2020-02-05 08:46:59,242 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-02-05 08:46:59,302 : INFO : collected 32180 word types and 6 unique tags from a corpus of 2591 examples and 531964 words\n",
      "2020-02-05 08:46:59,302 : INFO : Loading a fresh vocabulary\n",
      "2020-02-05 08:46:59,313 : INFO : effective_min_count=20 retains 2565 unique words (7% of original 32180, drops 29615)\n",
      "2020-02-05 08:46:59,314 : INFO : effective_min_count=20 leaves 444175 word corpus (83% of original 531964, drops 87789)\n",
      "2020-02-05 08:46:59,321 : INFO : deleting the raw counts dictionary of 32180 items\n",
      "2020-02-05 08:46:59,322 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2020-02-05 08:46:59,322 : INFO : downsampling leaves estimated 323935 word corpus (72.9% of prior 444175)\n",
      "2020-02-05 08:46:59,324 : INFO : constructing a huffman tree from 2565 words\n",
      "2020-02-05 08:46:59,369 : INFO : built huffman tree with maximum node depth 14\n",
      "2020-02-05 08:46:59,373 : INFO : estimated required memory for 2565 words and 300 dimensions: 11036700 bytes\n",
      "2020-02-05 08:46:59,373 : INFO : resetting layer weights\n",
      "/home/jake/venv/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "2020-02-05 08:46:59,741 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:47:01,619 : INFO : EPOCH 1 - PROGRESS: at 1.70% examples, 2600 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:02,753 : INFO : EPOCH 1 - PROGRESS: at 32.03% examples, 34336 words/s, in_qsize 39, out_qsize 0\n",
      "2020-02-05 08:47:03,362 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:03,541 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:03,548 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:03,577 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:03,718 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:03,755 : INFO : EPOCH 1 - PROGRESS: at 58.20% examples, 45439 words/s, in_qsize 26, out_qsize 1\n",
      "2020-02-05 08:47:03,758 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:03,880 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:03,936 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:03,951 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:03,978 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:04,063 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:04,091 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:04,121 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:04,183 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:04,283 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:04,296 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:04,344 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:04,347 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:04,406 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:04,441 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:04,447 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:04,449 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:04,490 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:04,506 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:04,525 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:04,603 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:04,636 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:04,648 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:04,650 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:04,674 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:04,735 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:04,746 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:04,747 : INFO : EPOCH - 1 : training on 531964 raw words (326319 effective words) took 5.0s, 65459 effective words/s\n",
      "2020-02-05 08:47:06,673 : INFO : EPOCH 2 - PROGRESS: at 1.43% examples, 2128 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:07,671 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:07,684 : INFO : EPOCH 2 - PROGRESS: at 50.60% examples, 53727 words/s, in_qsize 30, out_qsize 1\n",
      "2020-02-05 08:47:07,691 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:07,718 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:07,734 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:07,819 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:07,836 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:07,956 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:08,441 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:08,855 : INFO : EPOCH 2 - PROGRESS: at 62.29% examples, 47278 words/s, in_qsize 23, out_qsize 1\n",
      "2020-02-05 08:47:08,856 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:08,906 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:09,092 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:09,096 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:09,099 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:09,232 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:09,293 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:09,310 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:09,319 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:09,366 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:09,373 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:09,375 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:09,376 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:09,391 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:09,409 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:09,432 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:09,446 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:09,450 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:09,473 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:09,474 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:09,492 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:09,524 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:09,524 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:09,525 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:09,526 : INFO : EPOCH - 2 : training on 531964 raw words (326588 effective words) took 4.8s, 68567 effective words/s\n",
      "2020-02-05 08:47:11,707 : INFO : EPOCH 3 - PROGRESS: at 1.24% examples, 2496 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:12,911 : INFO : EPOCH 3 - PROGRESS: at 36.43% examples, 33274 words/s, in_qsize 38, out_qsize 0\n",
      "2020-02-05 08:47:13,556 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:13,572 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:13,590 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:13,662 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:13,679 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:13,697 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:13,722 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:13,744 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:13,971 : INFO : EPOCH 3 - PROGRESS: at 62.41% examples, 44830 words/s, in_qsize 23, out_qsize 1\n",
      "2020-02-05 08:47:13,973 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:13,980 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:14,037 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:14,083 : INFO : worker thread finished; awaiting finish of 20 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:47:14,088 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:14,106 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:14,112 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:14,117 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:14,125 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:14,133 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:14,135 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:14,137 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:14,151 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:14,201 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:14,258 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:14,275 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:14,287 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:14,487 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:14,538 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:14,554 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:14,586 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:14,602 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:14,628 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:14,642 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:14,642 : INFO : EPOCH - 3 : training on 531964 raw words (326854 effective words) took 5.1s, 64082 effective words/s\n",
      "2020-02-05 08:47:16,230 : INFO : EPOCH 4 - PROGRESS: at 1.43% examples, 2585 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:17,238 : INFO : EPOCH 4 - PROGRESS: at 23.23% examples, 29280 words/s, in_qsize 44, out_qsize 0\n",
      "2020-02-05 08:47:18,294 : INFO : EPOCH 4 - PROGRESS: at 39.48% examples, 34965 words/s, in_qsize 35, out_qsize 0\n",
      "2020-02-05 08:47:18,565 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:18,572 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:18,680 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:18,855 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:18,895 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:19,011 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:19,112 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:19,131 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:19,145 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:19,287 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:19,317 : INFO : EPOCH 4 - PROGRESS: at 64.07% examples, 43946 words/s, in_qsize 21, out_qsize 1\n",
      "2020-02-05 08:47:19,318 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:19,384 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:19,430 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:19,431 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:19,523 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:19,540 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:19,567 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:19,568 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:19,606 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:19,729 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:19,797 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:19,837 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:19,907 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:19,947 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:19,956 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:19,960 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:19,971 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:19,974 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:19,986 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:19,992 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:19,998 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:20,016 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:20,016 : INFO : EPOCH - 4 : training on 531964 raw words (326187 effective words) took 5.4s, 60876 effective words/s\n",
      "2020-02-05 08:47:21,910 : INFO : EPOCH 5 - PROGRESS: at 0.81% examples, 2822 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:22,974 : INFO : EPOCH 5 - PROGRESS: at 27.94% examples, 30085 words/s, in_qsize 42, out_qsize 0\n",
      "2020-02-05 08:47:24,017 : INFO : EPOCH 5 - PROGRESS: at 36.47% examples, 28965 words/s, in_qsize 37, out_qsize 0\n",
      "2020-02-05 08:47:24,259 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:24,513 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:24,529 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:24,573 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:24,687 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:24,689 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:24,829 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:24,831 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:24,844 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:24,907 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:24,910 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:24,932 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:24,935 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:25,207 : INFO : EPOCH 5 - PROGRESS: at 66.31% examples, 42558 words/s, in_qsize 18, out_qsize 1\n",
      "2020-02-05 08:47:25,209 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:25,270 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:25,277 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:25,337 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:25,400 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:25,415 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:25,446 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:25,454 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:25,456 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:25,512 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:25,520 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:25,521 : INFO : worker thread finished; awaiting finish of 7 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:47:25,528 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:25,578 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:25,598 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:25,614 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:25,628 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:25,659 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:25,700 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:25,701 : INFO : EPOCH - 5 : training on 531964 raw words (326834 effective words) took 5.7s, 57641 effective words/s\n",
      "2020-02-05 08:47:25,702 : INFO : training on a 2659820 raw words (1632782 effective words) took 26.0s, 62895 effective words/s\n",
      "2020-02-05 08:47:25,702 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-02-05 08:47:25,703 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2020-02-05 08:47:27,781 : INFO : EPOCH 1 - PROGRESS: at 0.96% examples, 2688 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:29,321 : INFO : EPOCH 1 - PROGRESS: at 35.51% examples, 30041 words/s, in_qsize 39, out_qsize 0\n",
      "2020-02-05 08:47:30,333 : INFO : EPOCH 1 - PROGRESS: at 49.29% examples, 33194 words/s, in_qsize 31, out_qsize 1\n",
      "2020-02-05 08:47:30,337 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:30,340 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:30,383 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:30,394 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:30,414 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:30,427 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:30,438 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:30,527 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:30,552 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:30,588 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:30,623 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:30,636 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:30,742 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:30,750 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:30,752 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:30,797 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:30,870 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:30,891 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:30,892 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:30,899 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:30,925 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:31,027 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:31,029 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:31,080 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:31,096 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:31,137 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:31,241 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:31,306 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:31,320 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:31,389 : INFO : EPOCH 1 - PROGRESS: at 95.37% examples, 55359 words/s, in_qsize 2, out_qsize 1\n",
      "2020-02-05 08:47:31,390 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:31,414 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:31,434 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:31,435 : INFO : EPOCH - 1 : training on 531964 raw words (326581 effective words) took 5.7s, 57111 effective words/s\n",
      "2020-02-05 08:47:33,090 : INFO : EPOCH 2 - PROGRESS: at 1.43% examples, 2462 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:34,100 : INFO : EPOCH 2 - PROGRESS: at 25.16% examples, 28253 words/s, in_qsize 44, out_qsize 0\n",
      "2020-02-05 08:47:35,278 : INFO : EPOCH 2 - PROGRESS: at 38.17% examples, 30289 words/s, in_qsize 37, out_qsize 0\n",
      "2020-02-05 08:47:35,975 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:35,980 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:36,022 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:36,081 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:36,118 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:36,153 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:36,226 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:36,241 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:36,254 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:36,301 : INFO : EPOCH 2 - PROGRESS: at 61.40% examples, 41128 words/s, in_qsize 22, out_qsize 1\n",
      "2020-02-05 08:47:36,302 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:36,326 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:36,358 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:36,430 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:36,441 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:36,462 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:36,492 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:36,504 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:36,539 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:36,569 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:36,597 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:36,608 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:36,693 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:36,697 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:36,705 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:36,706 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:36,731 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:36,791 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:36,883 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:36,949 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:36,993 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:37,096 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:37,112 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:37,112 : INFO : EPOCH - 2 : training on 531964 raw words (326599 effective words) took 5.7s, 57677 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:47:39,002 : INFO : EPOCH 3 - PROGRESS: at 1.70% examples, 2577 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:40,067 : INFO : EPOCH 3 - PROGRESS: at 30.53% examples, 31781 words/s, in_qsize 41, out_qsize 0\n",
      "2020-02-05 08:47:41,197 : INFO : EPOCH 3 - PROGRESS: at 37.01% examples, 29251 words/s, in_qsize 36, out_qsize 0\n",
      "2020-02-05 08:47:41,508 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:41,520 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:41,553 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:41,620 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:41,649 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:41,774 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:41,802 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:41,807 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:41,855 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:41,902 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:41,914 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:41,932 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:41,985 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:41,987 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:42,115 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:42,145 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:42,204 : INFO : EPOCH 3 - PROGRESS: at 73.52% examples, 47386 words/s, in_qsize 15, out_qsize 1\n",
      "2020-02-05 08:47:42,206 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:42,242 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:42,264 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:42,315 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:42,343 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:42,356 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:42,359 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:42,364 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:42,378 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:42,447 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:42,557 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:42,597 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:42,617 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:42,619 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:42,702 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:42,714 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:42,715 : INFO : EPOCH - 3 : training on 531964 raw words (326936 effective words) took 5.6s, 58499 effective words/s\n",
      "2020-02-05 08:47:44,245 : INFO : EPOCH 4 - PROGRESS: at 1.43% examples, 2673 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:45,337 : INFO : EPOCH 4 - PROGRESS: at 15.52% examples, 17542 words/s, in_qsize 49, out_qsize 0\n",
      "2020-02-05 08:47:46,356 : INFO : EPOCH 4 - PROGRESS: at 34.35% examples, 30149 words/s, in_qsize 38, out_qsize 0\n",
      "2020-02-05 08:47:46,875 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:46,919 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:46,974 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:47,052 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:47,120 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:47,232 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:47,382 : INFO : EPOCH 4 - PROGRESS: at 58.59% examples, 40073 words/s, in_qsize 25, out_qsize 1\n",
      "2020-02-05 08:47:47,384 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:47,388 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:47,464 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:47,480 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:47,511 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:47,542 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:47,580 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:47,593 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:47,614 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:47,733 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:47,743 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:47,765 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:47,849 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:47,947 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:48,000 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:48,003 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:48,010 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:48,074 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:48,079 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:48,081 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:48,136 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:48,148 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:48,184 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:48,271 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:48,292 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:48,294 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:48,295 : INFO : EPOCH - 4 : training on 531964 raw words (326724 effective words) took 5.6s, 58702 effective words/s\n",
      "2020-02-05 08:47:50,240 : INFO : EPOCH 5 - PROGRESS: at 1.51% examples, 2692 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:51,311 : INFO : EPOCH 5 - PROGRESS: at 28.79% examples, 29298 words/s, in_qsize 42, out_qsize 0\n",
      "2020-02-05 08:47:52,463 : INFO : EPOCH 5 - PROGRESS: at 41.53% examples, 31999 words/s, in_qsize 34, out_qsize 0\n",
      "2020-02-05 08:47:52,657 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:52,713 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:52,740 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:52,840 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:52,848 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:52,858 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:52,862 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:52,985 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:53,075 : INFO : worker thread finished; awaiting finish of 23 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:47:53,079 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:53,131 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:53,134 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:53,161 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:53,208 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:53,253 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:53,275 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:53,382 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:53,388 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:53,408 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:53,540 : INFO : EPOCH 5 - PROGRESS: at 79.00% examples, 48876 words/s, in_qsize 12, out_qsize 1\n",
      "2020-02-05 08:47:53,542 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:53,547 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:53,569 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:53,585 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:53,628 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:53,652 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:53,693 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:53,700 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:53,757 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:53,772 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:53,778 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:53,803 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:53,899 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:53,900 : INFO : EPOCH - 5 : training on 531964 raw words (326677 effective words) took 5.6s, 58440 effective words/s\n",
      "2020-02-05 08:47:53,900 : INFO : training on a 2659820 raw words (1633517 effective words) took 28.2s, 57933 effective words/s\n",
      "2020-02-05 08:47:53,901 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-02-05 08:47:53,902 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2020-02-05 08:47:55,455 : INFO : EPOCH 1 - PROGRESS: at 1.43% examples, 2626 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:47:56,467 : INFO : EPOCH 1 - PROGRESS: at 20.30% examples, 24946 words/s, in_qsize 46, out_qsize 0\n",
      "2020-02-05 08:47:57,483 : INFO : EPOCH 1 - PROGRESS: at 31.69% examples, 27704 words/s, in_qsize 40, out_qsize 0\n",
      "2020-02-05 08:47:58,301 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:47:58,322 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:47:58,377 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:47:58,456 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:47:58,568 : INFO : EPOCH 1 - PROGRESS: at 53.42% examples, 37396 words/s, in_qsize 27, out_qsize 1\n",
      "2020-02-05 08:47:58,570 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:47:58,573 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:47:58,651 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:47:58,699 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:47:58,739 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:47:58,742 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:47:58,753 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:47:58,779 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:47:58,792 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:47:58,797 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:47:58,805 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:47:58,827 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:47:58,884 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:47:58,909 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:47:58,911 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:47:58,956 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:47:58,964 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:47:58,994 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:47:59,039 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:47:59,115 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:47:59,186 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:47:59,265 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:47:59,340 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:47:59,361 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:47:59,396 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:47:59,424 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:47:59,431 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:47:59,468 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:47:59,469 : INFO : EPOCH - 1 : training on 531964 raw words (326555 effective words) took 5.6s, 58806 effective words/s\n",
      "2020-02-05 08:48:01,278 : INFO : EPOCH 2 - PROGRESS: at 1.70% examples, 2716 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:02,324 : INFO : EPOCH 2 - PROGRESS: at 23.54% examples, 27786 words/s, in_qsize 43, out_qsize 0\n",
      "2020-02-05 08:48:03,618 : INFO : EPOCH 2 - PROGRESS: at 42.96% examples, 33506 words/s, in_qsize 33, out_qsize 0\n",
      "2020-02-05 08:48:03,673 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:03,706 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:03,772 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:03,776 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:03,855 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:03,865 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:04,000 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:04,031 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:04,115 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:04,204 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:04,229 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:04,263 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:04,267 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:04,298 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:04,400 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:04,506 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:04,514 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:04,539 : INFO : worker thread finished; awaiting finish of 14 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:48:04,596 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:04,615 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:04,623 : INFO : EPOCH 2 - PROGRESS: at 80.55% examples, 51500 words/s, in_qsize 11, out_qsize 1\n",
      "2020-02-05 08:48:04,624 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:04,631 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:04,637 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:04,657 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:04,708 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:04,858 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:04,880 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:04,908 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:04,914 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:04,942 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:04,954 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:05,006 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:05,006 : INFO : EPOCH - 2 : training on 531964 raw words (326436 effective words) took 5.5s, 59092 effective words/s\n",
      "2020-02-05 08:48:06,806 : INFO : EPOCH 3 - PROGRESS: at 1.70% examples, 2704 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:07,929 : INFO : EPOCH 3 - PROGRESS: at 23.20% examples, 27193 words/s, in_qsize 43, out_qsize 0\n",
      "2020-02-05 08:48:08,935 : INFO : EPOCH 3 - PROGRESS: at 40.25% examples, 33538 words/s, in_qsize 34, out_qsize 0\n",
      "2020-02-05 08:48:09,153 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:09,255 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:09,344 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:09,349 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:09,359 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:09,538 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:09,593 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:09,647 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:09,706 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:09,801 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:09,833 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:09,895 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:09,983 : INFO : EPOCH 3 - PROGRESS: at 63.10% examples, 43266 words/s, in_qsize 19, out_qsize 1\n",
      "2020-02-05 08:48:09,984 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:10,017 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:10,105 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:10,112 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:10,146 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:10,176 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:10,239 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:10,245 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:10,265 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:10,285 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:10,292 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:10,298 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:10,326 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:10,332 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:10,333 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:10,423 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:10,465 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:10,483 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:10,498 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:10,588 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:10,589 : INFO : EPOCH - 3 : training on 531964 raw words (326762 effective words) took 5.6s, 58686 effective words/s\n",
      "2020-02-05 08:48:12,265 : INFO : EPOCH 4 - PROGRESS: at 1.43% examples, 2449 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:13,306 : INFO : EPOCH 4 - PROGRESS: at 22.35% examples, 27987 words/s, in_qsize 44, out_qsize 0\n",
      "2020-02-05 08:48:14,346 : INFO : EPOCH 4 - PROGRESS: at 35.97% examples, 31276 words/s, in_qsize 37, out_qsize 0\n",
      "2020-02-05 08:48:14,778 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:14,874 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:14,936 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:14,950 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:14,983 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:15,110 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:15,135 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:15,152 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:15,157 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:15,166 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:15,240 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:15,331 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:15,372 : INFO : EPOCH 4 - PROGRESS: at 64.72% examples, 44718 words/s, in_qsize 19, out_qsize 1\n",
      "2020-02-05 08:48:15,374 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:15,385 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:15,401 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:15,415 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:15,469 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:15,472 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:15,557 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:15,605 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:15,652 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:15,687 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:15,719 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:15,877 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:15,939 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:15,976 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:15,980 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:16,037 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:16,043 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:16,048 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:48:16,064 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:16,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:16,075 : INFO : EPOCH - 4 : training on 531964 raw words (326240 effective words) took 5.5s, 59625 effective words/s\n",
      "2020-02-05 08:48:17,655 : INFO : EPOCH 5 - PROGRESS: at 1.43% examples, 2591 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:18,655 : INFO : EPOCH 5 - PROGRESS: at 19.41% examples, 23865 words/s, in_qsize 46, out_qsize 0\n",
      "2020-02-05 08:48:19,784 : INFO : EPOCH 5 - PROGRESS: at 41.22% examples, 35704 words/s, in_qsize 33, out_qsize 1\n",
      "2020-02-05 08:48:19,793 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:19,817 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:20,210 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:20,228 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:20,308 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:20,358 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:20,396 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:20,414 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:20,451 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:20,463 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:20,505 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:20,527 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:20,528 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:20,531 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:20,535 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:20,538 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:20,556 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:20,660 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:20,673 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:20,688 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:20,696 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:20,709 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:20,831 : INFO : EPOCH 5 - PROGRESS: at 84.91% examples, 57827 words/s, in_qsize 9, out_qsize 1\n",
      "2020-02-05 08:48:20,832 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:20,834 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:21,072 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:21,083 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:21,114 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:21,123 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:21,137 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:21,149 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:21,156 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:21,184 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:21,185 : INFO : EPOCH - 5 : training on 531964 raw words (326438 effective words) took 5.1s, 64087 effective words/s\n",
      "2020-02-05 08:48:21,186 : INFO : training on a 2659820 raw words (1632431 effective words) took 27.3s, 59831 effective words/s\n",
      "2020-02-05 08:48:21,186 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-02-05 08:48:21,187 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2020-02-05 08:48:22,803 : INFO : EPOCH 1 - PROGRESS: at 1.43% examples, 2524 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:23,904 : INFO : EPOCH 1 - PROGRESS: at 24.86% examples, 27562 words/s, in_qsize 44, out_qsize 0\n",
      "2020-02-05 08:48:25,082 : INFO : EPOCH 1 - PROGRESS: at 44.89% examples, 36254 words/s, in_qsize 33, out_qsize 0\n",
      "2020-02-05 08:48:25,164 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:25,204 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:25,386 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:25,411 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:25,441 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:25,456 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:25,482 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:25,524 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:25,580 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:25,620 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:25,652 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:25,656 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:25,741 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:25,771 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:25,785 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:25,805 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:25,813 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:25,883 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:25,915 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:26,032 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:26,066 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:26,077 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:26,129 : INFO : EPOCH 1 - PROGRESS: at 84.64% examples, 55405 words/s, in_qsize 9, out_qsize 1\n",
      "2020-02-05 08:48:26,130 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:26,147 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:26,160 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:26,232 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:26,296 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:26,316 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:26,318 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:26,318 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:26,340 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:26,401 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:26,402 : INFO : EPOCH - 1 : training on 531964 raw words (326206 effective words) took 5.2s, 62737 effective words/s\n",
      "2020-02-05 08:48:28,277 : INFO : EPOCH 2 - PROGRESS: at 0.81% examples, 2824 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:29,348 : INFO : EPOCH 2 - PROGRESS: at 23.89% examples, 27083 words/s, in_qsize 43, out_qsize 0\n",
      "2020-02-05 08:48:29,879 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:30,032 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:30,247 : INFO : worker thread finished; awaiting finish of 29 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:48:30,450 : INFO : EPOCH 2 - PROGRESS: at 51.60% examples, 40630 words/s, in_qsize 28, out_qsize 1\n",
      "2020-02-05 08:48:30,452 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:30,546 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:30,597 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:30,679 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:30,736 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:30,752 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:30,761 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:30,788 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:30,965 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:30,983 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:31,050 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:31,071 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:31,072 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:31,141 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:31,158 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:31,165 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:31,225 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:31,252 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:31,307 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:31,331 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:31,400 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:31,430 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:31,501 : INFO : EPOCH 2 - PROGRESS: at 89.85% examples, 57361 words/s, in_qsize 6, out_qsize 1\n",
      "2020-02-05 08:48:31,502 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:31,510 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:31,562 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:31,588 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:31,619 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:31,632 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:31,635 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:31,636 : INFO : EPOCH - 2 : training on 531964 raw words (326346 effective words) took 5.2s, 62508 effective words/s\n",
      "2020-02-05 08:48:33,704 : INFO : EPOCH 3 - PROGRESS: at 1.70% examples, 2348 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:34,857 : INFO : EPOCH 3 - PROGRESS: at 33.85% examples, 33055 words/s, in_qsize 39, out_qsize 0\n",
      "2020-02-05 08:48:35,865 : INFO : EPOCH 3 - PROGRESS: at 44.00% examples, 33869 words/s, in_qsize 32, out_qsize 0\n",
      "2020-02-05 08:48:35,884 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:35,936 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:35,957 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:35,961 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:35,978 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:36,039 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:36,061 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:36,066 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:36,105 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:36,112 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:36,127 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:36,137 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:36,166 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:36,214 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:36,216 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:36,250 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:36,281 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:36,286 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:36,320 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:36,358 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:36,368 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:36,411 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:36,427 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:36,483 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:36,571 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:36,640 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:36,667 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:36,754 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:36,777 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:36,800 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:36,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:36,836 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:36,837 : INFO : EPOCH - 3 : training on 531964 raw words (326595 effective words) took 5.2s, 62963 effective words/s\n",
      "2020-02-05 08:48:38,640 : INFO : EPOCH 4 - PROGRESS: at 0.81% examples, 2938 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:39,789 : INFO : EPOCH 4 - PROGRESS: at 27.75% examples, 28418 words/s, in_qsize 43, out_qsize 0\n",
      "2020-02-05 08:48:40,418 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:40,587 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:40,742 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:40,797 : INFO : EPOCH 4 - PROGRESS: at 54.03% examples, 42768 words/s, in_qsize 28, out_qsize 1\n",
      "2020-02-05 08:48:40,800 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:40,842 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:40,892 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:40,940 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:40,967 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:41,084 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:41,115 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:41,164 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:41,314 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:41,346 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:41,458 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:41,512 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:41,619 : INFO : worker thread finished; awaiting finish of 16 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:48:41,646 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:41,658 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:41,684 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:41,694 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:41,787 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:41,801 : INFO : EPOCH 4 - PROGRESS: at 82.94% examples, 54212 words/s, in_qsize 10, out_qsize 1\n",
      "2020-02-05 08:48:41,801 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:41,877 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:41,889 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:41,890 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:41,909 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:41,913 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:41,933 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:41,935 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:41,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:41,942 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:42,003 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:42,004 : INFO : EPOCH - 4 : training on 531964 raw words (326459 effective words) took 5.2s, 63354 effective words/s\n",
      "2020-02-05 08:48:43,827 : INFO : EPOCH 5 - PROGRESS: at 0.81% examples, 2933 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:45,144 : INFO : EPOCH 5 - PROGRESS: at 31.61% examples, 32044 words/s, in_qsize 40, out_qsize 0\n",
      "2020-02-05 08:48:46,038 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:46,180 : INFO : EPOCH 5 - PROGRESS: at 50.44% examples, 37579 words/s, in_qsize 30, out_qsize 1\n",
      "2020-02-05 08:48:46,182 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:46,282 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:46,346 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:46,384 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:46,392 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:46,400 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:46,408 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:46,432 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:46,441 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:46,475 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:46,489 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:46,498 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:46,601 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:46,605 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:46,647 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:46,658 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:46,717 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:46,737 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:46,755 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:46,787 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:46,793 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:46,922 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:46,935 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:46,949 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:46,987 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:47,022 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:47,048 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:47,067 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:47,136 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:47,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:47,208 : INFO : EPOCH 5 - PROGRESS: at 100.00% examples, 62950 words/s, in_qsize 0, out_qsize 1\n",
      "2020-02-05 08:48:47,208 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:47,209 : INFO : EPOCH - 5 : training on 531964 raw words (326700 effective words) took 5.2s, 62933 effective words/s\n",
      "2020-02-05 08:48:47,210 : INFO : training on a 2659820 raw words (1632306 effective words) took 26.0s, 62727 effective words/s\n",
      "2020-02-05 08:48:47,210 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-02-05 08:48:47,211 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2020-02-05 08:48:48,697 : INFO : EPOCH 1 - PROGRESS: at 1.43% examples, 2748 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:49,798 : INFO : EPOCH 1 - PROGRESS: at 19.41% examples, 27933 words/s, in_qsize 44, out_qsize 0\n",
      "2020-02-05 08:48:50,819 : INFO : EPOCH 1 - PROGRESS: at 36.01% examples, 33351 words/s, in_qsize 36, out_qsize 0\n",
      "2020-02-05 08:48:51,196 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:51,257 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:51,393 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:51,475 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:51,513 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:51,534 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:51,568 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:51,618 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:51,640 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:51,645 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:51,653 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:51,661 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:51,697 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:51,735 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:51,739 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:51,761 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:51,769 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:51,796 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:51,901 : INFO : EPOCH 1 - PROGRESS: at 79.20% examples, 54832 words/s, in_qsize 13, out_qsize 1\n",
      "2020-02-05 08:48:51,902 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:51,967 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:51,992 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:52,013 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:52,031 : INFO : worker thread finished; awaiting finish of 9 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:48:52,140 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:52,141 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:52,153 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:52,156 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:52,171 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:52,386 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:52,391 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:52,421 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:52,442 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:52,443 : INFO : EPOCH - 1 : training on 531964 raw words (326326 effective words) took 5.2s, 62578 effective words/s\n",
      "2020-02-05 08:48:54,331 : INFO : EPOCH 2 - PROGRESS: at 1.43% examples, 2159 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:48:55,371 : INFO : EPOCH 2 - PROGRESS: at 25.32% examples, 29495 words/s, in_qsize 42, out_qsize 0\n",
      "2020-02-05 08:48:56,350 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:48:56,388 : INFO : EPOCH 2 - PROGRESS: at 48.48% examples, 39987 words/s, in_qsize 30, out_qsize 1\n",
      "2020-02-05 08:48:56,390 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:48:56,434 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:48:56,582 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:48:56,603 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:48:56,619 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:48:56,632 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:48:56,699 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:48:56,842 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:48:56,921 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:48:56,997 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:48:57,102 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:48:57,129 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:48:57,142 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:48:57,178 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:48:57,186 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:48:57,196 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:48:57,208 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:48:57,262 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:48:57,279 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:48:57,300 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:48:57,310 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:48:57,353 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:48:57,389 : INFO : EPOCH 2 - PROGRESS: at 85.91% examples, 56604 words/s, in_qsize 8, out_qsize 1\n",
      "2020-02-05 08:48:57,389 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:48:57,484 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:48:57,495 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:48:57,509 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:48:57,518 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:48:57,521 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:48:57,531 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:48:57,559 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:48:57,594 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:48:57,594 : INFO : EPOCH - 2 : training on 531964 raw words (326439 effective words) took 5.1s, 63587 effective words/s\n",
      "2020-02-05 08:48:59,236 : INFO : EPOCH 3 - PROGRESS: at 1.43% examples, 2491 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:00,272 : INFO : EPOCH 3 - PROGRESS: at 20.42% examples, 27431 words/s, in_qsize 44, out_qsize 0\n",
      "2020-02-05 08:49:01,366 : INFO : EPOCH 3 - PROGRESS: at 40.33% examples, 35572 words/s, in_qsize 34, out_qsize 0\n",
      "2020-02-05 08:49:01,704 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:01,711 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:01,786 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:01,808 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:01,817 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:01,876 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:01,943 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:01,955 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:02,021 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:02,039 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:02,066 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:02,081 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:02,088 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:02,110 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:02,161 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:02,165 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:02,225 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:02,257 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:02,335 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:02,420 : INFO : EPOCH 3 - PROGRESS: at 77.96% examples, 53343 words/s, in_qsize 12, out_qsize 1\n",
      "2020-02-05 08:49:02,421 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:02,422 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:02,423 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:02,438 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:02,455 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:02,562 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:02,571 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:02,618 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:02,628 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:02,696 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:02,697 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:02,698 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:02,759 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:02,760 : INFO : EPOCH - 3 : training on 531964 raw words (326723 effective words) took 5.2s, 63420 effective words/s\n",
      "2020-02-05 08:49:04,501 : INFO : EPOCH 4 - PROGRESS: at 1.43% examples, 2334 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:05,538 : INFO : EPOCH 4 - PROGRESS: at 28.83% examples, 33061 words/s, in_qsize 41, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:49:06,657 : INFO : EPOCH 4 - PROGRESS: at 40.80% examples, 33946 words/s, in_qsize 34, out_qsize 0\n",
      "2020-02-05 08:49:06,906 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:07,004 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:07,080 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:07,135 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:07,168 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:07,182 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:07,190 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:07,200 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:07,217 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:07,222 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:07,230 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:07,241 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:07,300 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:07,316 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:07,368 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:07,395 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:07,400 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:07,403 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:07,434 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:07,453 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:07,471 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:07,515 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:07,590 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:07,598 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:07,754 : INFO : EPOCH 4 - PROGRESS: at 86.45% examples, 57310 words/s, in_qsize 7, out_qsize 1\n",
      "2020-02-05 08:49:07,755 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:07,777 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:07,788 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:07,822 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:07,915 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:07,945 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:07,955 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:07,985 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:07,986 : INFO : EPOCH - 4 : training on 531964 raw words (326850 effective words) took 5.2s, 62748 effective words/s\n",
      "2020-02-05 08:49:09,985 : INFO : EPOCH 5 - PROGRESS: at 1.43% examples, 2049 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:11,053 : INFO : EPOCH 5 - PROGRESS: at 35.47% examples, 34642 words/s, in_qsize 39, out_qsize 0\n",
      "2020-02-05 08:49:11,976 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:12,189 : INFO : EPOCH 5 - PROGRESS: at 51.83% examples, 37894 words/s, in_qsize 30, out_qsize 1\n",
      "2020-02-05 08:49:12,193 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:12,224 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:12,248 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:12,340 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:12,379 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:12,469 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:12,475 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:12,484 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:12,517 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:12,524 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:12,620 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:12,625 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:12,635 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:12,675 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:12,801 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:12,880 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:12,911 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:12,912 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:12,912 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:12,937 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:12,947 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:12,973 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:12,986 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:13,008 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:13,009 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:13,021 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:13,070 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:13,119 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:13,122 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:13,140 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:13,218 : INFO : EPOCH 5 - PROGRESS: at 100.00% examples, 62609 words/s, in_qsize 0, out_qsize 1\n",
      "2020-02-05 08:49:13,219 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:13,219 : INFO : EPOCH - 5 : training on 531964 raw words (326613 effective words) took 5.2s, 62595 effective words/s\n",
      "2020-02-05 08:49:13,220 : INFO : training on a 2659820 raw words (1632951 effective words) took 26.0s, 62785 effective words/s\n",
      "2020-02-05 08:49:13,220 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-02-05 08:49:13,221 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2020-02-05 08:49:14,695 : INFO : EPOCH 1 - PROGRESS: at 1.43% examples, 2758 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:15,705 : INFO : EPOCH 1 - PROGRESS: at 17.60% examples, 23147 words/s, in_qsize 47, out_qsize 0\n",
      "2020-02-05 08:49:16,719 : INFO : EPOCH 1 - PROGRESS: at 35.43% examples, 31673 words/s, in_qsize 38, out_qsize 0\n",
      "2020-02-05 08:49:17,061 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:17,105 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:17,241 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:17,337 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:17,381 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:17,651 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:17,667 : INFO : worker thread finished; awaiting finish of 25 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:49:17,672 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:17,679 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:17,688 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:17,767 : INFO : EPOCH 1 - PROGRESS: at 64.49% examples, 46081 words/s, in_qsize 21, out_qsize 1\n",
      "2020-02-05 08:49:17,778 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:17,795 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:17,819 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:17,821 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:17,823 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:17,836 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:17,864 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:17,957 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:18,024 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:18,038 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:18,106 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:18,125 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:18,211 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:18,254 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:18,259 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:18,297 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:18,300 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:18,309 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:18,347 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:18,383 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:18,480 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:18,518 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:18,519 : INFO : EPOCH - 1 : training on 531964 raw words (326518 effective words) took 5.3s, 61828 effective words/s\n",
      "2020-02-05 08:49:20,565 : INFO : EPOCH 2 - PROGRESS: at 0.96% examples, 2732 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:21,586 : INFO : EPOCH 2 - PROGRESS: at 30.34% examples, 31625 words/s, in_qsize 40, out_qsize 0\n",
      "2020-02-05 08:49:22,266 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:22,551 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:22,697 : INFO : EPOCH 2 - PROGRESS: at 50.91% examples, 38924 words/s, in_qsize 29, out_qsize 1\n",
      "2020-02-05 08:49:22,701 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:22,709 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:22,722 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:22,768 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:22,769 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:22,799 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:22,805 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:22,808 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:22,842 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:22,930 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:22,946 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:23,006 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:23,051 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:23,061 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:23,207 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:23,231 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:23,371 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:23,376 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:23,396 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:23,492 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:23,516 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:23,550 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:23,573 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:23,587 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:23,684 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:23,704 : INFO : EPOCH 2 - PROGRESS: at 92.28% examples, 58499 words/s, in_qsize 4, out_qsize 1\n",
      "2020-02-05 08:49:23,705 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:23,754 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:23,784 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:23,793 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:23,816 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:23,817 : INFO : EPOCH - 2 : training on 531964 raw words (326778 effective words) took 5.3s, 61854 effective words/s\n",
      "2020-02-05 08:49:25,786 : INFO : EPOCH 3 - PROGRESS: at 1.51% examples, 2625 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:26,792 : INFO : EPOCH 3 - PROGRESS: at 31.15% examples, 33785 words/s, in_qsize 40, out_qsize 0\n",
      "2020-02-05 08:49:27,370 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:27,708 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:27,752 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:27,852 : INFO : EPOCH 3 - PROGRESS: at 55.46% examples, 42471 words/s, in_qsize 28, out_qsize 1\n",
      "2020-02-05 08:49:27,856 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:27,920 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:27,926 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:27,941 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:28,077 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:28,198 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:28,252 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:28,291 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:28,337 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:28,368 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:28,422 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:28,445 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:28,546 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:28,570 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:28,590 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:28,596 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:28,661 : INFO : worker thread finished; awaiting finish of 12 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:49:28,725 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:28,754 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:28,827 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:28,864 : INFO : EPOCH 3 - PROGRESS: at 83.87% examples, 55631 words/s, in_qsize 8, out_qsize 1\n",
      "2020-02-05 08:49:28,865 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:28,889 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:28,891 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:28,927 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:28,955 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:28,966 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:28,982 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:28,999 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:29,036 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:29,037 : INFO : EPOCH - 3 : training on 531964 raw words (326626 effective words) took 5.2s, 62745 effective words/s\n",
      "2020-02-05 08:49:30,967 : INFO : EPOCH 4 - PROGRESS: at 1.70% examples, 2506 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:31,968 : INFO : EPOCH 4 - PROGRESS: at 28.83% examples, 33581 words/s, in_qsize 40, out_qsize 0\n",
      "2020-02-05 08:49:32,868 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:32,926 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:33,024 : INFO : EPOCH 4 - PROGRESS: at 50.02% examples, 40852 words/s, in_qsize 29, out_qsize 1\n",
      "2020-02-05 08:49:33,026 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:33,168 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:33,186 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:33,234 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:33,236 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:33,246 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:33,308 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:33,382 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:33,400 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:33,448 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:33,521 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:33,539 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:33,636 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:33,650 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:33,655 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:33,702 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:33,788 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:33,804 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:33,840 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:34,005 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:34,026 : INFO : EPOCH 4 - PROGRESS: at 84.10% examples, 54926 words/s, in_qsize 9, out_qsize 1\n",
      "2020-02-05 08:49:34,027 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:34,040 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:34,081 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:34,116 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:34,131 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:34,139 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:34,149 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:34,160 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:34,211 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:34,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:34,271 : INFO : EPOCH - 4 : training on 531964 raw words (326320 effective words) took 5.2s, 62544 effective words/s\n",
      "2020-02-05 08:49:35,763 : INFO : EPOCH 5 - PROGRESS: at 1.43% examples, 2748 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:37,238 : INFO : EPOCH 5 - PROGRESS: at 30.61% examples, 31601 words/s, in_qsize 41, out_qsize 0\n",
      "2020-02-05 08:49:38,257 : INFO : EPOCH 5 - PROGRESS: at 42.26% examples, 33382 words/s, in_qsize 34, out_qsize 0\n",
      "2020-02-05 08:49:38,452 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:38,588 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:38,604 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:38,617 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:38,632 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:38,647 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:38,650 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:38,694 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:38,728 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:38,757 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:38,892 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:38,895 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:38,899 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:38,919 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:38,929 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:38,980 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:39,023 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:39,044 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:39,053 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:39,074 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:39,078 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:39,127 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:39,158 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:39,194 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:39,239 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:39,267 : INFO : EPOCH 5 - PROGRESS: at 88.07% examples, 58446 words/s, in_qsize 6, out_qsize 1\n",
      "2020-02-05 08:49:39,268 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:39,329 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:39,393 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:39,430 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:39,455 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:39,460 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:39,467 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:49:39,468 : INFO : EPOCH - 5 : training on 531964 raw words (326386 effective words) took 5.2s, 62973 effective words/s\n",
      "2020-02-05 08:49:39,468 : INFO : training on a 2659820 raw words (1632628 effective words) took 26.2s, 62202 effective words/s\n",
      "2020-02-05 08:49:39,469 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-02-05 08:49:39,469 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2020-02-05 08:49:41,399 : INFO : EPOCH 1 - PROGRESS: at 1.70% examples, 2549 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:42,409 : INFO : EPOCH 1 - PROGRESS: at 37.40% examples, 39654 words/s, in_qsize 37, out_qsize 0\n",
      "2020-02-05 08:49:43,393 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:43,563 : INFO : EPOCH 1 - PROGRESS: at 48.51% examples, 37577 words/s, in_qsize 30, out_qsize 1\n",
      "2020-02-05 08:49:43,564 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:43,612 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:43,619 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:43,691 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:43,728 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:43,754 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:43,894 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:43,897 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:43,904 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:43,937 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:44,029 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:44,076 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:44,077 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:44,093 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:44,096 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:44,123 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:44,180 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:44,216 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:44,394 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:44,433 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:44,434 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:44,439 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:44,516 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:44,525 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:44,587 : INFO : EPOCH 1 - PROGRESS: at 89.27% examples, 57029 words/s, in_qsize 6, out_qsize 1\n",
      "2020-02-05 08:49:44,588 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:44,606 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:44,639 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:44,648 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:44,657 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:44,675 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:44,676 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:44,676 : INFO : EPOCH - 1 : training on 531964 raw words (326398 effective words) took 5.2s, 62881 effective words/s\n",
      "2020-02-05 08:49:46,097 : INFO : EPOCH 2 - PROGRESS: at 1.43% examples, 2879 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:47,128 : INFO : EPOCH 2 - PROGRESS: at 18.22% examples, 24903 words/s, in_qsize 46, out_qsize 0\n",
      "2020-02-05 08:49:48,182 : INFO : EPOCH 2 - PROGRESS: at 36.67% examples, 32994 words/s, in_qsize 37, out_qsize 0\n",
      "2020-02-05 08:49:48,890 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:48,895 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:48,947 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:48,956 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:48,996 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:49,021 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:49,046 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:49,077 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:49,089 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:49,092 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:49,103 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:49,190 : INFO : EPOCH 2 - PROGRESS: at 65.46% examples, 47122 words/s, in_qsize 20, out_qsize 1\n",
      "2020-02-05 08:49:49,192 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:49,217 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:49,269 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:49,283 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:49,288 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:49,314 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:49,343 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:49,358 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:49,372 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:49,387 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:49,434 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:49,541 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:49,580 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:49,605 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:49,750 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:49,767 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:49,773 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:49,813 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:49,852 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:49,888 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:49,899 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:49,900 : INFO : EPOCH - 2 : training on 531964 raw words (326405 effective words) took 5.2s, 62704 effective words/s\n",
      "2020-02-05 08:49:51,749 : INFO : EPOCH 3 - PROGRESS: at 1.43% examples, 2200 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:52,822 : INFO : EPOCH 3 - PROGRESS: at 26.13% examples, 27629 words/s, in_qsize 43, out_qsize 0\n",
      "2020-02-05 08:49:53,590 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:53,684 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:53,728 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:54,114 : INFO : EPOCH 3 - PROGRESS: at 53.18% examples, 40316 words/s, in_qsize 28, out_qsize 1\n",
      "2020-02-05 08:49:54,117 : INFO : worker thread finished; awaiting finish of 28 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:49:54,145 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:54,308 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:54,319 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:54,353 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:54,415 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:54,450 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:54,461 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:54,535 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:54,569 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:54,571 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:54,669 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:54,710 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:54,722 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:54,741 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:54,762 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:49:54,836 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:49:54,886 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:49:54,906 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:49:54,917 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:49:54,928 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:49:54,970 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:49:54,996 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:49:55,058 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:49:55,111 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:49:55,132 : INFO : EPOCH 3 - PROGRESS: at 94.60% examples, 59289 words/s, in_qsize 3, out_qsize 1\n",
      "2020-02-05 08:49:55,133 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:49:55,143 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:49:55,174 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:49:55,178 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:49:55,179 : INFO : EPOCH - 3 : training on 531964 raw words (326627 effective words) took 5.3s, 62079 effective words/s\n",
      "2020-02-05 08:49:56,648 : INFO : EPOCH 4 - PROGRESS: at 1.43% examples, 2767 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:49:57,668 : INFO : EPOCH 4 - PROGRESS: at 18.41% examples, 22805 words/s, in_qsize 47, out_qsize 0\n",
      "2020-02-05 08:49:58,680 : INFO : EPOCH 4 - PROGRESS: at 43.30% examples, 38474 words/s, in_qsize 34, out_qsize 0\n",
      "2020-02-05 08:49:58,908 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:49:58,919 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:49:59,195 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:49:59,381 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:49:59,383 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:49:59,386 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:49:59,470 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:49:59,488 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:49:59,534 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:49:59,586 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:49:59,614 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:49:59,626 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:49:59,628 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:49:59,635 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:49:59,721 : INFO : EPOCH 4 - PROGRESS: at 71.75% examples, 50717 words/s, in_qsize 17, out_qsize 1\n",
      "2020-02-05 08:49:59,722 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:49:59,788 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:49:59,832 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:49:59,910 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:49:59,974 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:00,112 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:00,130 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:00,199 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:00,214 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:00,248 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:00,258 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:00,320 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:00,327 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:00,361 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:00,373 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:00,376 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:00,380 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:00,384 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:00,384 : INFO : EPOCH - 4 : training on 531964 raw words (326668 effective words) took 5.2s, 62938 effective words/s\n",
      "2020-02-05 08:50:02,396 : INFO : EPOCH 5 - PROGRESS: at 1.58% examples, 2729 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:03,442 : INFO : EPOCH 5 - PROGRESS: at 33.23% examples, 34833 words/s, in_qsize 39, out_qsize 0\n",
      "2020-02-05 08:50:04,465 : INFO : EPOCH 5 - PROGRESS: at 47.05% examples, 36832 words/s, in_qsize 31, out_qsize 1\n",
      "2020-02-05 08:50:04,468 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:04,472 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:04,567 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:04,591 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:04,635 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:04,701 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:04,772 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:04,844 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:04,885 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:04,903 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:04,916 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:04,923 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:04,953 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:04,969 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:05,061 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:05,075 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:05,091 : INFO : worker thread finished; awaiting finish of 15 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:50:05,128 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:05,130 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:05,131 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:05,174 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:05,198 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:05,210 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:05,266 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:05,358 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:05,494 : INFO : EPOCH 5 - PROGRESS: at 89.39% examples, 57037 words/s, in_qsize 6, out_qsize 1\n",
      "2020-02-05 08:50:05,495 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:05,537 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:05,543 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:05,564 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:05,568 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:05,576 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:05,585 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:05,585 : INFO : EPOCH - 5 : training on 531964 raw words (326288 effective words) took 5.2s, 62880 effective words/s\n",
      "2020-02-05 08:50:05,586 : INFO : training on a 2659820 raw words (1632386 effective words) took 26.1s, 62504 effective words/s\n",
      "2020-02-05 08:50:05,587 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-02-05 08:50:05,587 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2020-02-05 08:50:07,592 : INFO : EPOCH 1 - PROGRESS: at 1.24% examples, 2717 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:08,607 : INFO : EPOCH 1 - PROGRESS: at 30.99% examples, 32644 words/s, in_qsize 40, out_qsize 0\n",
      "2020-02-05 08:50:09,652 : INFO : EPOCH 1 - PROGRESS: at 40.99% examples, 31552 words/s, in_qsize 35, out_qsize 0\n",
      "2020-02-05 08:50:09,756 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:09,782 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:09,884 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:09,908 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:09,910 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:09,917 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:09,919 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:09,982 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:10,025 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:10,061 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:10,099 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:10,107 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:10,138 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:10,160 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:10,208 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:10,259 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:10,283 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:10,311 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:10,344 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:10,369 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:10,373 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:10,384 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:10,409 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:10,452 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:10,565 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:10,594 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:10,619 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:10,774 : INFO : EPOCH 1 - PROGRESS: at 91.51% examples, 58571 words/s, in_qsize 4, out_qsize 1\n",
      "2020-02-05 08:50:10,774 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:10,784 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:10,828 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:10,837 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:10,864 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:10,865 : INFO : EPOCH - 1 : training on 531964 raw words (326366 effective words) took 5.2s, 62188 effective words/s\n",
      "2020-02-05 08:50:12,752 : INFO : EPOCH 2 - PROGRESS: at 1.51% examples, 2763 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:13,774 : INFO : EPOCH 2 - PROGRESS: at 34.04% examples, 34681 words/s, in_qsize 40, out_qsize 0\n",
      "2020-02-05 08:50:14,865 : INFO : EPOCH 2 - PROGRESS: at 48.21% examples, 36547 words/s, in_qsize 32, out_qsize 0\n",
      "2020-02-05 08:50:14,924 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:15,099 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:15,102 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:15,172 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:15,276 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:15,362 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:15,429 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:15,475 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:15,479 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:15,535 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:15,546 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:15,575 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:15,588 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:15,623 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:15,638 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:15,688 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:15,749 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:15,757 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:15,830 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:15,842 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:15,862 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:15,935 : INFO : EPOCH 2 - PROGRESS: at 83.29% examples, 52939 words/s, in_qsize 10, out_qsize 1\n",
      "2020-02-05 08:50:15,937 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:15,963 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:15,989 : INFO : worker thread finished; awaiting finish of 8 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:50:16,011 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:16,054 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:16,060 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:16,060 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:16,086 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:16,107 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:16,129 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:16,136 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:16,136 : INFO : EPOCH - 2 : training on 531964 raw words (326535 effective words) took 5.3s, 62123 effective words/s\n",
      "2020-02-05 08:50:17,953 : INFO : EPOCH 3 - PROGRESS: at 1.70% examples, 2687 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:19,048 : INFO : EPOCH 3 - PROGRESS: at 24.74% examples, 27121 words/s, in_qsize 43, out_qsize 0\n",
      "2020-02-05 08:50:20,185 : INFO : EPOCH 3 - PROGRESS: at 40.29% examples, 31014 words/s, in_qsize 35, out_qsize 0\n",
      "2020-02-05 08:50:20,318 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:20,572 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:20,577 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:20,649 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:20,702 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:20,723 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:20,763 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:20,773 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:20,876 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:20,878 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:20,898 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:20,910 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:20,916 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:20,977 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:20,993 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:20,995 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:21,034 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:21,047 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:21,059 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:21,071 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:21,072 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:21,092 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:21,138 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:21,156 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:21,181 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:21,218 : INFO : EPOCH 3 - PROGRESS: at 89.39% examples, 57397 words/s, in_qsize 6, out_qsize 1\n",
      "2020-02-05 08:50:21,219 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:21,322 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:21,372 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:21,428 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:21,435 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:21,443 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:21,497 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:21,498 : INFO : EPOCH - 3 : training on 531964 raw words (326347 effective words) took 5.3s, 61034 effective words/s\n",
      "2020-02-05 08:50:23,043 : INFO : EPOCH 4 - PROGRESS: at 1.43% examples, 2620 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:24,341 : INFO : EPOCH 4 - PROGRESS: at 29.72% examples, 33298 words/s, in_qsize 41, out_qsize 0\n",
      "2020-02-05 08:50:25,601 : INFO : EPOCH 4 - PROGRESS: at 37.55% examples, 29920 words/s, in_qsize 36, out_qsize 0\n",
      "2020-02-05 08:50:25,809 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:25,855 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:25,859 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:25,876 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:25,923 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:25,925 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:25,965 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:25,981 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:26,177 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:26,180 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:26,183 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:26,207 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:26,254 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:26,298 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:26,305 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:26,331 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:26,333 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:26,348 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:26,357 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:26,408 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:26,412 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:26,418 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:26,421 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:26,441 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:26,583 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:26,635 : INFO : EPOCH 4 - PROGRESS: at 88.07% examples, 56797 words/s, in_qsize 6, out_qsize 1\n",
      "2020-02-05 08:50:26,637 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:26,695 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:26,728 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:26,783 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:26,811 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:26,821 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:26,833 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:26,834 : INFO : EPOCH - 4 : training on 531964 raw words (326253 effective words) took 5.3s, 61293 effective words/s\n",
      "2020-02-05 08:50:28,361 : INFO : EPOCH 5 - PROGRESS: at 1.43% examples, 2671 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:29,556 : INFO : EPOCH 5 - PROGRESS: at 15.05% examples, 16923 words/s, in_qsize 49, out_qsize 0\n",
      "2020-02-05 08:50:30,570 : INFO : EPOCH 5 - PROGRESS: at 46.82% examples, 37589 words/s, in_qsize 33, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:50:30,627 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:30,703 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:30,754 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:30,832 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:31,153 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:31,189 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:31,232 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:31,260 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:31,291 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:31,431 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:31,454 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:31,510 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:31,519 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:31,541 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:31,588 : INFO : EPOCH 5 - PROGRESS: at 71.32% examples, 47930 words/s, in_qsize 17, out_qsize 1\n",
      "2020-02-05 08:50:31,589 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:31,590 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:31,593 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:31,681 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:31,702 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:31,740 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:31,741 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:31,822 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:31,882 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:32,065 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:32,075 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:32,086 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:32,109 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:32,110 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:32,143 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:32,146 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:32,161 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:32,187 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:32,187 : INFO : EPOCH - 5 : training on 531964 raw words (326606 effective words) took 5.3s, 61147 effective words/s\n",
      "2020-02-05 08:50:32,188 : INFO : training on a 2659820 raw words (1632107 effective words) took 26.6s, 61358 effective words/s\n",
      "2020-02-05 08:50:32,188 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-02-05 08:50:32,189 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2020-02-05 08:50:34,070 : INFO : EPOCH 1 - PROGRESS: at 1.43% examples, 2171 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:35,276 : INFO : EPOCH 1 - PROGRESS: at 30.53% examples, 29866 words/s, in_qsize 41, out_qsize 0\n",
      "2020-02-05 08:50:36,308 : INFO : EPOCH 1 - PROGRESS: at 45.23% examples, 32427 words/s, in_qsize 34, out_qsize 0\n",
      "2020-02-05 08:50:36,425 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:36,434 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:36,534 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:36,538 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:36,646 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:36,656 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:36,676 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:36,685 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:36,755 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:36,778 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:36,794 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:36,854 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:36,868 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:36,876 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:36,891 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:36,938 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:37,053 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:37,097 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:37,147 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:37,203 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:37,224 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:37,246 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:37,346 : INFO : EPOCH 1 - PROGRESS: at 84.45% examples, 53722 words/s, in_qsize 9, out_qsize 1\n",
      "2020-02-05 08:50:37,347 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:37,348 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:37,380 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:37,384 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:37,400 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:37,515 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:37,547 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:37,578 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:37,586 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:37,610 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:37,611 : INFO : EPOCH - 1 : training on 531964 raw words (326539 effective words) took 5.4s, 60401 effective words/s\n",
      "2020-02-05 08:50:39,104 : INFO : EPOCH 2 - PROGRESS: at 1.43% examples, 2748 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:40,170 : INFO : EPOCH 2 - PROGRESS: at 24.31% examples, 31447 words/s, in_qsize 43, out_qsize 0\n",
      "2020-02-05 08:50:41,376 : INFO : EPOCH 2 - PROGRESS: at 43.15% examples, 36965 words/s, in_qsize 33, out_qsize 0\n",
      "2020-02-05 08:50:41,834 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:41,929 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:42,025 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:42,031 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:42,116 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:42,149 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:42,177 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:42,204 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:42,250 : INFO : worker thread finished; awaiting finish of 23 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:50:42,283 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:42,311 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:42,402 : INFO : EPOCH 2 - PROGRESS: at 66.07% examples, 44954 words/s, in_qsize 20, out_qsize 1\n",
      "2020-02-05 08:50:42,404 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:42,452 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:42,466 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:42,484 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:42,512 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:42,530 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:42,541 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:42,559 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:42,578 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:42,639 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:42,647 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:42,672 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:42,720 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:42,745 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:42,746 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:42,780 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:42,825 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:42,871 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:42,927 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:42,948 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:42,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:42,989 : INFO : EPOCH - 2 : training on 531964 raw words (326365 effective words) took 5.4s, 60879 effective words/s\n",
      "2020-02-05 08:50:44,699 : INFO : EPOCH 3 - PROGRESS: at 1.43% examples, 2395 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:45,829 : INFO : EPOCH 3 - PROGRESS: at 29.83% examples, 31222 words/s, in_qsize 42, out_qsize 0\n",
      "2020-02-05 08:50:47,006 : INFO : EPOCH 3 - PROGRESS: at 46.20% examples, 34819 words/s, in_qsize 33, out_qsize 0\n",
      "2020-02-05 08:50:47,146 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:47,224 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:47,255 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:47,286 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:47,314 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:47,436 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:47,489 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:47,505 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:47,543 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:47,577 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:47,578 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:47,668 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:47,674 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:47,802 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:47,807 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:47,834 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:47,850 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:47,982 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:48,019 : INFO : EPOCH 3 - PROGRESS: at 76.73% examples, 50247 words/s, in_qsize 13, out_qsize 1\n",
      "2020-02-05 08:50:48,020 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:48,054 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:48,064 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:48,097 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:48,194 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:48,206 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:48,240 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:48,255 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:48,259 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:48,282 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:48,299 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:48,316 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:48,333 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:48,392 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:48,392 : INFO : EPOCH - 3 : training on 531964 raw words (326575 effective words) took 5.4s, 60574 effective words/s\n",
      "2020-02-05 08:50:50,191 : INFO : EPOCH 4 - PROGRESS: at 1.43% examples, 2279 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:52,043 : INFO : EPOCH 4 - PROGRESS: at 29.95% examples, 26940 words/s, in_qsize 40, out_qsize 0\n",
      "2020-02-05 08:50:52,627 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:52,708 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:52,768 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:52,825 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:52,853 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:52,855 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:52,926 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:52,937 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:52,987 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:53,016 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:53,034 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:53,080 : INFO : EPOCH 4 - PROGRESS: at 65.96% examples, 45661 words/s, in_qsize 20, out_qsize 1\n",
      "2020-02-05 08:50:53,081 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:53,109 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:53,117 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:53,124 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:53,186 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:53,202 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:53,211 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:53,232 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:53,255 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:53,268 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:53,289 : INFO : worker thread finished; awaiting finish of 10 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:50:53,295 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:53,360 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:53,432 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:53,643 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:53,650 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:53,664 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:53,694 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:53,718 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:53,752 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:53,753 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:53,753 : INFO : EPOCH - 4 : training on 531964 raw words (326456 effective words) took 5.3s, 61096 effective words/s\n",
      "2020-02-05 08:50:55,758 : INFO : EPOCH 5 - PROGRESS: at 1.51% examples, 2581 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:50:56,778 : INFO : EPOCH 5 - PROGRESS: at 27.87% examples, 30594 words/s, in_qsize 41, out_qsize 0\n",
      "2020-02-05 08:50:57,364 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:50:57,429 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:50:57,492 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:50:57,516 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:50:57,938 : INFO : EPOCH 5 - PROGRESS: at 55.42% examples, 41956 words/s, in_qsize 27, out_qsize 1\n",
      "2020-02-05 08:50:57,940 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:50:57,951 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:50:58,046 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:50:58,063 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:50:58,097 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:50:58,126 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:50:58,215 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:50:58,322 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:50:58,349 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:50:58,354 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:50:58,482 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:50:58,501 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:50:58,506 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:50:58,674 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:50:58,681 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:50:58,779 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:50:58,787 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:50:58,811 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:50:58,850 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:50:58,868 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:50:58,916 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:50:58,982 : INFO : EPOCH 5 - PROGRESS: at 88.46% examples, 55632 words/s, in_qsize 6, out_qsize 1\n",
      "2020-02-05 08:50:58,983 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:50:59,026 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:50:59,042 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:50:59,060 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:50:59,086 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:50:59,092 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:50:59,102 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:50:59,103 : INFO : EPOCH - 5 : training on 531964 raw words (326781 effective words) took 5.3s, 61217 effective words/s\n",
      "2020-02-05 08:50:59,103 : INFO : training on a 2659820 raw words (1632716 effective words) took 26.9s, 60664 effective words/s\n",
      "2020-02-05 08:50:59,103 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n",
      "2020-02-05 08:50:59,104 : INFO : training model with 32 workers on 2565 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 negative=10 window=8\n",
      "2020-02-05 08:51:00,923 : INFO : EPOCH 1 - PROGRESS: at 1.70% examples, 2678 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:51:01,967 : INFO : EPOCH 1 - PROGRESS: at 25.70% examples, 26703 words/s, in_qsize 44, out_qsize 0\n",
      "2020-02-05 08:51:02,948 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:51:03,082 : INFO : EPOCH 1 - PROGRESS: at 51.91% examples, 39967 words/s, in_qsize 30, out_qsize 1\n",
      "2020-02-05 08:51:03,084 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:51:03,151 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:51:03,397 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:51:03,400 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:51:03,554 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:51:03,563 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:51:03,689 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:51:03,696 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:51:03,771 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:51:03,809 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:51:03,833 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:51:03,857 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:51:03,872 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:51:03,890 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:51:03,898 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:51:03,930 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:51:03,953 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:51:04,042 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:51:04,060 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:51:04,072 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:51:04,127 : INFO : EPOCH 1 - PROGRESS: at 83.40% examples, 53439 words/s, in_qsize 10, out_qsize 1\n",
      "2020-02-05 08:51:04,128 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:51:04,136 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:51:04,168 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:51:04,195 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:51:04,263 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:51:04,275 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:51:04,435 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:51:04,450 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:51:04,453 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:51:04,468 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:51:04,483 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:51:04,484 : INFO : EPOCH - 1 : training on 531964 raw words (326427 effective words) took 5.4s, 60825 effective words/s\n",
      "2020-02-05 08:51:06,256 : INFO : EPOCH 2 - PROGRESS: at 1.70% examples, 2761 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:51:07,336 : INFO : EPOCH 2 - PROGRESS: at 29.02% examples, 31256 words/s, in_qsize 42, out_qsize 0\n",
      "2020-02-05 08:51:08,519 : INFO : EPOCH 2 - PROGRESS: at 40.68% examples, 31730 words/s, in_qsize 35, out_qsize 0\n",
      "2020-02-05 08:51:08,821 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:51:08,845 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:51:08,849 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:51:08,908 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:51:08,918 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:51:08,919 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:51:08,931 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:51:08,995 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:51:09,181 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:51:09,231 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:51:09,283 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:51:09,301 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:51:09,315 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:51:09,340 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:51:09,347 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:51:09,349 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:51:09,355 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:51:09,369 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:51:09,376 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:51:09,512 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:51:09,573 : INFO : EPOCH 2 - PROGRESS: at 81.32% examples, 51573 words/s, in_qsize 11, out_qsize 1\n",
      "2020-02-05 08:51:09,574 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:51:09,586 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:51:09,615 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:51:09,643 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:51:09,692 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:51:09,709 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:51:09,785 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:51:09,809 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:51:09,822 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:51:09,830 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:51:09,831 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:51:09,866 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:51:09,867 : INFO : EPOCH - 2 : training on 531964 raw words (326725 effective words) took 5.4s, 60858 effective words/s\n",
      "2020-02-05 08:51:11,406 : INFO : EPOCH 3 - PROGRESS: at 1.43% examples, 2658 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:51:12,580 : INFO : EPOCH 3 - PROGRESS: at 24.20% examples, 28051 words/s, in_qsize 44, out_qsize 0\n",
      "2020-02-05 08:51:13,586 : INFO : EPOCH 3 - PROGRESS: at 39.83% examples, 34694 words/s, in_qsize 35, out_qsize 0\n",
      "2020-02-05 08:51:13,986 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:51:14,104 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:51:14,129 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:51:14,164 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:51:14,261 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:51:14,313 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:51:14,344 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:51:14,359 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:51:14,433 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:51:14,452 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:51:14,597 : INFO : EPOCH 3 - PROGRESS: at 62.49% examples, 43855 words/s, in_qsize 21, out_qsize 1\n",
      "2020-02-05 08:51:14,599 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:51:14,621 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:51:14,644 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:51:14,651 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:51:14,723 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:51:14,746 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:51:14,747 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:51:14,755 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:51:14,815 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:51:14,833 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:51:14,834 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:51:14,849 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:51:14,860 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:51:14,984 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:51:15,037 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:51:15,048 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:51:15,069 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:51:15,078 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:51:15,156 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:51:15,171 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:51:15,232 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:51:15,270 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:51:15,271 : INFO : EPOCH - 3 : training on 531964 raw words (326734 effective words) took 5.4s, 60646 effective words/s\n",
      "2020-02-05 08:51:17,098 : INFO : EPOCH 4 - PROGRESS: at 1.70% examples, 2652 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:51:18,151 : INFO : EPOCH 4 - PROGRESS: at 28.33% examples, 31408 words/s, in_qsize 42, out_qsize 0\n",
      "2020-02-05 08:51:19,285 : INFO : EPOCH 4 - PROGRESS: at 42.61% examples, 33505 words/s, in_qsize 34, out_qsize 0\n",
      "2020-02-05 08:51:19,547 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:51:19,604 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:51:19,631 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:51:19,656 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:51:19,746 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:51:19,747 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:51:19,764 : INFO : worker thread finished; awaiting finish of 25 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:51:19,782 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:51:19,786 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:51:19,851 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:51:19,875 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:51:19,891 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:51:19,901 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:51:19,910 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:51:20,101 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:51:20,151 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:51:20,248 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:51:20,276 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:51:20,291 : INFO : EPOCH 4 - PROGRESS: at 78.08% examples, 51123 words/s, in_qsize 13, out_qsize 1\n",
      "2020-02-05 08:51:20,292 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:51:20,311 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:51:20,328 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:51:20,334 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:51:20,376 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:51:20,388 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:51:20,396 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:51:20,397 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:51:20,421 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:51:20,506 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:51:20,545 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:51:20,622 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:51:20,631 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:51:20,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:51:20,705 : INFO : EPOCH - 4 : training on 531964 raw words (326502 effective words) took 5.4s, 60230 effective words/s\n",
      "2020-02-05 08:51:22,219 : INFO : EPOCH 5 - PROGRESS: at 1.43% examples, 2668 words/s, in_qsize 56, out_qsize 0\n",
      "2020-02-05 08:51:23,222 : INFO : EPOCH 5 - PROGRESS: at 26.09% examples, 32126 words/s, in_qsize 43, out_qsize 0\n",
      "2020-02-05 08:51:24,358 : INFO : EPOCH 5 - PROGRESS: at 34.39% examples, 30188 words/s, in_qsize 38, out_qsize 0\n",
      "2020-02-05 08:51:24,805 : INFO : worker thread finished; awaiting finish of 31 more threads\n",
      "2020-02-05 08:51:24,876 : INFO : worker thread finished; awaiting finish of 30 more threads\n",
      "2020-02-05 08:51:24,894 : INFO : worker thread finished; awaiting finish of 29 more threads\n",
      "2020-02-05 08:51:24,986 : INFO : worker thread finished; awaiting finish of 28 more threads\n",
      "2020-02-05 08:51:25,000 : INFO : worker thread finished; awaiting finish of 27 more threads\n",
      "2020-02-05 08:51:25,019 : INFO : worker thread finished; awaiting finish of 26 more threads\n",
      "2020-02-05 08:51:25,066 : INFO : worker thread finished; awaiting finish of 25 more threads\n",
      "2020-02-05 08:51:25,157 : INFO : worker thread finished; awaiting finish of 24 more threads\n",
      "2020-02-05 08:51:25,160 : INFO : worker thread finished; awaiting finish of 23 more threads\n",
      "2020-02-05 08:51:25,306 : INFO : worker thread finished; awaiting finish of 22 more threads\n",
      "2020-02-05 08:51:25,320 : INFO : worker thread finished; awaiting finish of 21 more threads\n",
      "2020-02-05 08:51:25,357 : INFO : worker thread finished; awaiting finish of 20 more threads\n",
      "2020-02-05 08:51:25,388 : INFO : EPOCH 5 - PROGRESS: at 66.50% examples, 46731 words/s, in_qsize 19, out_qsize 1\n",
      "2020-02-05 08:51:25,389 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2020-02-05 08:51:25,399 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2020-02-05 08:51:25,442 : INFO : worker thread finished; awaiting finish of 17 more threads\n",
      "2020-02-05 08:51:25,521 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2020-02-05 08:51:25,539 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2020-02-05 08:51:25,623 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2020-02-05 08:51:25,659 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2020-02-05 08:51:25,747 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2020-02-05 08:51:25,816 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2020-02-05 08:51:25,842 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2020-02-05 08:51:25,864 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2020-02-05 08:51:25,890 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2020-02-05 08:51:25,899 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-05 08:51:25,966 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-05 08:51:25,969 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-05 08:51:25,988 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-05 08:51:26,026 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-05 08:51:26,039 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-05 08:51:26,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-05 08:51:26,100 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-05 08:51:26,100 : INFO : EPOCH - 5 : training on 531964 raw words (326405 effective words) took 5.4s, 60643 effective words/s\n",
      "2020-02-05 08:51:26,101 : INFO : training on a 2659820 raw words (1632793 effective words) took 27.0s, 60482 effective words/s\n",
      "2020-02-05 08:51:26,101 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During Time: 266.3614172935486\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "doc_vectorizer.build_vocab(tagged_train_docs)\n",
    "print(str(doc_vectorizer))\n",
    "\n",
    "# 벡터 문서 학습\n",
    "\n",
    "start = time()\n",
    "for epoch in range(10):\n",
    "    doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "    doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "    doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay\n",
    "end = time()\n",
    "print(\"During Time: {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:51:26,119 : INFO : saving Doc2Vec object under Doc2vec.model, separately None\n",
      "2020-02-05 08:51:26,201 : INFO : saved Doc2vec.model\n",
      "2020-02-05 08:51:26,202 : INFO : loading Doc2Vec object from Doc2vec.model\n",
      "2020-02-05 08:51:26,264 : INFO : loading vocabulary recursively from Doc2vec.model.vocabulary.* with mmap=None\n",
      "2020-02-05 08:51:26,264 : INFO : loading trainables recursively from Doc2vec.model.trainables.* with mmap=None\n",
      "2020-02-05 08:51:26,265 : INFO : loading wv recursively from Doc2vec.model.wv.* with mmap=None\n",
      "2020-02-05 08:51:26,265 : INFO : loading docvecs recursively from Doc2vec.model.docvecs.* with mmap=None\n",
      "2020-02-05 08:51:26,266 : INFO : loaded Doc2vec.model\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Doc2vec.model'\n",
    "doc_vectorizer.save(model_name)\n",
    "doc_vectorizer = Doc2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2565"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_vectorizer.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wait': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822eb8>,\n",
       " '()': <gensim.models.keyedvectors.Vocab at 0x7fc7d98221d0>,\n",
       " 'sleep': <gensim.models.keyedvectors.Vocab at 0x7fc7d98222b0>,\n",
       " '차이점': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822320>,\n",
       " '뭔가': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822390>,\n",
       " '발생': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822400>,\n",
       " '문제': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822470>,\n",
       " '실행': <gensim.models.keyedvectors.Vocab at 0x7fc7d98224e0>,\n",
       " '환경': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822550>,\n",
       " '초보': <gensim.models.keyedvectors.Vocab at 0x7fc7d98225c0>,\n",
       " '외부': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822668>,\n",
       " '클래스': <gensim.models.keyedvectors.Vocab at 0x7fc7d98226d8>,\n",
       " '멤버': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822748>,\n",
       " '변수': <gensim.models.keyedvectors.Vocab at 0x7fc7d98227b8>,\n",
       " '사용': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822828>,\n",
       " '질문': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822898>,\n",
       " '합니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822908>,\n",
       " '.': <gensim.models.keyedvectors.Vocab at 0x7fc7d98229b0>,\n",
       " '1': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822ba8>,\n",
       " '헤더': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822cc0>,\n",
       " ',': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822d30>,\n",
       " '파일': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822e80>,\n",
       " '예': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822ef0>,\n",
       " '들어': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822f60>,\n",
       " '해당': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822fd0>,\n",
       " '이름': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822080>,\n",
       " '라면': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822710>,\n",
       " '가져와서': <gensim.models.keyedvectors.Vocab at 0x7fc7d98225f8>,\n",
       " '현재': <gensim.models.keyedvectors.Vocab at 0x7fc7d9822be0>,\n",
       " 'cpp': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03240>,\n",
       " '*': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03320>,\n",
       " 'A': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a034e0>,\n",
       " '=': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03588>,\n",
       " 'NULL': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03e80>,\n",
       " ';': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03f98>,\n",
       " '이나': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a038d0>,\n",
       " 'new': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03e48>,\n",
       " '하여': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03f60>,\n",
       " '라는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a032e8>,\n",
       " '객체': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03470>,\n",
       " '만들고': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03860>,\n",
       " '하고자': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03a58>,\n",
       " '리스트': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03d68>,\n",
       " '->': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03c18>,\n",
       " '같은': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a030b8>,\n",
       " '방법': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a030f0>,\n",
       " '저장': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03128>,\n",
       " '불러오는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03160>,\n",
       " '방식': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03198>,\n",
       " '싶은데요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a031d0>,\n",
       " '아무': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03208>,\n",
       " '않고': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03278>,\n",
       " '에는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03358>,\n",
       " '값': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a033c8>,\n",
       " '만': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03400>,\n",
       " '..': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03550>,\n",
       " '그냥': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a035f8>,\n",
       " '줄': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a036d8>,\n",
       " '알았는데': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a037b8>,\n",
       " '하루': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03898>,\n",
       " '...': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a039b0>,\n",
       " '다른': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a039e8>,\n",
       " '화': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03ac8>,\n",
       " '해야': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03b00>,\n",
       " '되는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03b38>,\n",
       " '건지': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03b70>,\n",
       " '아니면': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03ba8>,\n",
       " '수': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03be0>,\n",
       " '있는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03c50>,\n",
       " '있다면': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03cf8>,\n",
       " '알려주세요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03d30>,\n",
       " '고수': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03da0>,\n",
       " '분들': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03eb8>,\n",
       " '답변': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03ef0>,\n",
       " ':': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03f28>,\n",
       " 'Sequelize': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03390>,\n",
       " '다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03080>,\n",
       " '관계': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a032b0>,\n",
       " '쿼리': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03518>,\n",
       " '안녕하세요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a037f0>,\n",
       " '어떻게': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03908>,\n",
       " '해야하나요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03940>,\n",
       " '?': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03dd8>,\n",
       " '`': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03c88>,\n",
       " 'product': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a03630>,\n",
       " '`,': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ae48>,\n",
       " 'category': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2aef0>,\n",
       " '_': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2aba8>,\n",
       " '모델': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a780>,\n",
       " '있다고': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a860>,\n",
       " '아래': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a9b0>,\n",
       " '가지': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a208>,\n",
       " '있습니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a198>,\n",
       " '```': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a518>,\n",
       " '//': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a7f0>,\n",
       " '(': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ab70>,\n",
       " 'models': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a2b0>,\n",
       " '{': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a550>,\n",
       " \"'\": <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a7b8>,\n",
       " \"',\": <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ac88>,\n",
       " 'id': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ae10>,\n",
       " '});': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a630>,\n",
       " '맨': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a9e8>,\n",
       " '처음': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ad68>,\n",
       " '()`': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a358>,\n",
       " '메서드': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2aa20>,\n",
       " '무슨': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a470>,\n",
       " '알려주시면': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ac18>,\n",
       " '감사하겠습니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a1d0>,\n",
       " '숫자': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a048>,\n",
       " '인지': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a0b8>,\n",
       " '검사': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a278>,\n",
       " '하려면': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a320>,\n",
       " '해야하죠': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a400>,\n",
       " \"('\": <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a5c0>,\n",
       " \"')\": <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a6d8>,\n",
       " '==': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a898>,\n",
       " '이렇게': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a908>,\n",
       " '해봤는데': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a940>,\n",
       " 'true': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2aa58>,\n",
       " '로만': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ab38>,\n",
       " '뭐': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ac50>,\n",
       " '인가요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2acc0>,\n",
       " '>>>': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ada0>,\n",
       " 'dict': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ae80>,\n",
       " \"['\": <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2afd0>,\n",
       " 'name': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a8d0>,\n",
       " \"']\": <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a748>,\n",
       " 'json': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a0f0>,\n",
       " 'replace': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2a4a8>,\n",
       " 'u': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a5f8>,\n",
       " '80': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a748>,\n",
       " 'e': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a7b8>,\n",
       " '\\\\\\\\': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a898>,\n",
       " '5': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a908>,\n",
       " 'b': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a978>,\n",
       " '00': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0aa58>,\n",
       " '7': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0aba8>,\n",
       " '9': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ac18>,\n",
       " '6': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ac88>,\n",
       " 'c': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0acf8>,\n",
       " '\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ad68>,\n",
       " 'Player': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0aeb8>,\n",
       " 'format': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0af98>,\n",
       " 'encode': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a278>,\n",
       " '단어': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0aac8>,\n",
       " '인': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ab38>,\n",
       " '코드': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ae48>,\n",
       " '에러': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a080>,\n",
       " '하네요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a0f0>,\n",
       " '아니라': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a1d0>,\n",
       " '가운데': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a320>,\n",
       " '점': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a390>,\n",
       " '같은데': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a4e0>,\n",
       " '혹시': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a550>,\n",
       " '경우': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a630>,\n",
       " '시작': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a710>,\n",
       " '위치': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a780>,\n",
       " '변경': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a4a8>,\n",
       " '하고싶습니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a0b8>,\n",
       " '코딩': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a160>,\n",
       " '중': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a198>,\n",
       " '인데': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a208>,\n",
       " 'def': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a3c8>,\n",
       " '():': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a470>,\n",
       " 'file': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a588>,\n",
       " '경로': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a5c0>,\n",
       " '뭘': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a6a0>,\n",
       " '선택': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a7f0>,\n",
       " '따라서': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a860>,\n",
       " '설정': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a8d0>,\n",
       " 'path': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a9b0>,\n",
       " 'os': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ab00>,\n",
       " ')': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0abe0>,\n",
       " '지정': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0acc0>,\n",
       " '싶습니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ad30>,\n",
       " '웹': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ada0>,\n",
       " '개발': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ae80>,\n",
       " '하나요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0aef0>,\n",
       " '에서는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0af60>,\n",
       " '수정': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0afd0>,\n",
       " '이라': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0aa20>,\n",
       " '개인': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a2b0>,\n",
       " '적': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0ae10>,\n",
       " '공부': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a128>,\n",
       " '하려': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a2e8>,\n",
       " '-': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a0a438>,\n",
       " '보니': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d9978>,\n",
       " '이클립스': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d9b70>,\n",
       " '바로': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d9f60>,\n",
       " '안되고': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d9710>,\n",
       " '하는데요': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d97b8>,\n",
       " '일반': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d9a20>,\n",
       " 'express': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d9b38>,\n",
       " '특정': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d94e0>,\n",
       " '눌렀을': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d9e80>,\n",
       " 'mysql': <gensim.models.keyedvectors.Vocab at 0x7fc7d365b518>,\n",
       " '데이터': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23780>,\n",
       " '후': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23c18>,\n",
       " '페이지': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23048>,\n",
       " '로드': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23240>,\n",
       " '되도록': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23358>,\n",
       " 'main': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b237f0>,\n",
       " 'js': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23b38>,\n",
       " \"('/\": <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23438>,\n",
       " 'count': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b233c8>,\n",
       " 'function': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b235c0>,\n",
       " 'req': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b230b8>,\n",
       " 'res': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23cf8>,\n",
       " '){': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23198>,\n",
       " 'var': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23080>,\n",
       " 'num': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23160>,\n",
       " 'Object': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23278>,\n",
       " 'keys': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23320>,\n",
       " 'body': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23400>,\n",
       " '0': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b234e0>,\n",
       " '];': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b236a0>,\n",
       " 'sql': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23710>,\n",
       " 'select': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b237b8>,\n",
       " 'times': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23898>,\n",
       " 'db': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23908>,\n",
       " 'conn': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23a20>,\n",
       " 'query': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23b00>,\n",
       " '[': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23be0>,\n",
       " 'err': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23d30>,\n",
       " 'rows': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23dd8>,\n",
       " 'console': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23e80>,\n",
       " 'log': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23f28>,\n",
       " ');': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23fd0>,\n",
       " 'status': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23b70>,\n",
       " '500': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23eb8>,\n",
       " ').': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b230f0>,\n",
       " 'send': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b23208>,\n",
       " 'Server': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b232b0>,\n",
       " 'Error': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746668>,\n",
       " \"');\": <gensim.models.keyedvectors.Vocab at 0x7fc7d9746048>,\n",
       " '}': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746128>,\n",
       " 'else': <gensim.models.keyedvectors.Vocab at 0x7fc7d97461d0>,\n",
       " '].': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746278>,\n",
       " \"='\": <gensim.models.keyedvectors.Vocab at 0x7fc7d9746320>,\n",
       " 'update': <gensim.models.keyedvectors.Vocab at 0x7fc7d97463c8>,\n",
       " 'set': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746470>,\n",
       " '})': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746588>,\n",
       " 'output': <gensim.models.keyedvectors.Vocab at 0x7fc7d97465f8>,\n",
       " 'form': <gensim.models.keyedvectors.Vocab at 0x7fc7d97467b8>,\n",
       " 'action': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746860>,\n",
       " 'method': <gensim.models.keyedvectors.Vocab at 0x7fc7d97468d0>,\n",
       " 'post': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746a20>,\n",
       " 'input': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746a90>,\n",
       " 'type': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746b38>,\n",
       " 'submit': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746c88>,\n",
       " 'value': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746da0>,\n",
       " 'onclick': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746e80>,\n",
       " 'window': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746ef0>,\n",
       " 'location': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746f60>,\n",
       " '버튼': <gensim.models.keyedvectors.Vocab at 0x7fc7d9746f98>,\n",
       " '누르면': <gensim.models.keyedvectors.Vocab at 0x7fc7d36471d0>,\n",
       " '되고': <gensim.models.keyedvectors.Vocab at 0x7fc7d3649710>,\n",
       " '출력': <gensim.models.keyedvectors.Vocab at 0x7fc7d36498d0>,\n",
       " '되게': <gensim.models.keyedvectors.Vocab at 0x7fc7d364bef0>,\n",
       " '브라우저': <gensim.models.keyedvectors.Vocab at 0x7fc7d364b0f0>,\n",
       " '하면': <gensim.models.keyedvectors.Vocab at 0x7fc7d364b400>,\n",
       " '제대로': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7048>,\n",
       " '리': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d70f0>,\n",
       " '되는데': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7fd0>,\n",
       " '클릭': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d70b8>,\n",
       " '이벤트': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7208>,\n",
       " '통해': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7390>,\n",
       " '하니': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d74e0>,\n",
       " '되지': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d75c0>,\n",
       " '않습니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7630>,\n",
       " '할까': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7668>,\n",
       " '텍스트': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d78d0>,\n",
       " '차순': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7940>,\n",
       " '혹은': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7a58>,\n",
       " '정리': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7710>,\n",
       " '다시': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7dd8>,\n",
       " '10': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d79e8>,\n",
       " '34': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7b70>,\n",
       " '3': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7748>,\n",
       " '이런': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7da0>,\n",
       " '식': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7f60>,\n",
       " '되어있는': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d72e8>,\n",
       " '학번': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7080>,\n",
       " '성적': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7160>,\n",
       " '기준': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d76d8>,\n",
       " '차': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d72b0>,\n",
       " '순': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7320>,\n",
       " '다음': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7470>,\n",
       " '해야하는데': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7908>,\n",
       " '대해': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7550>,\n",
       " '궁금합니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d77f0>,\n",
       " 'Class': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7860>,\n",
       " 'Dog': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d7ba8>,\n",
       " 'str': <gensim.models.keyedvectors.Vocab at 0x7fc7d97524e0>,\n",
       " '[]': <gensim.models.keyedvectors.Vocab at 0x7fc7d97520f0>,\n",
       " 'B': <gensim.models.keyedvectors.Vocab at 0x7fc7d9752278>,\n",
       " 'append': <gensim.models.keyedvectors.Vocab at 0x7fc7d36538d0>,\n",
       " '왜': <gensim.models.keyedvectors.Vocab at 0x7fc7d36530f0>,\n",
       " '함께': <gensim.models.keyedvectors.Vocab at 0x7fc7d3653d68>,\n",
       " '되나요': <gensim.models.keyedvectors.Vocab at 0x7fc7d3653470>,\n",
       " '사이': <gensim.models.keyedvectors.Vocab at 0x7fc7d36534a8>,\n",
       " '차이': <gensim.models.keyedvectors.Vocab at 0x7fc7d3653c50>,\n",
       " '있나요': <gensim.models.keyedvectors.Vocab at 0x7fc7d3654898>,\n",
       " '??': <gensim.models.keyedvectors.Vocab at 0x7fc7d3654a20>,\n",
       " '순서': <gensim.models.keyedvectors.Vocab at 0x7fc7d3654048>,\n",
       " '오류': <gensim.models.keyedvectors.Vocab at 0x7fc7d36b87f0>,\n",
       " 'include': <gensim.models.keyedvectors.Vocab at 0x7fc7d365a860>,\n",
       " '<': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d81d0>,\n",
       " 'stdio': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d83c8>,\n",
       " 'h': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d84e0>,\n",
       " '>': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d85c0>,\n",
       " 'stdlib': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d8b38>,\n",
       " 'time': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d8320>,\n",
       " 'int': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d8438>,\n",
       " ']': <gensim.models.keyedvectors.Vocab at 0x7fc7d97fb3c8>,\n",
       " '));': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750550>,\n",
       " '++)': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750c50>,\n",
       " '배열': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750f28>,\n",
       " '~': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750c18>,\n",
       " '까지': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750e48>,\n",
       " '난수': <gensim.models.keyedvectors.Vocab at 0x7fc7d97509e8>,\n",
       " '입력': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750b70>,\n",
       " '함': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750ac8>,\n",
       " 'ran': <gensim.models.keyedvectors.Vocab at 0x7fc7d97505f8>,\n",
       " 'rand': <gensim.models.keyedvectors.Vocab at 0x7fc7d97502b0>,\n",
       " '%': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750828>,\n",
       " '+': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750898>,\n",
       " 'sizeof': <gensim.models.keyedvectors.Vocab at 0x7fc7d97506a0>,\n",
       " ')/': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750208>,\n",
       " ')-': <gensim.models.keyedvectors.Vocab at 0x7fc7d97500f0>,\n",
       " 'change': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750278>,\n",
       " '])': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750438>,\n",
       " 'printf': <gensim.models.keyedvectors.Vocab at 0x7fc7d97505c0>,\n",
       " '(\"%': <gensim.models.keyedvectors.Vocab at 0x7fc7d97507b8>,\n",
       " '\",': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750b00>,\n",
       " ']);': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750d30>,\n",
       " 'return': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750eb8>,\n",
       " '순서대로': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750f60>,\n",
       " '정렬': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750fd0>,\n",
       " '하는데': <gensim.models.keyedvectors.Vocab at 0x7fc7d9750748>,\n",
       " 'core': <gensim.models.keyedvectors.Vocab at 0x7fc7d984edd8>,\n",
       " ')\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e4e0>,\n",
       " '함수': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e518>,\n",
       " 'import': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e978>,\n",
       " '설명': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e6a0>,\n",
       " 'control': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e240>,\n",
       " 'result': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e320>,\n",
       " 'run': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e438>,\n",
       " '해결': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e470>,\n",
       " '하기': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e4a8>,\n",
       " '위해': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e860>,\n",
       " 'global': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e9b0>,\n",
       " '전역변수': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ea90>,\n",
       " '만들어': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ec18>,\n",
       " 'app': <gensim.models.keyedvectors.Vocab at 0x7fc7d984eda0>,\n",
       " 'route': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ee80>,\n",
       " '호출': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ef60>,\n",
       " '온': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ef98>,\n",
       " 'subprocess': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e5c0>,\n",
       " '4': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e6d8>,\n",
       " '해서': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ec88>,\n",
       " '않아서': <gensim.models.keyedvectors.Vocab at 0x7fc7d984efd0>,\n",
       " '테스트': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e128>,\n",
       " '안': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e550>,\n",
       " '302': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ec50>,\n",
       " '시도': <gensim.models.keyedvectors.Vocab at 0x7fc7d984eef0>,\n",
       " '여기': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e588>,\n",
       " '할수': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e908>,\n",
       " '있게': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ed30>,\n",
       " '조언': <gensim.models.keyedvectors.Vocab at 0x7fc7d984eb00>,\n",
       " '해': <gensim.models.keyedvectors.Vocab at 0x7fc7d984eb38>,\n",
       " '주시': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e0b8>,\n",
       " '면': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e208>,\n",
       " '하겠습니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e3c8>,\n",
       " 'connection': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e5f8>,\n",
       " 'engine': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ea58>,\n",
       " 'connect': <gensim.models.keyedvectors.Vocab at 0x7fc7d984ecf8>,\n",
       " 'DB': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e080>,\n",
       " '연결': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e630>,\n",
       " 'execute': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e940>,\n",
       " '(\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e7f0>,\n",
       " 'users': <gensim.models.keyedvectors.Vocab at 0x7fc7d984e0f0>,\n",
       " '\")': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867400>,\n",
       " 'render': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867d30>,\n",
       " 'template': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867c88>,\n",
       " 'index': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867e48>,\n",
       " 'html': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867f28>,\n",
       " 'table': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867128>,\n",
       " '홈페이지': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867358>,\n",
       " '정의': <gensim.models.keyedvectors.Vocab at 0x7fc7d98673c8>,\n",
       " '부터': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867518>,\n",
       " 'POST': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867198>,\n",
       " 'request': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867278>,\n",
       " '=\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867438>,\n",
       " 'check': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867588>,\n",
       " 'True': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867668>,\n",
       " 'http': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867748>,\n",
       " '://': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867898>,\n",
       " 'localhost': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867978>,\n",
       " '/': <gensim.models.keyedvectors.Vocab at 0x7fc7d98679e8>,\n",
       " '\">': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867ac8>,\n",
       " 'label': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867ba8>,\n",
       " 'text': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867d68>,\n",
       " '생': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867e10>,\n",
       " '성': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867e80>,\n",
       " 'create': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867f60>,\n",
       " '</': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867080>,\n",
       " '이랑': <gensim.models.keyedvectors.Vocab at 0x7fc7d98670f0>,\n",
       " '주소': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867160>,\n",
       " '죠': <gensim.models.keyedvectors.Vocab at 0x7fc7d98671d0>,\n",
       " '포인터': <gensim.models.keyedvectors.Vocab at 0x7fc7d98672b0>,\n",
       " '다르게': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867320>,\n",
       " '이면': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867390>,\n",
       " '!=': <gensim.models.keyedvectors.Vocab at 0x7fc7d98674e0>,\n",
       " '일까': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867550>,\n",
       " '소스코드': <gensim.models.keyedvectors.Vocab at 0x7fc7d98675c0>,\n",
       " 'char': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867630>,\n",
       " 'array': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867710>,\n",
       " '100': <gensim.models.keyedvectors.Vocab at 0x7fc7d98677f0>,\n",
       " 'string': <gensim.models.keyedvectors.Vocab at 0x7fc7d98678d0>,\n",
       " '\";': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867940>,\n",
       " 'p': <gensim.models.keyedvectors.Vocab at 0x7fc7d98679b0>,\n",
       " '\\\\': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867a90>,\n",
       " 'n': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867b00>,\n",
       " '&': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867b70>,\n",
       " 'pointer': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867c50>,\n",
       " 'continue': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867cc0>,\n",
       " '\");': <gensim.models.keyedvectors.Vocab at 0x7fc7d9867a20>,\n",
       " '();': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da128>,\n",
       " '학생': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da2b0>,\n",
       " '제': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da470>,\n",
       " '(){': <gensim.models.keyedvectors.Vocab at 0x7fc7d97dab38>,\n",
       " 'j': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da240>,\n",
       " '],': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da048>,\n",
       " 'std': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da0f0>,\n",
       " 'float': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da1d0>,\n",
       " 'avg': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da400>,\n",
       " 'scanf': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da630>,\n",
       " '전체': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da6a0>,\n",
       " '++){': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da7f0>,\n",
       " '만큼': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da860>,\n",
       " '각각': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da8d0>,\n",
       " '점수': <gensim.models.keyedvectors.Vocab at 0x7fc7d97da940>,\n",
       " '+=': <gensim.models.keyedvectors.Vocab at 0x7fc7d97daa20>,\n",
       " '평균': <gensim.models.keyedvectors.Vocab at 0x7fc7d97daa90>,\n",
       " 'lf': <gensim.models.keyedvectors.Vocab at 0x7fc7d97dad30>,\n",
       " '컴파일': <gensim.models.keyedvectors.Vocab at 0x7fc7d97dada0>,\n",
       " '하': <gensim.models.keyedvectors.Vocab at 0x7fc7d97daef0>,\n",
       " '종료': <gensim.models.keyedvectors.Vocab at 0x7fc7d97daf60>,\n",
       " '있는데': <gensim.models.keyedvectors.Vocab at 0x7fc7d97dafd0>,\n",
       " '실수': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12a90>,\n",
       " '부분': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12b70>,\n",
       " '있으면': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12c50>,\n",
       " '!': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12dd8>,\n",
       " ']:': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12a58>,\n",
       " 'null': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12ba8>,\n",
       " '예외처리': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12d68>,\n",
       " '법': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12e48>,\n",
       " '보통': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12eb8>,\n",
       " '보면': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12f28>,\n",
       " '보기': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12f98>,\n",
       " '엔': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12080>,\n",
       " '너무': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a120f0>,\n",
       " '더': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12160>,\n",
       " '없을까요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12198>,\n",
       " 'Override': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a121d0>,\n",
       " 'public': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12278>,\n",
       " 'void': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a122e8>,\n",
       " 'actionPerformed': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12320>,\n",
       " 'ActionEvent': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12358>,\n",
       " '확인': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12390>,\n",
       " 'NO': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12400>,\n",
       " 'try': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a124a8>,\n",
       " 'String': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12550>,\n",
       " 'pstmt': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a125c0>,\n",
       " '()){': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12668>,\n",
       " '++': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a126d8>,\n",
       " '+\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a127b8>,\n",
       " 'con': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12828>,\n",
       " 'C': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12860>,\n",
       " 'D': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12940>,\n",
       " 'E': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12978>,\n",
       " 'catch': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12a20>,\n",
       " 'TODO': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12b38>,\n",
       " 'Auto': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12c18>,\n",
       " 'generated': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12c88>,\n",
       " 'block': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12cf8>,\n",
       " 'printStackTrace': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12da0>,\n",
       " '위': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12e10>,\n",
       " '삽입': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12e80>,\n",
       " '사실': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12f60>,\n",
       " '계속': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12fd0>,\n",
       " '고민': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12470>,\n",
       " '\"+': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a128d0>,\n",
       " 'rs': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12ef0>,\n",
       " 'getInt': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a120b8>,\n",
       " 'sum': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12518>,\n",
       " 'JLabel': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12898>,\n",
       " 'setText': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a12710>,\n",
       " 'charAt': <gensim.models.keyedvectors.Vocab at 0x7fc7d366ecc0>,\n",
       " 'close': <gensim.models.keyedvectors.Vocab at 0x7fc7d36e7eb8>,\n",
       " '간단한': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07160>,\n",
       " '형식': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07198>,\n",
       " '프로그램': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b071d0>,\n",
       " '추가': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07208>,\n",
       " '넣어': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07278>,\n",
       " '모르겠어서': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b072e8>,\n",
       " '내용': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07320>,\n",
       " '일단': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07358>,\n",
       " '들어가는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b074a8>,\n",
       " 'next': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07748>,\n",
       " '전부': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07a58>,\n",
       " '할지': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07c18>,\n",
       " '부탁드립니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07d30>,\n",
       " 'arr': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07fd0>,\n",
       " '99': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07f28>,\n",
       " '55': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b070f0>,\n",
       " '};': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b078d0>,\n",
       " '선언': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07e48>,\n",
       " '가정': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07518>,\n",
       " '이라는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b07780>,\n",
       " '그런데': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872cf8>,\n",
       " '어디': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872e48>,\n",
       " '건가': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872e80>,\n",
       " '메모리': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872128>,\n",
       " '상': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872358>,\n",
       " '앞': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872588>,\n",
       " '가요': <gensim.models.keyedvectors.Vocab at 0x7fc7d98727b8>,\n",
       " '주': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872a58>,\n",
       " '소': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872080>,\n",
       " '똑같이': <gensim.models.keyedvectors.Vocab at 0x7fc7d98722b0>,\n",
       " '알': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872550>,\n",
       " '반복': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872860>,\n",
       " '문': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872b00>,\n",
       " '작성': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872c18>,\n",
       " '(\".': <gensim.models.keyedvectors.Vocab at 0x7fc7d9872a20>,\n",
       " 'list': <gensim.models.keyedvectors.Vocab at 0x7fc7da24e048>,\n",
       " 'child': <gensim.models.keyedvectors.Vocab at 0x7fc7da24e3c8>,\n",
       " 'cursor': <gensim.models.keyedvectors.Vocab at 0x7fc7da24e908>,\n",
       " 'li': <gensim.models.keyedvectors.Vocab at 0x7fc7da24e160>,\n",
       " '\").': <gensim.models.keyedvectors.Vocab at 0x7fc7da24e550>,\n",
       " 'hide': <gensim.models.keyedvectors.Vocab at 0x7fc7da24e6a0>,\n",
       " 'show': <gensim.models.keyedvectors.Vocab at 0x7fc7da24e978>,\n",
       " '저': <gensim.models.keyedvectors.Vocab at 0x7fc7da24eb00>,\n",
       " '**': <gensim.models.keyedvectors.Vocab at 0x7fc7da24ed30>,\n",
       " ')**': <gensim.models.keyedvectors.Vocab at 0x7fc7da24e240>,\n",
       " '씩': <gensim.models.keyedvectors.Vocab at 0x7fc7da24ee48>,\n",
       " '벡터': <gensim.models.keyedvectors.Vocab at 0x7fc7da24e588>,\n",
       " '레퍼런스': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2f0f0>,\n",
       " '::': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2f278>,\n",
       " 'vector': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2f438>,\n",
       " 'hello': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2f748>,\n",
       " ';`': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2f8d0>,\n",
       " '같이': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2fa20>,\n",
       " '하려고': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2fc18>,\n",
       " 'error': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2fdd8>,\n",
       " 'reference': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2f898>,\n",
       " '뜹니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2f978>,\n",
       " '써서': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2ff98>,\n",
       " '거': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2f390>,\n",
       " '꼭': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a2fb70>,\n",
       " '검색': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21048>,\n",
       " 'low': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21438>,\n",
       " 'high': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a216d8>,\n",
       " '파라미터': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a219e8>,\n",
       " '재': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21c18>,\n",
       " '구현': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21eb8>,\n",
       " 'x': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21470>,\n",
       " '해주세요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21710>,\n",
       " '\\t': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21b00>,\n",
       " 'mid': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21e10>,\n",
       " '인자': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21080>,\n",
       " '탐색': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21358>,\n",
       " '도움': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21898>,\n",
       " '웹사이트': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a21160>,\n",
       " '만들려고': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d0978>,\n",
       " '만들기': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745048>,\n",
       " '가입': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745208>,\n",
       " '하게': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745358>,\n",
       " '되었습니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745518>,\n",
       " '전': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745748>,\n",
       " '관': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745908>,\n",
       " '원하는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745b00>,\n",
       " '정보': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745cc0>,\n",
       " '언어': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745eb8>,\n",
       " '초보자': <gensim.models.keyedvectors.Vocab at 0x7fc7d9745940>,\n",
       " '이용': <gensim.models.keyedvectors.Vocab at 0x7fc7d99e6048>,\n",
       " '글': <gensim.models.keyedvectors.Vocab at 0x7fc7d99e64a8>,\n",
       " '그래서': <gensim.models.keyedvectors.Vocab at 0x7fc7d99e69b0>,\n",
       " '만드는': <gensim.models.keyedvectors.Vocab at 0x7fc7d99e6c88>,\n",
       " '동영상': <gensim.models.keyedvectors.Vocab at 0x7fc7d99e67b8>,\n",
       " '지': <gensim.models.keyedvectors.Vocab at 0x7fc7d97ef940>,\n",
       " '처럼': <gensim.models.keyedvectors.Vocab at 0x7fc7d97ef550>,\n",
       " '끝': <gensim.models.keyedvectors.Vocab at 0x7fc7d99f4278>,\n",
       " '방향': <gensim.models.keyedvectors.Vocab at 0x7fc7d99f4908>,\n",
       " '각': <gensim.models.keyedvectors.Vocab at 0x7fc7d99f4cf8>,\n",
       " '여': <gensim.models.keyedvectors.Vocab at 0x7fc7d99f4208>,\n",
       " '이기': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a0e48>,\n",
       " '무엇': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a05c0>,\n",
       " '어떤': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a0e10>,\n",
       " '어느': <gensim.models.keyedvectors.Vocab at 0x7fc7d979e860>,\n",
       " '정도': <gensim.models.keyedvectors.Vocab at 0x7fc7d979e240>,\n",
       " '시간': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a320f0>,\n",
       " '필요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a321d0>,\n",
       " '읽어주셔서': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a32550>,\n",
       " '감사합니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a32a20>,\n",
       " 'ArrayList': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a32ef0>,\n",
       " '차이는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a32940>,\n",
       " '좋을까요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a322e8>,\n",
       " '표현': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a32588>,\n",
       " '알고리즘': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a327b8>,\n",
       " '예시': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a32a90>,\n",
       " '이해': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a32eb8>,\n",
       " '드립니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c8cc0>,\n",
       " '![': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c8320>,\n",
       " '이미지': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c8b38>,\n",
       " '][': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b242b0>,\n",
       " '하세요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b244e0>,\n",
       " 'graph': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b24eb8>,\n",
       " '{}': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b24be0>,\n",
       " '[\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b24b00>,\n",
       " 'start': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b24cc0>,\n",
       " '\"]': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b24400>,\n",
       " '{\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b24fd0>,\n",
       " 'fin': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b24a20>,\n",
       " '\":': <gensim.models.keyedvectors.Vocab at 0x7fc7d98400b8>,\n",
       " '노드': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840160>,\n",
       " '가격': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840320>,\n",
       " '무한': <gensim.models.keyedvectors.Vocab at 0x7fc7d98406a0>,\n",
       " 'costs': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840860>,\n",
       " '부모': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840a20>,\n",
       " 'None': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840c18>,\n",
       " '한번': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840dd8>,\n",
       " '처리': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840f98>,\n",
       " '이미': <gensim.models.keyedvectors.Vocab at 0x7fc7d98403c8>,\n",
       " '가장': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840438>,\n",
       " '찾는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840d30>,\n",
       " 'find': <gensim.models.keyedvectors.Vocab at 0x7fc7d9840eb8>,\n",
       " 'cost': <gensim.models.keyedvectors.Vocab at 0x7fc7d98407f0>,\n",
       " 'node': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0748>,\n",
       " '):': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c03c8>,\n",
       " '테이블': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c02b0>,\n",
       " '하나': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0470>,\n",
       " '보다': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0d68>,\n",
       " '않은': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0668>,\n",
       " '일': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c09e8>,\n",
       " '갱신': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0d30>,\n",
       " '아직': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0eb8>,\n",
       " '하지': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0390>,\n",
       " '모든': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0898>,\n",
       " \"{'\": <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0cf8>,\n",
       " '새': <gensim.models.keyedvectors.Vocab at 0x7fc7d99c0f98>,\n",
       " '새로': <gensim.models.keyedvectors.Vocab at 0x7fc7d97d4358>,\n",
       " '초기': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c4278>,\n",
       " '원소': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c4d68>,\n",
       " '대입': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c45c0>,\n",
       " '건': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c4be0>,\n",
       " '이유': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c4e10>,\n",
       " '그리고': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c4f60>,\n",
       " '라고': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c42b0>,\n",
       " '했는데': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c45f8>,\n",
       " '마지막': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c4940>,\n",
       " '또': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a197f0>,\n",
       " '비교': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19a20>,\n",
       " '지금': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a196a0>,\n",
       " '연산자': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19fd0>,\n",
       " '근데': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19048>,\n",
       " '상황': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19ef0>,\n",
       " 'equals': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a192e8>,\n",
       " '했습니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19668>,\n",
       " '언제': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19828>,\n",
       " '안되는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19ba8>,\n",
       " '대한': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19dd8>,\n",
       " '({': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19e80>,\n",
       " 'sub': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19320>,\n",
       " 'color': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a193c8>,\n",
       " '},{': <gensim.models.keyedvectors.Vocab at 0x7fc7d9a19c18>,\n",
       " 'false': <gensim.models.keyedvectors.Vocab at 0x7fc7d97fecf8>,\n",
       " '},': <gensim.models.keyedvectors.Vocab at 0x7fc7d97fe7b8>,\n",
       " '가진': <gensim.models.keyedvectors.Vocab at 0x7fc7d97fe048>,\n",
       " '클라이언트': <gensim.models.keyedvectors.Vocab at 0x7fc7d97fefd0>,\n",
       " '\":\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d97feef0>,\n",
       " '}]': <gensim.models.keyedvectors.Vocab at 0x7fc7d97fe160>,\n",
       " '서버': <gensim.models.keyedvectors.Vocab at 0x7fc7d97fe4e0>,\n",
       " 'item': <gensim.models.keyedvectors.Vocab at 0x7fc7d97fe208>,\n",
       " '받은': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d24e0>,\n",
       " '정확히': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d2780>,\n",
       " '일치': <gensim.models.keyedvectors.Vocab at 0x7fc7d99d2f60>,\n",
       " '리턴': <gensim.models.keyedvectors.Vocab at 0x7fc7d97cef98>,\n",
       " '포함': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c16d8>,\n",
       " '사': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c1748>,\n",
       " 'document': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c13c8>,\n",
       " '감': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c1278>,\n",
       " 'Item': <gensim.models.keyedvectors.Vocab at 0x7fc7d97c14e0>,\n",
       " 'sort': <gensim.models.keyedvectors.Vocab at 0x7fc7d99e5e10>,\n",
       " 'exec': <gensim.models.keyedvectors.Vocab at 0x7fc7d99e5438>,\n",
       " 'data': <gensim.models.keyedvectors.Vocab at 0x7fc7d99e5978>,\n",
       " '되지만': <gensim.models.keyedvectors.Vocab at 0x7fc7d99e5c50>,\n",
       " '형태': <gensim.models.keyedvectors.Vocab at 0x7fc7d99fbd68>,\n",
       " '라': <gensim.models.keyedvectors.Vocab at 0x7fc7d99fb198>,\n",
       " '아무리': <gensim.models.keyedvectors.Vocab at 0x7fc7d99fb080>,\n",
       " '해봐도': <gensim.models.keyedvectors.Vocab at 0x7fc7d99fb4e0>,\n",
       " '비슷한': <gensim.models.keyedvectors.Vocab at 0x7fc7d99fbef0>,\n",
       " '찾을': <gensim.models.keyedvectors.Vocab at 0x7fc7d99fbd30>,\n",
       " '없어': <gensim.models.keyedvectors.Vocab at 0x7fc7d978d438>,\n",
       " '될까': <gensim.models.keyedvectors.Vocab at 0x7fc7d978d128>,\n",
       " '딕셔': <gensim.models.keyedvectors.Vocab at 0x7fc7d978d780>,\n",
       " '너리': <gensim.models.keyedvectors.Vocab at 0x7fc7d978dcc0>,\n",
       " '문장': <gensim.models.keyedvectors.Vocab at 0x7fc7d978dd30>,\n",
       " 'dic': <gensim.models.keyedvectors.Vocab at 0x7fc7d978dba8>,\n",
       " 'H': <gensim.models.keyedvectors.Vocab at 0x7fc7d978d358>,\n",
       " \"':\": <gensim.models.keyedvectors.Vocab at 0x7fc7d978d048>,\n",
       " 'l': <gensim.models.keyedvectors.Vocab at 0x7fc7d978d240>,\n",
       " 'w': <gensim.models.keyedvectors.Vocab at 0x7fc7d978d630>,\n",
       " 'r': <gensim.models.keyedvectors.Vocab at 0x7fc7d978d7f0>,\n",
       " 'Hello': <gensim.models.keyedvectors.Vocab at 0x7fc7d978d978>,\n",
       " 'world': <gensim.models.keyedvectors.Vocab at 0x7fc7d978de10>,\n",
       " '딕셔너리': <gensim.models.keyedvectors.Vocab at 0x7fc7d978df98>,\n",
       " '관련': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794080>,\n",
       " '죄송합니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794390>,\n",
       " 'API': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794198>,\n",
       " 'io': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794c50>,\n",
       " 'IOException': <gensim.models.keyedvectors.Vocab at 0x7fc7d97949e8>,\n",
       " 'class': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794da0>,\n",
       " 'Main': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794f98>,\n",
       " 'static': <gensim.models.keyedvectors.Vocab at 0x7fc7d97946d8>,\n",
       " 'args': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794320>,\n",
       " '[])': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794240>,\n",
       " 'throws': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794b38>,\n",
       " 'results': <gensim.models.keyedvectors.Vocab at 0x7fc7d9794d68>,\n",
       " 'Foo': <gensim.models.keyedvectors.Vocab at 0x7fc7d9797048>,\n",
       " 'System': <gensim.models.keyedvectors.Vocab at 0x7fc7d979db70>,\n",
       " 'println': <gensim.models.keyedvectors.Vocab at 0x7fc7d979d5f8>,\n",
       " '소스': <gensim.models.keyedvectors.Vocab at 0x7fc7d979d240>,\n",
       " '직접': <gensim.models.keyedvectors.Vocab at 0x7fc7d979d518>,\n",
       " '션': <gensim.models.keyedvectors.Vocab at 0x7fc7d979d860>,\n",
       " 'Array': <gensim.models.keyedvectors.Vocab at 0x7fc7d979dc50>,\n",
       " '밑': <gensim.models.keyedvectors.Vocab at 0x7fc7d979d400>,\n",
       " '않는': <gensim.models.keyedvectors.Vocab at 0x7fc7d979d160>,\n",
       " '원래': <gensim.models.keyedvectors.Vocab at 0x7fc7d979d2b0>,\n",
       " '할당': <gensim.models.keyedvectors.Vocab at 0x7fc7d979d7b8>,\n",
       " '없어서': <gensim.models.keyedvectors.Vocab at 0x7fc7d979d6a0>,\n",
       " '에도': <gensim.models.keyedvectors.Vocab at 0x7fc7d978e240>,\n",
       " '표시': <gensim.models.keyedvectors.Vocab at 0x7fc7d978e630>,\n",
       " '되네요': <gensim.models.keyedvectors.Vocab at 0x7fc7d978edd8>,\n",
       " 'length': <gensim.models.keyedvectors.Vocab at 0x7fc7d978e518>,\n",
       " 'Exception': <gensim.models.keyedvectors.Vocab at 0x7fc7d978e198>,\n",
       " 'thread': <gensim.models.keyedvectors.Vocab at 0x7fc7d978e390>,\n",
       " 'lang': <gensim.models.keyedvectors.Vocab at 0x7fc7d978e5f8>,\n",
       " '11': <gensim.models.keyedvectors.Vocab at 0x7fc7d978e860>,\n",
       " '크롤': <gensim.models.keyedvectors.Vocab at 0x7fc7d978e978>,\n",
       " '링': <gensim.models.keyedvectors.Vocab at 0x7fc7d978eb70>,\n",
       " '엑셀': <gensim.models.keyedvectors.Vocab at 0x7fc7d978ed68>,\n",
       " '싶은데': <gensim.models.keyedvectors.Vocab at 0x7fc7d978eef0>,\n",
       " '크': <gensim.models.keyedvectors.Vocab at 0x7fc7d974f0f0>,\n",
       " '롤링': <gensim.models.keyedvectors.Vocab at 0x7fc7d974f390>,\n",
       " '여러': <gensim.models.keyedvectors.Vocab at 0x7fc7d974f668>,\n",
       " '봤는데': <gensim.models.keyedvectors.Vocab at 0x7fc7d974f8d0>,\n",
       " '첫': <gensim.models.keyedvectors.Vocab at 0x7fc7d974fb00>,\n",
       " '번째': <gensim.models.keyedvectors.Vocab at 0x7fc7d974fdd8>,\n",
       " '항목': <gensim.models.keyedvectors.Vocab at 0x7fc7d974ff98>,\n",
       " '이상': <gensim.models.keyedvectors.Vocab at 0x7fc7d974f240>,\n",
       " '않아': <gensim.models.keyedvectors.Vocab at 0x7fc7fd997940>,\n",
       " '참고': <gensim.models.keyedvectors.Vocab at 0x7fc7fd997dd8>,\n",
       " '자료': <gensim.models.keyedvectors.Vocab at 0x7fc7fd997f28>,\n",
       " '활용': <gensim.models.keyedvectors.Vocab at 0x7fc7d978f240>,\n",
       " '싶어요': <gensim.models.keyedvectors.Vocab at 0x7fc7d978fd30>,\n",
       " '!!': <gensim.models.keyedvectors.Vocab at 0x7fc7d978f198>,\n",
       " 'requests': <gensim.models.keyedvectors.Vocab at 0x7fc7d978f2b0>,\n",
       " 'bs': <gensim.models.keyedvectors.Vocab at 0x7fc7d978f400>,\n",
       " 'BeautifulSoup': <gensim.models.keyedvectors.Vocab at 0x7fc7d978f4a8>,\n",
       " 'pandas': <gensim.models.keyedvectors.Vocab at 0x7fc7d978f668>,\n",
       " 'pd': <gensim.models.keyedvectors.Vocab at 0x7fc7d978f7b8>,\n",
       " 'numpy': <gensim.models.keyedvectors.Vocab at 0x7fc7d978f898>,\n",
       " 'np': <gensim.models.keyedvectors.Vocab at 0x7fc7d978fa58>,\n",
       " 'get': <gensim.models.keyedvectors.Vocab at 0x7fc7d978fc18>,\n",
       " 'content': <gensim.models.keyedvectors.Vocab at 0x7fc7d978fe10>,\n",
       " ',\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d978ffd0>,\n",
       " 'parser': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b287b8>,\n",
       " 'div': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b28470>,\n",
       " 'panel': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b28320>,\n",
       " 'title': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b28a20>,\n",
       " 'print': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b28278>,\n",
       " '날짜': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b284e0>,\n",
       " 'date': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b287f0>,\n",
       " 'meta': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b28a90>,\n",
       " 'items': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b28c88>,\n",
       " '18': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b28f28>,\n",
       " '([': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b280f0>,\n",
       " 'DataFrame': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b28128>,\n",
       " 'csv': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b28e10>,\n",
       " 'encoding': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b898>,\n",
       " 'cp': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2ba90>,\n",
       " '윈도우': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2bb38>,\n",
       " '전달': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b588>,\n",
       " 'program': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b9b0>,\n",
       " 'test': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2be48>,\n",
       " 'system': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b630>,\n",
       " 'ex': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b7b8>,\n",
       " '---': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b668>,\n",
       " '시': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b908>,\n",
       " '됩니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b128>,\n",
       " '하지만': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2bd68>,\n",
       " '.(': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2bba8>,\n",
       " 'HTML': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b320>,\n",
       " 'GET': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b518>,\n",
       " '중복': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b2b048>,\n",
       " '제거': <gensim.models.keyedvectors.Vocab at 0x7fc7d97bee10>,\n",
       " '제일': <gensim.models.keyedvectors.Vocab at 0x7fc7d97be048>,\n",
       " '까요': <gensim.models.keyedvectors.Vocab at 0x7fc7d97be0b8>,\n",
       " 'SIZE': <gensim.models.keyedvectors.Vocab at 0x7fc7d97becf8>,\n",
       " 'cout': <gensim.models.keyedvectors.Vocab at 0x7fc7d97be470>,\n",
       " '<<': <gensim.models.keyedvectors.Vocab at 0x7fc7d97be240>,\n",
       " 'Enter': <gensim.models.keyedvectors.Vocab at 0x7fc7d97bec88>,\n",
       " 'size': <gensim.models.keyedvectors.Vocab at 0x7fc7d99db2e8>,\n",
       " 'cin': <gensim.models.keyedvectors.Vocab at 0x7fc7d99dbe80>,\n",
       " '>>': <gensim.models.keyedvectors.Vocab at 0x7fc7d99db400>,\n",
       " 'integer': <gensim.models.keyedvectors.Vocab at 0x7fc7d99db1d0>,\n",
       " 'break': <gensim.models.keyedvectors.Vocab at 0x7fc7d99dbfd0>,\n",
       " '받고': <gensim.models.keyedvectors.Vocab at 0x7fc7d99dbeb8>,\n",
       " '새로운': <gensim.models.keyedvectors.Vocab at 0x7fc7d99db470>,\n",
       " '존재': <gensim.models.keyedvectors.Vocab at 0x7fc7d99dbd30>,\n",
       " '없이': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c940>,\n",
       " '짜': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c208>,\n",
       " '쓰는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c320>,\n",
       " '있을까요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c4a8>,\n",
       " '없는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c668>,\n",
       " '과정': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c828>,\n",
       " '모르겠어요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c978>,\n",
       " '소멸': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1cb70>,\n",
       " '있는데요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1cc88>,\n",
       " 'numbers': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1ce80>,\n",
       " '8': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c0f0>,\n",
       " '[],': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c908>,\n",
       " 'number': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1c5f8>,\n",
       " '[(': <gensim.models.keyedvectors.Vocab at 0x7fc7d9b1cda0>,\n",
       " '나머지': <gensim.models.keyedvectors.Vocab at 0x7fc7d97954a8>,\n",
       " '나오는': <gensim.models.keyedvectors.Vocab at 0x7fc7d9795978>,\n",
       " '요소': <gensim.models.keyedvectors.Vocab at 0x7fc7d9795c18>,\n",
       " '대로': <gensim.models.keyedvectors.Vocab at 0x7fc7d9795b00>,\n",
       " '상태': <gensim.models.keyedvectors.Vocab at 0x7fc7d9795828>,\n",
       " ']`': <gensim.models.keyedvectors.Vocab at 0x7fc7d9795550>,\n",
       " '라이브러리': <gensim.models.keyedvectors.Vocab at 0x7fc7d97957f0>,\n",
       " 'Library': <gensim.models.keyedvectors.Vocab at 0x7fc7d97952e8>,\n",
       " 'jQuery': <gensim.models.keyedvectors.Vocab at 0x7fc7d35e3518>,\n",
       " '자바스크립트': <gensim.models.keyedvectors.Vocab at 0x7fc7d35e3710>,\n",
       " '먼저': <gensim.models.keyedvectors.Vocab at 0x7fc7d35e36a0>,\n",
       " '하는게': <gensim.models.keyedvectors.Vocab at 0x7fc7d35e3550>,\n",
       " '구글링': <gensim.models.keyedvectors.Vocab at 0x7fc7d35e32e8>,\n",
       " '해도': <gensim.models.keyedvectors.Vocab at 0x7fc7d35e3128>,\n",
       " '모르겠네요': <gensim.models.keyedvectors.Vocab at 0x7fc7d35e3160>,\n",
       " 'JSON': <gensim.models.keyedvectors.Vocab at 0x7fc7d35e3668>,\n",
       " '파싱': <gensim.models.keyedvectors.Vocab at 0x7fc7d35e37f0>,\n",
       " 'success': <gensim.models.keyedvectors.Vocab at 0x7fc7d97517b8>,\n",
       " 'message': <gensim.models.keyedvectors.Vocab at 0x7fc7d97516a0>,\n",
       " 'code': <gensim.models.keyedvectors.Vocab at 0x7fc7d9751e10>,\n",
       " '24': <gensim.models.keyedvectors.Vocab at 0x7fc7d9751f98>,\n",
       " 'api': <gensim.models.keyedvectors.Vocab at 0x7fc7d9751630>,\n",
       " '패키지': <gensim.models.keyedvectors.Vocab at 0x7fc7d9751128>,\n",
       " '되는지': <gensim.models.keyedvectors.Vocab at 0x7fc7d9751e80>,\n",
       " '따로': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa668>,\n",
       " '메인': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa6d8>,\n",
       " '추출': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa240>,\n",
       " 'object': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa7b8>,\n",
       " 'JSONObject': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa9b0>,\n",
       " 'toString': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa358>,\n",
       " '());': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa2e8>,\n",
       " '등록': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa588>,\n",
       " '기능': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa898>,\n",
       " 'Data': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aabe0>,\n",
       " 'long': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa550>,\n",
       " 'column': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aaac8>,\n",
       " '길이': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa518>,\n",
       " '같습니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d97aa128>,\n",
       " 'datetime': <gensim.models.keyedvectors.Vocab at 0x7fc7d974eba8>,\n",
       " '변환': <gensim.models.keyedvectors.Vocab at 0x7fc7d974edd8>,\n",
       " '형': <gensim.models.keyedvectors.Vocab at 0x7fc7d974e550>,\n",
       " 'year': <gensim.models.keyedvectors.Vocab at 0x7fc7d974e940>,\n",
       " 'month': <gensim.models.keyedvectors.Vocab at 0x7fc7d974e0b8>,\n",
       " ')`': <gensim.models.keyedvectors.Vocab at 0x7fc7d974e588>,\n",
       " '진수': <gensim.models.keyedvectors.Vocab at 0x7fc7d974ee48>,\n",
       " 'iostream': <gensim.models.keyedvectors.Vocab at 0x7fc7d974e240>,\n",
       " 'using': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a5240>,\n",
       " 'namespace': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a5c88>,\n",
       " 'begin': <gensim.models.keyedvectors.Vocab at 0x7fc7d987e780>,\n",
       " '(),': <gensim.models.keyedvectors.Vocab at 0x7fc7d987e198>,\n",
       " 'end': <gensim.models.keyedvectors.Vocab at 0x7fc7d987e320>,\n",
       " 'cnt': <gensim.models.keyedvectors.Vocab at 0x7fc7d987e5c0>,\n",
       " \"';\": <gensim.models.keyedvectors.Vocab at 0x7fc7d987e8d0>,\n",
       " 'idx': <gensim.models.keyedvectors.Vocab at 0x7fc7d987ec18>,\n",
       " '()-': <gensim.models.keyedvectors.Vocab at 0x7fc7d987eeb8>,\n",
       " '++;': <gensim.models.keyedvectors.Vocab at 0x7fc7d987e3c8>,\n",
       " 'endl': <gensim.models.keyedvectors.Vocab at 0x7fc7d987e630>,\n",
       " '백': <gensim.models.keyedvectors.Vocab at 0x7fc7d987e908>,\n",
       " '안되네요': <gensim.models.keyedvectors.Vocab at 0x7fc7d987eb70>,\n",
       " '랑': <gensim.models.keyedvectors.Vocab at 0x7fc7d987eda0>,\n",
       " '===': <gensim.models.keyedvectors.Vocab at 0x7fc7d987ef60>,\n",
       " '쓰고': <gensim.models.keyedvectors.Vocab at 0x7fc7d987e898>,\n",
       " '사람': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a7c18>,\n",
       " '하면서': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a75f8>,\n",
       " '많이': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a7e10>,\n",
       " '보고': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a70b8>,\n",
       " '역할': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a7eb8>,\n",
       " '하는지': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a7470>,\n",
       " '궁금해서': <gensim.models.keyedvectors.Vocab at 0x7fc7d974d2e8>,\n",
       " 'callback': <gensim.models.keyedvectors.Vocab at 0x7fc7d974d470>,\n",
       " '((': <gensim.models.keyedvectors.Vocab at 0x7fc7d974d668>,\n",
       " '1000': <gensim.models.keyedvectors.Vocab at 0x7fc7d974d978>,\n",
       " '짠': <gensim.models.keyedvectors.Vocab at 0x7fc7d974db38>,\n",
       " '되면': <gensim.models.keyedvectors.Vocab at 0x7fc7d974dc50>,\n",
       " '마다': <gensim.models.keyedvectors.Vocab at 0x7fc7d974dd30>,\n",
       " '이라고': <gensim.models.keyedvectors.Vocab at 0x7fc7d974de80>,\n",
       " '예상': <gensim.models.keyedvectors.Vocab at 0x7fc7d974d0f0>,\n",
       " 'TypeError': <gensim.models.keyedvectors.Vocab at 0x7fc7d974d860>,\n",
       " 'argument': <gensim.models.keyedvectors.Vocab at 0x7fc7d9796160>,\n",
       " '걸까': <gensim.models.keyedvectors.Vocab at 0x7fc7d97962e8>,\n",
       " '설치': <gensim.models.keyedvectors.Vocab at 0x7fc7d9796eb8>,\n",
       " '노트북': <gensim.models.keyedvectors.Vocab at 0x7fc7d9796a20>,\n",
       " '할려고': <gensim.models.keyedvectors.Vocab at 0x7fc7d97969e8>,\n",
       " '인식': <gensim.models.keyedvectors.Vocab at 0x7fc7d9796240>,\n",
       " '뜨네요': <gensim.models.keyedvectors.Vocab at 0x7fc7d9796b70>,\n",
       " '저렇게': <gensim.models.keyedvectors.Vocab at 0x7fc7d97961d0>,\n",
       " '자꾸': <gensim.models.keyedvectors.Vocab at 0x7fc7d974c240>,\n",
       " '그림': <gensim.models.keyedvectors.Vocab at 0x7fc7d974cb38>,\n",
       " '밖에': <gensim.models.keyedvectors.Vocab at 0x7fc7d974cd68>,\n",
       " 'matplotlib': <gensim.models.keyedvectors.Vocab at 0x7fc7d974ce80>,\n",
       " 'plt': <gensim.models.keyedvectors.Vocab at 0x7fc7d974c780>,\n",
       " 'round': <gensim.models.keyedvectors.Vocab at 0x7fc7da246358>,\n",
       " 'center': <gensim.models.keyedvectors.Vocab at 0x7fc7da2466a0>,\n",
       " 'white': <gensim.models.keyedvectors.Vocab at 0x7fc7da246908>,\n",
       " 'subplot': <gensim.models.keyedvectors.Vocab at 0x7fc7da246c18>,\n",
       " 'False': <gensim.models.keyedvectors.Vocab at 0x7fc7da246dd8>,\n",
       " '0.1': <gensim.models.keyedvectors.Vocab at 0x7fc7da246b00>,\n",
       " '),': <gensim.models.keyedvectors.Vocab at 0x7fc7da2466d8>,\n",
       " 'leaf': <gensim.models.keyedvectors.Vocab at 0x7fc7da246f98>,\n",
       " '그래프': <gensim.models.keyedvectors.Vocab at 0x7fc7da246390>,\n",
       " '..?': <gensim.models.keyedvectors.Vocab at 0x7fc7da2468d0>,\n",
       " '업로드': <gensim.models.keyedvectors.Vocab at 0x7fc7da246a90>,\n",
       " '화면': <gensim.models.keyedvectors.Vocab at 0x7fc7da246e80>,\n",
       " '저런': <gensim.models.keyedvectors.Vocab at 0x7fc7da246198>,\n",
       " '나오고': <gensim.models.keyedvectors.Vocab at 0x7fc7d97930b8>,\n",
       " '이동': <gensim.models.keyedvectors.Vocab at 0x7fc7d9793198>,\n",
       " 'model': <gensim.models.keyedvectors.Vocab at 0x7fc7d9793240>,\n",
       " 'image': <gensim.models.keyedvectors.Vocab at 0x7fc7d9793470>,\n",
       " 'Model': <gensim.models.keyedvectors.Vocab at 0x7fc7d9793748>,\n",
       " 'upload': <gensim.models.keyedvectors.Vocab at 0x7fc7d9793860>,\n",
       " 'Y': <gensim.models.keyedvectors.Vocab at 0x7fc7d9793978>,\n",
       " 'forms': <gensim.models.keyedvectors.Vocab at 0x7fc7d9793b38>,\n",
       " 'fields': <gensim.models.keyedvectors.Vocab at 0x7fc7d9793cc0>,\n",
       " \"','\": <gensim.models.keyedvectors.Vocab at 0x7fc7d97931d0>,\n",
       " 'views': <gensim.models.keyedvectors.Vocab at 0x7fc7d979acf8>,\n",
       " 'valid': <gensim.models.keyedvectors.Vocab at 0x7fc7d979a748>,\n",
       " '한글': <gensim.models.keyedvectors.Vocab at 0x7fc7d979a860>,\n",
       " '영어': <gensim.models.keyedvectors.Vocab at 0x7fc7d979af28>,\n",
       " 'names': <gensim.models.keyedvectors.Vocab at 0x7fc7d979a6d8>,\n",
       " '복사': <gensim.models.keyedvectors.Vocab at 0x7fc7d979a198>,\n",
       " 'foo': <gensim.models.keyedvectors.Vocab at 0x7fc7d979afd0>,\n",
       " 'bar': <gensim.models.keyedvectors.Vocab at 0x7fc7d974b080>,\n",
       " '똑같은': <gensim.models.keyedvectors.Vocab at 0x7fc7d974b438>,\n",
       " '하는것': <gensim.models.keyedvectors.Vocab at 0x7fc7d974b710>,\n",
       " '문자열': <gensim.models.keyedvectors.Vocab at 0x7fc7d974bac8>,\n",
       " 'selenium': <gensim.models.keyedvectors.Vocab at 0x7fc7d974bc88>,\n",
       " '웹페이지': <gensim.models.keyedvectors.Vocab at 0x7fc7d974bf28>,\n",
       " 'menu': <gensim.models.keyedvectors.Vocab at 0x7fc7d974b9e8>,\n",
       " 'sb': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a4cc0>,\n",
       " 'utf': <gensim.models.keyedvectors.Vocab at 0x7fc7d97a4748>,\n",
       " 'urllib': <gensim.models.keyedvectors.Vocab at 0x7fc7d979ccc0>,\n",
       " 'urlopen': <gensim.models.keyedvectors.Vocab at 0x7fc7d979ca90>,\n",
       " 'url': <gensim.models.keyedvectors.Vocab at 0x7fc7d979cbe0>,\n",
       " 'read': <gensim.models.keyedvectors.Vocab at 0x7fc7d979cfd0>,\n",
       " 'soup': <gensim.models.keyedvectors.Vocab at 0x7fc7d979c438>,\n",
       " '용': <gensim.models.keyedvectors.Vocab at 0x7fc7d974a160>,\n",
       " '태그': <gensim.models.keyedvectors.Vocab at 0x7fc7d974a240>,\n",
       " '생략': <gensim.models.keyedvectors.Vocab at 0x7fc7d974a358>,\n",
       " '나옵니다': <gensim.models.keyedvectors.Vocab at 0x7fc7d974a6a0>,\n",
       " 'navbar': <gensim.models.keyedvectors.Vocab at 0x7fc7d974a908>,\n",
       " 'header': <gensim.models.keyedvectors.Vocab at 0x7fc7d974aac8>,\n",
       " 'button': <gensim.models.keyedvectors.Vocab at 0x7fc7d974ac88>,\n",
       " 'toggle': <gensim.models.keyedvectors.Vocab at 0x7fc7d974ae80>,\n",
       " 'target': <gensim.models.keyedvectors.Vocab at 0x7fc7da25b240>,\n",
       " 'collapse': <gensim.models.keyedvectors.Vocab at 0x7fc7da25b048>,\n",
       " 'span': <gensim.models.keyedvectors.Vocab at 0x7fc7da25b198>,\n",
       " 'icon': <gensim.models.keyedvectors.Vocab at 0x7fc7da25b320>,\n",
       " '\"></': <gensim.models.keyedvectors.Vocab at 0x7fc7da25b4a8>,\n",
       " 'container': <gensim.models.keyedvectors.Vocab at 0x7fc7da25b668>,\n",
       " 'ul': <gensim.models.keyedvectors.Vocab at 0x7fc7da25b828>,\n",
       " 'nav': <gensim.models.keyedvectors.Vocab at 0x7fc7da25b978>,\n",
       " 'match': <gensim.models.keyedvectors.Vocab at 0x7fc7da25bac8>,\n",
       " '\"><': <gensim.models.keyedvectors.Vocab at 0x7fc7da25bcc0>,\n",
       " 'ng': <gensim.models.keyedvectors.Vocab at 0x7fc7da25be10>,\n",
       " 'click': <gensim.models.keyedvectors.Vocab at 0x7fc7da25bf98>,\n",
       " 'href': <gensim.models.keyedvectors.Vocab at 0x7fc7da25b7f0>,\n",
       " '></': <gensim.models.keyedvectors.Vocab at 0x7fc7d9791f60>,\n",
       " 'right': <gensim.models.keyedvectors.Vocab at 0x7fc7d9791588>,\n",
       " '><': <gensim.models.keyedvectors.Vocab at 0x7fc7d97914e0>,\n",
       " 'view': <gensim.models.keyedvectors.Vocab at 0x7fc7d97916a0>,\n",
       " '=\"\"': <gensim.models.keyedvectors.Vocab at 0x7fc7d9791e10>,\n",
       " 'Process': <gensim.models.keyedvectors.Vocab at 0x7fc7d97912b0>,\n",
       " 'exit': <gensim.models.keyedvectors.Vocab at 0x7fc7d97911d0>,\n",
       " ...}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_vectorizer.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-05 08:51:26,316 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rmi', 0.6273820400238037), ('lang', 0.588934063911438), ('util', 0.5851370096206665), ('reflect', 0.561657190322876), ('invoke', 0.5428824424743652), ('awt', 0.5062268972396851), ('base', 0.46494966745376587), ('sun', 0.46236616373062134), ('Method', 0.4517890214920044), ('Unknown', 0.44239354133605957)]\n"
     ]
    }
   ],
   "source": [
    "print(doc_vectorizer.wv.most_similar('java'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(\"%', 0.6748197078704834), ('n', 0.5772900581359863), ('scanf', 0.5637867450714111), ('%', 0.4926224946975708), ('\",&', 0.4799691140651703), ('lf', 0.4489816427230835), (':\");', 0.4018970727920532), ('(\"\\\\', 0.4018910229206085), ('.\\\\', 0.37859654426574707), ('(&', 0.36244356632232666)]\n"
     ]
    }
   ],
   "source": [
    "print(doc_vectorizer.wv.most_similar('printf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('np', 0.56317538022995), ('matplotlib', 0.4679657816886902), ('pandas', 0.4170475900173187), ('plt', 0.4167183041572571), ('tensorflow', 0.35670551657676697), ('import', 0.34196656942367554), ('cv', 0.3255158066749573), ('행렬', 0.3087981641292572), ('pd', 0.288971483707428), ('xrand', 0.2888769805431366)]\n"
     ]
    }
   ],
   "source": [
    "print(doc_vectorizer.wv.most_similar('numpy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = 2000\n",
    "train_doc=tagged_train_docs[:tr]\n",
    "test_doc = tagged_train_docs[tr:]\n",
    "\n",
    "train_x = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "train_y = [doc.tags[0] for doc in tagged_train_docs]\n",
    "\n",
    "test_x = [doc_vectorizer.infer_vector(doc.words) for doc in test_doc]\n",
    "test_y = [doc.tags[0] for doc in test_doc]\n",
    "test_Y = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = LogisticRegression(random_state=1234)\n",
    "mlp_clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(50,),\n",
    "    max_iter=10,\n",
    "    alpha=1e-4,\n",
    "    solver='sgd',\n",
    "    verbose=10,\n",
    "    tol=1e-4,\n",
    "    random_state=1,\n",
    "    learning_rate_init=.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.50565298\n",
      "Iteration 2, loss = 1.18003737\n",
      "Iteration 3, loss = 0.80978404\n",
      "Iteration 4, loss = 0.56681493\n",
      "Iteration 5, loss = 0.45422070\n",
      "Iteration 6, loss = 0.39529208\n",
      "Iteration 7, loss = 0.35419384\n",
      "Iteration 8, loss = 0.32456318\n",
      "Iteration 9, loss = 0.30068419\n",
      "Iteration 10, loss = 0.27827560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train = 0.918918918918919, Test = 0.8651252408477842\n",
      "Iteration 1, loss = 1.49769959\n",
      "Iteration 2, loss = 1.18009900\n",
      "Iteration 3, loss = 0.80066163\n",
      "Iteration 4, loss = 0.56502219\n",
      "Iteration 5, loss = 0.45390651\n",
      "Iteration 6, loss = 0.38992952\n",
      "Iteration 7, loss = 0.35077862\n",
      "Iteration 8, loss = 0.32096807\n",
      "Iteration 9, loss = 0.29621819\n",
      "Iteration 10, loss = 0.27599410\n",
      "Train = 0.9141341051616015, Test = 0.8474903474903475\n",
      "Iteration 1, loss = 1.50002862\n",
      "Iteration 2, loss = 1.18665615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.81588150\n",
      "Iteration 4, loss = 0.56867029\n",
      "Iteration 5, loss = 0.45016771\n",
      "Iteration 6, loss = 0.38857464\n",
      "Iteration 7, loss = 0.34561082\n",
      "Iteration 8, loss = 0.31728202\n",
      "Iteration 9, loss = 0.28930199\n",
      "Iteration 10, loss = 0.26978264\n",
      "Train = 0.9165460684997588, Test = 0.859073359073359\n",
      "Iteration 1, loss = 1.50416595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.18542414\n",
      "Iteration 3, loss = 0.81223473\n",
      "Iteration 4, loss = 0.56399897\n",
      "Iteration 5, loss = 0.44921684\n",
      "Iteration 6, loss = 0.38577102\n",
      "Iteration 7, loss = 0.34795224\n",
      "Iteration 8, loss = 0.31787735\n",
      "Iteration 9, loss = 0.29262579\n",
      "Iteration 10, loss = 0.27158106\n",
      "Train = 0.9083453931500242, Test = 0.8436293436293436\n",
      "Iteration 1, loss = 1.50374241\n",
      "Iteration 2, loss = 1.17282671\n",
      "Iteration 3, loss = 0.79614954\n",
      "Iteration 4, loss = 0.55605868\n",
      "Iteration 5, loss = 0.44805918\n",
      "Iteration 6, loss = 0.38367709\n",
      "Iteration 7, loss = 0.34597335\n",
      "Iteration 8, loss = 0.31635767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.29161432\n",
      "Iteration 10, loss = 0.27170159\n",
      "Train = 0.9184756391702846, Test = 0.8455598455598455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "X = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "y = [doc.tags[0] for doc in tagged_train_docs]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "for tr, te in skf.split(X, y):\n",
    "    mlp_clf.fit(X[tr], y[tr])\n",
    "    train_score = mlp_clf.score(X[tr], y[tr])\n",
    "    test_score = mlp_clf.score(X[te], y[te])\n",
    "    print(\"Train = {}, Test = {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 480  491  492 ... 2588 2589 2590]\n",
      "Train = 0.9913127413127413, Test = 0.7880539499036608\n",
      "[   0    1    2 ... 2588 2589 2590]\n",
      "Train = 0.9903521466473709, Test = 0.7664092664092664\n",
      "[   0    1    2 ... 2588 2589 2590]\n",
      "Train = 0.9898697539797395, Test = 0.7722007722007722\n",
      "[   0    1    2 ... 2588 2589 2590]\n",
      "Train = 0.9889049686444766, Test = 0.7799227799227799\n",
      "[   0    1    2 ... 2116 2119 2120]\n",
      "Train = 0.989387361312108, Test = 0.7760617760617761\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "#classifier = LogisticRegression(random_state=1234)\n",
    "\n",
    "X = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "y = [doc.tags[0] for doc in tagged_train_docs]\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "for tr, te in skf.split(X, y):\n",
    "    print(tr)\n",
    "    xgb.fit(X[tr], y[tr])\n",
    "    train_score = xgb.score(X[tr], y[tr])\n",
    "    test_score = xgb.score(X[te], y[te])\n",
    "    print(\"Train = {}, Test = {}\".format(train_score, test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skt-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "from kobert.utils import get_tokenizer\n",
    "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
    "\n",
    "from transformers import AdamW\n",
    "from transformers.optimization import WarmupLinearSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_ids = torch.LongTensor([[31, 51, 99], [15, 5, 0]])\n",
    "#input_mask = torch.LongTensor([[1, 1, 1], [1, 1, 0]])\n",
    "#token_type_ids = torch.LongTensor([[0, 0, 1], [0, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, vocab  = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_encoder_layers, pooled_output = model(input_ids, token_type_ids, input_mask)\n",
    "#pooled_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.dropbox.com/s/374ftkec978br3d/ratings_train.txt?dl=1\n",
    "#!wget https://www.dropbox.com/s/977gbwh542gdy94/ratings_test.txt?dl=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\"ratings_train.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)\n",
    "dataset_test = nlp.data.TSVDataset(\"ratings_test.txt?dl=1\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##GPU 사용 시\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "bertmodel, vocab = get_pytorch_kobert_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer()\n",
    "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
    "                 pad, pair):\n",
    "        transform = nlp.data.BERTSentenceTransform(\n",
    "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n",
    "\n",
    "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
    "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.sentences[i] + (self.labels[i], ))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wait()과 sleep()의 차이점은 뭔가요</td>\n",
       "      <td>###발생하는 문제 및 실행환경\\nwait()과 sleep()의 차이점은 뭔가요</td>\n",
       "      <td>3</td>\n",
       "      <td>wait()과 sleep()의 차이점은 뭔가요 ###발생하는 문제 및 실행환경\\nw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$$$ 초보 외부 클래스 멤버 변수 사용 질문합니다.ㅠㅠ</td>\n",
       "      <td>1.헤더에, 사용할 멤버변수가 담긴 헤더 파일이 Include 되어있습니다.\\n예를...</td>\n",
       "      <td>2</td>\n",
       "      <td>$$$ 초보 외부 클래스 멤버 변수 사용 질문합니다.ㅠㅠ 1.헤더에, 사용할 멤버변...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORM: Sequelize: 다대다 관계 쿼리</td>\n",
       "      <td>안녕하세요.\\n\\n어떻게 다대다 관계 쿼리를 해야하나요? 예를들어, `product...</td>\n",
       "      <td>4</td>\n",
       "      <td>ORM: Sequelize: 다대다 관계 쿼리 안녕하세요.\\n\\n어떻게 다대다 관계...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$$$에서 숫자가 NaN인지 검사하려면 어떻게해야하죠?</td>\n",
       "      <td>```\\nparseFloat('geoff') == NaN;\\n\\nparseFloat...</td>\n",
       "      <td>4</td>\n",
       "      <td>$$$에서 숫자가 NaN인지 검사하려면 어떻게해야하죠? ```\\nparseFloat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$$$ 2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요?</td>\n",
       "      <td>```\\n&gt;&gt;&gt;dict['name']\\n胡安·马塔\\n&gt;&gt;&gt;json.dumps(dic...</td>\n",
       "      <td>5</td>\n",
       "      <td>$$$ 2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요? ```\\n&gt;&gt;&gt;di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>$$$ 슬라이드 질문입니다.</td>\n",
       "      <td>안녕하세요.\\n다름이아니라 \\n$$$로 버튼을 클릭하면 \\n오른쪽에서 왼쪽으로 들어...</td>\n",
       "      <td>4</td>\n",
       "      <td>$$$ 슬라이드 질문입니다. 안녕하세요.\\n다름이아니라 \\n$$$로 버튼을 클릭하면...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>$$$ 메인 클래스</td>\n",
       "      <td>프로그램 전체 메인 클래스를 하나 만들고 메인에서 메뉴를 선택하면 세가지 각각 다른...</td>\n",
       "      <td>3</td>\n",
       "      <td>$$$ 메인 클래스 프로그램 전체 메인 클래스를 하나 만들고 메인에서 메뉴를 선택하...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>$$$ sparse matrix 질문합니다!</td>\n",
       "      <td>* sparse matrix: 0이 아닌 값을 가진 원소들을 ordered list...</td>\n",
       "      <td>1</td>\n",
       "      <td>$$$ sparse matrix 질문합니다! * sparse matrix: 0이 아...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>$$$ models 폴더의 depth가 일반적이지 않을 경우 migration하는 법</td>\n",
       "      <td>안녕하세요 $$$ + javascript를 이용해서 간단한 웹게임을 만들어보려고 하...</td>\n",
       "      <td>5</td>\n",
       "      <td>$$$ models 폴더의 depth가 일반적이지 않을 경우 migration하는 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>허프만 코드를 사용한 파일 압축 질문입니다.</td>\n",
       "      <td>허프만 코딩을 사용해서 파일 압축을 하는 과제 도중에 \\n입력받은 파일 데이터를 이...</td>\n",
       "      <td>2</td>\n",
       "      <td>허프만 코드를 사용한 파일 압축 질문입니다. 허프만 코딩을 사용해서 파일 압축을 하...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2591 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                           wait()과 sleep()의 차이점은 뭔가요   \n",
       "1                     $$$ 초보 외부 클래스 멤버 변수 사용 질문합니다.ㅠㅠ   \n",
       "2                           ORM: Sequelize: 다대다 관계 쿼리   \n",
       "3                      $$$에서 숫자가 NaN인지 검사하려면 어떻게해야하죠?   \n",
       "4                 $$$ 2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요?   \n",
       "...                                               ...   \n",
       "2587                                  $$$ 슬라이드 질문입니다.   \n",
       "2588                                       $$$ 메인 클래스   \n",
       "2589                         $$$ sparse matrix 질문합니다!   \n",
       "2590  $$$ models 폴더의 depth가 일반적이지 않을 경우 migration하는 법   \n",
       "2591                         허프만 코드를 사용한 파일 압축 질문입니다.   \n",
       "\n",
       "                                                content  label  \\\n",
       "0          ###발생하는 문제 및 실행환경\\nwait()과 sleep()의 차이점은 뭔가요      3   \n",
       "1     1.헤더에, 사용할 멤버변수가 담긴 헤더 파일이 Include 되어있습니다.\\n예를...      2   \n",
       "2     안녕하세요.\\n\\n어떻게 다대다 관계 쿼리를 해야하나요? 예를들어, `product...      4   \n",
       "3     ```\\nparseFloat('geoff') == NaN;\\n\\nparseFloat...      4   \n",
       "4     ```\\n>>>dict['name']\\n胡安·马塔\\n>>>json.dumps(dic...      5   \n",
       "...                                                 ...    ...   \n",
       "2587  안녕하세요.\\n다름이아니라 \\n$$$로 버튼을 클릭하면 \\n오른쪽에서 왼쪽으로 들어...      4   \n",
       "2588  프로그램 전체 메인 클래스를 하나 만들고 메인에서 메뉴를 선택하면 세가지 각각 다른...      3   \n",
       "2589  * sparse matrix: 0이 아닌 값을 가진 원소들을 ordered list...      1   \n",
       "2590  안녕하세요 $$$ + javascript를 이용해서 간단한 웹게임을 만들어보려고 하...      5   \n",
       "2591  허프만 코딩을 사용해서 파일 압축을 하는 과제 도중에 \\n입력받은 파일 데이터를 이...      2   \n",
       "\n",
       "                                               document  \n",
       "0     wait()과 sleep()의 차이점은 뭔가요 ###발생하는 문제 및 실행환경\\nw...  \n",
       "1     $$$ 초보 외부 클래스 멤버 변수 사용 질문합니다.ㅠㅠ 1.헤더에, 사용할 멤버변...  \n",
       "2     ORM: Sequelize: 다대다 관계 쿼리 안녕하세요.\\n\\n어떻게 다대다 관계...  \n",
       "3     $$$에서 숫자가 NaN인지 검사하려면 어떻게해야하죠? ```\\nparseFloat...  \n",
       "4     $$$ 2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요? ```\\n>>>di...  \n",
       "...                                                 ...  \n",
       "2587  $$$ 슬라이드 질문입니다. 안녕하세요.\\n다름이아니라 \\n$$$로 버튼을 클릭하면...  \n",
       "2588  $$$ 메인 클래스 프로그램 전체 메인 클래스를 하나 만들고 메인에서 메뉴를 선택하...  \n",
       "2589  $$$ sparse matrix 질문합니다! * sparse matrix: 0이 아...  \n",
       "2590  $$$ models 폴더의 depth가 일반적이지 않을 경우 migration하는 ...  \n",
       "2591  허프만 코드를 사용한 파일 압축 질문입니다. 허프만 코딩을 사용해서 파일 압축을 하...  \n",
       "\n",
       "[2591 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train set 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_train, df_bert_dev = train_test_split(train, test_size=0.01)\n",
    "train.to_csv('./train.tsv', sep='\\t', index = False,header=False)\n",
    "#output tsv file, no header for train and dev\n",
    "df_bert_train.to_csv('train.tsv', sep='\\t', index=False, header=False)\n",
    "df_bert_dev.to_csv('test.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range. Fields = ['$$$ 초보 외부 클래스 멤버 변수 사용 질문합니다.ㅠㅠ', '\"1.헤더에, 사용할 멤버변수가 담긴 헤더 파일이 Include 되어있습니다.']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/gluonnlp/data/dataset.py\u001b[0m in \u001b[0;36m_field_selector\u001b[0;34m(self, fields)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/gluonnlp/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-0801a6619df1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTSVDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_discard_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#dataset_test = nlp.data.TSVDataset(\"test.tsv\", field_indices=[1,2], num_discard_samples=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/gluonnlp/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, encoding, sample_splitter, field_separator, num_discard_samples, field_indices, allow_missing)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallow_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTSVDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_should_discard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/gluonnlp/data/dataset.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_separator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_separator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0mselected_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/gluonnlp/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_separator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_separator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                     \u001b[0mselected_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/gluonnlp/data/dataset.py\u001b[0m in \u001b[0;36m_field_selector\u001b[0;34m(self, fields)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s. Fields = %s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range. Fields = ['$$$ 초보 외부 클래스 멤버 변수 사용 질문합니다.ㅠㅠ', '\"1.헤더에, 사용할 멤버변수가 담긴 헤더 파일이 Include 되어있습니다.']"
     ]
    }
   ],
   "source": [
    "dataset_train = nlp.data.TSVDataset(\"train.tsv\", field_indices=[1,2], num_discard_samples=1)\n",
    "#dataset_test = nlp.data.TSVDataset(\"test.tsv\", field_indices=[1,2], num_discard_samples=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label = train.label.apply(lambda x: str(x))\n",
    "train.content = train.content.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       2\n",
       "2       4\n",
       "3       4\n",
       "4       5\n",
       "       ..\n",
       "2587    4\n",
       "2588    3\n",
       "2589    1\n",
       "2590    5\n",
       "2591    2\n",
       "Name: label, Length: 2591, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub(' +', ' ',test.document[0])\n",
    "def clean_df():\n",
    "    list=[' +','ㅜ+','ㅠ+','[$]+','[@]+','[#]+','\\n','\\t',\"[']+\"]\n",
    "    #list=[' +','ㅜ+','ㅠ+','\\n']\n",
    "    for i in list:\n",
    "        train.document=train.document.apply(lambda x: re.sub(i, ' ',x))\n",
    "        test.document=test.document.apply(lambda x: re.sub(i, ' ',x))\n",
    "clean_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4',\n",
       " ' 에서 숫자가 NaN인지 검사하려면 어떻게해야하죠? ``` parseFloat( geoff ) == NaN;  parseFloat( geoff ) == Number.NaN; ``` 이렇게 해봤는데 둘다 true로만 나와요. 뭐가 문제인가요  ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_temp=train.iloc[:,2:4].values.tolist() \n",
    "train_temp[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_temp=train.document,train.label.tolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['아 더빙.. 진짜 짜증나네요 목소리', '0']\n",
      "['흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나', '1']\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train[0])\n",
    "print(dataset_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['3', 'wait()과 sleep()의 차이점은 뭔가요  발생하는 문제 및 실행환경 wait()과 sleep()의 차이점은 뭔가요'],\n",
       " ['2',\n",
       "  '  초보 외부 클래스 멤버 변수 사용 질문합니다.  1.헤더에, 사용할 멤버변수가 담긴 헤더 파일이 Include 되어있습니다. 예를 들어 해당 클래스 이름이 xProtect 라면.  가져와서 쓰고자 하는 현재 cpp 파일에   xProtect *A = NULL; 이나 xProtect *A = new xProtect  를 사용하여 A라는 객체를 만들고, 사용하고자 하는 외부 xProtect 클래스의 멤버변수가 PP라는 리스트라면  A->PP 와 같은 방법으로 외부클래스에서 저장된 리스트 PP를 불러오는 방식으로 사용하고싶은데요  아무 방법도 먹히지 않고 해당 PP에는 쓰레기 값만 저장이 되어있네요..  그냥 간단할 줄 알았는데 이게 하루를 잡아먹어 미칠 노릇입니다...   다른 방법으로 객체화 해야되는건지... 아니면 PP라는 외부 클래스의 멤버변수를 가져올 수 있는 다른 방법이 있다면 알려주세요   고수분들 답변 기다리겠습니다.. '],\n",
       " ['4',\n",
       "  'ORM: Sequelize: 다대다 관계 쿼리 안녕하세요.  어떻게 다대다 관계 쿼리를 해야하나요? 예를들어, `product`, `category`, `product_category` 모델이 있다고 하고 아래와 같은 association을 가지고 있습니다.  ``` // product product.belongsToMany (models.category, {  through:  product_category ,  foreignKey:  product_id   });  // category category.belongsToMany (models.product, {  through:  product_category ,  foreignKey:  category_id   });  // product_category product_category.belongsTo (models.product, {  foreignKey:  product_id   });  product_category.belongsTo (models.category, {  foreignKey:  category_id   }); ```  맨처음 쿼리에 `findAll()` 메서드를 붙여야할 모델이 무슨 모델인지도 알려주시면 감사하겠습니다.'],\n",
       " ['4',\n",
       "  ' 에서 숫자가 NaN인지 검사하려면 어떻게해야하죠? ``` parseFloat( geoff ) == NaN;  parseFloat( geoff ) == Number.NaN; ``` 이렇게 해봤는데 둘다 true로만 나와요. 뭐가 문제인가요  '],\n",
       " ['5',\n",
       "  '  2.7에서 중국어, 특수문자 인코딩 하는 방법이 뭔가요? ``` >>>dict[ name ] 胡安·马塔 >>>json.dumps(dict[ name ]).replace(\"\\\\\\\\\",\"\\\\\\\\\\\\\\\\\") \"\\\\\\\\u80e1\\\\\\\\u5b89\\\\\\\\u00b7\\\\\\\\u9a6c\\\\\\\\u5854\" >>>\"Player name is  {} \".format(dict[ name ]) UnicodeEncodeError  ascii  codec can t encode character >>>\"Player name is  {} \".format(json.dumps(dict[ name ])) UnicodeEncodeError  ascii  codec can t encode character ``` 다른 중국 단어들은 잘 들어가는데 胡安·马塔 이 단어에서 인코드 에러가 발생하네요... 중국어가 문제가 아니라 가운데 점이 문제인거같은데 혹시 이 경우 어떻게 포멧팅 해야하나요? '],\n",
       " ['5',\n",
       "  ' 으로 탐색기 시작위치 변경하고싶습니다.  으로 코딩중인데   def explorer():   subprocess.call( explorer )  으로 탐색기를 실행하고  file의 경로가 뭘 선택하냐에 따라서 달라져서 절대값으로 경로설정은 힘들고   path=os.path.dirname(file)  으로 파일 경로 구해서  탐색기 맨처음 시작하는 위치를 path로 지정하고 싶습니다.  이럴땐 어떻게 해야하나요?  '],\n",
       " ['3',\n",
       "  '  웹 개발 하고 있습니다. 실무에서 lombok 사용하나요?  으로 웹 개발 하고 있습니다.  회사에서는 사수가 주는 코트만 수정중이라...  개인적으로 공부를 하려합니다.   https://github.com/origoni/ -Blog  이 코트를 보니 이클립스에서 바로 실행이 안되고 lombok라는 플러그인을 깔아야 하는데요.  이 플러그인이 일반적으로 사용되는 것인가요?'],\n",
       " ['4',\n",
       "  'express에서 특정 단추를 눌렀을 때, mysql 데이터를 수정한 후, 수정된 페이지가 로드되도록 하고 싶습니다. ``` main.js app.post( /count , function(req, res){  var num_ = Object.keys(req.body)[0];  var sql =  select times from db where num=?   conn.query(sql, [num_], function(err, rows){   if(err){    console.log(err);    res.status(500).send( Internal Server Error );   } else{    var times_ = rows[0].times    var sql= update db set times=? where num=? ;    conn.query(sql, [times_+1, num_], function(err, rows_){     if(err){      console.log(err);      res.status(500).send( Internal Server Error );      } else {     }    })   }  }) }) ```  ``` output.jade     form(action= /count  method= post )      input(type= submit , value= + , name=i.num, onclick= window.location.reload() ) ```  버튼을 누르면, db의 데이터가 수정되고, 수정된 데이터가 페이지에 출력되게 하고싶습니다. 브라우저에서 새로고침을 하면 페이지가 제대로 리로드 되는데, 클릭이벤트 ronclick= window.location.reload() 를 통해서 새로고침을 하니 페이지가 로드되지 않습니다. 어떻게 해야 할까요'],\n",
       " ['3',\n",
       "  '텍스트 파일을 읽어와서 내림차순 혹은 오름차순으로 정리하고 다시 파일로 출력 9 김철수 72  10 박재용 79  1 나영희 34  3 이나연 46  이런식으로 되어있는 텍스트파일(학번, 이름, 성적)을 읽어와서 학번을 기준으로 내림차순이나 오름차순으로 정리한다음에 다시 파일로 출력 해야하는데욥 어떻게 해야할까요? '],\n",
       " ['5',\n",
       "  '  클래스 변수에 대해 궁금합니다 ``` Class Dog :   name = str()  trick = []  A = Dog()  B = Dog()   A.name =  Apple   B.name =  Banana   A.trick.append( say_hi )  B.trick.append( stand ) ```  이렇게 클래스를 만들면 A와 B의 name 은 각자 Apple, Banana로 저장이 되는데,  왜 trick 은  say_hi  와  stand  가 함께 저장되나요?  name 과 trick 사이에 무슨 차이가 있나요??'],\n",
       " ['1',\n",
       "  '  순서정리 오류 질문 ``` //      include <stdio.h>  include <stdlib.h>  include <time.h>   int main() {  int ArrRoom[10] = {0,};    srand(time(NULL));    for (int i = 0; i < 10; i++) // ArrRoom 배열에 1 ~ 10까지 난수로 입력함  {  int ran = (rand() % 10) + 1;   ArrRoom[i] = ran;  }    for (int i = 0; sizeof(ArrRoom)/sizeof(int)-1; i++) // 순서 정리  {  int change = 0; // 값 저장 변수     if (ArrRoom[i] > ArrRoom[i+1])  {  change = ArrRoom[i+1];  ArrRoom[i+1] = ArrRoom[i];  ArrRoom[i] = change;  }  }    for (int i = 0; sizeof(ArrRoom)/sizeof(int); i++) // 실행결과 출력  {  printf(\"%d \",ArrRoom[i]);  }    return 0; }   ``` 1~10 까지 난수를 받아 순서대로 정렬하려 하는데 실행하면 \"Segmentation fault (core dumped)\" 라는 오류가 뜨는데 왜 이렇게 나오는지 모르겠습니다. '],\n",
       " ['5',\n",
       "  '함수에 있는 변수 값을 밖으로 빼서, 다른 파일에 import 하려 합니다. 안녕하세요. 간단히 설명하자면, control. 의 input()함수에 있는 변수값kkk(result2)를 다른 실행파일(run. )에 넣고자 하는데요.   이문제를 해결하기위해 [1] global kkk라는 전역변수를 만들어 놓고, [2] input()함수가 app.route로 호출됐을때, 웹에서 받아온 result2 값을 kkk에 저장시킨 후, [3] subprocess로 run. 를 실행시키면, [4] run. 는 control. 의 kkk 변수 값을 import해서 실행 했었습니다.  run. 가 실행되지 않아서, 여러가지로 테스트 해본 결과 control. 에서 input() 함수 안의 kkk(result2) 값을 밖으로 빼낼수 없었습니다.   kkk값을 밖으로 뺴내려고, input()함수의 return 값을 2개로( return (kkk,redirect( / ,302) ) 시도 해봤는데 안되고 결국 여기에 질문 남깁니다.. 문제를 해결할수 있게 방법론 등을 조언해 주시면 갑사하겠습니다 .    control.  ``` ... global kkk   app.route( / ) def main():  connection = engine.connect()   DB 연결  result = connection.execute(\"select * from users\")   DB에서 result1,2,값 가져옴  return render_template( index.html ,table=result)   홈페이지에 정의해둔 table에 값 뿌려줌    여기부터 입니다. ---------- --------- ------------ --------  app.route( /input , methods = [ POST ]) def input():  result1 = request.form[ a ]   웹에서 a 값 가져옴  result2 = request.form[ b ]   웹에서 b 값 가져옴  ...  DB에 result1,2 값 저장  ...   kkk = result2   result2 값을 run. 에 보내기위해 kkk에 저장   path=\"  run. \"   subprocess_check_out(path, shell=True)  subprocess로 run.  파일 실행   return redirect( / ,302)    ```  run.  ``` ... control. 에서 subprocess로 실행하려는 파일 ... from control import kkk   control. 에서 변수 kkk(result2)를 import 해 실행  run(kkk)  ``` index.html ``` ...  <form action=\"http://localhost:5000/input\" method=\"post\">  <label >a 경로:</label>  <input type=\"text\" name=\"a\">  <label >b 경로:</label>  <input type=\"text\" name=\"b\">  <label >생성:</label>  <input type=\"submit\" value=\"create\">  </form> ...  ```'],\n",
       " ['1',\n",
       "  '배열 이름이랑 배열의 주소가 같은건 왜죠?   발생하는 문제 및 실행환경 배열 이름이랑 배열 주소가 같길래 포인터가 배열을 가리키게 해놓고 포인터 주소를 출력했더니 다르게 나왔어요.  배열이름 = 배열 주소 이면서  포인터값 != 포인터 주소 인건 왜일까요?    소스코드  ```  include <stdio.h>  int main() {  char my_array[100] = \"some cool string\";  printf(\"my_array = %p\\\\n\", my_array);  printf(\"&my_array = %p\\\\n\", &my_array);   char *pointer_to_array = my_array;  printf(\"pointer_to_array = %p\\\\n\", pointer_to_array);  printf(\"&pointer_to_array = %p\\\\n\", &pointer_to_array);   printf(\"Press ENTER to continue...\\\\n\");  getchar();  return 0; } ```   출력    my_array = 0022FF00  &my_array = 0022FF00  pointer_to_array = 0022FF00  &pointer_to_array = 0022FEFC  '],\n",
       " ['1',\n",
       "  ' 를 배우하는 학생입니다. 현재 제가 풀고 있는 문제입니다. [https://noj.am/4344][1]  ```  include <stdio.h>  int main(){  int i, j, c, ec[c], numec, std[ec[i]];   float avg, avgover;  scanf(\"%d\", &c); //전체 케이스 입력     for(i=0;i<c;i++){ //전체 케이스 수만큼 각각의 케이스 입력   scanf(\"%d\", &ec[i]);   for(j=0;j<ec[i];j++){ //각각의 케이스 수만큼 학생점수 입력     scanf(\"%d\", &std[j]);    avg+=std[j];   }   avg/=ec[i];   for(j=0;j<ec[i];j++){ //평균 넘는 애    if(std[j]>avg){     avgover+=1;    }   }   printf(\"%.3lf\", (avgover/(float)ec[i])*100);  }  return 0; } ``` 이 코드를 컴파일 하면 실행하자마자 종료되는 현상이 있는데 제가 여기서 실수한 부분이나 잘못된점 있으면 알려주시면 감사하겠습니다!    [1]: https://noj.am/4344'],\n",
       " ['3',\n",
       "  'null 예외처리를 깔끔하게 하는 법  발생하는 문제 및 실행환경 보통 코드를 짜다보면     if (someobject != null) {  someobject.doCalc();  } 같은 방식으로 예외처리를 하는데 제가 보기엔 너무 더러워보여서요 좀 더 깔끔하게 하는 방법 없을까요? '],\n",
       " ['3',\n",
       "  '  레이블이나 텍스트박스에 DB에서 select한 값을 출력하려면 어떻게 해야하나요? ```  Override  public void actionPerformed(ActionEvent e) {   if(e.getSource() == 버튼) {    int i=JOptionPane.showConfirmDialog(this, \"투표하시겠습니까?\", \"확인\", JOptionPane.YES_NO_OPTION);   if(i==0){  try {  //String sql = \"update VoteNum set count=? where num=?\";  PreparedStatement pstmt=null;   if(A.isSelected()){  ++num0;  String sql = \"update VoteNum set count=\"+num0+\" where num=1\";  pstmt=con.prepareStatement(sql);  //pstmt.setInt(1, num0);  //pstmt.setInt(2, 1);  pstmt.executeUpdate(sql);  new Result();  }else if(B.isSelected()){   ++num1;   String sql = \"update VoteNum set count=\"+num1+\" where num=2\";  pstmt=con.prepareStatement(sql);  //pstmt.setInt(1, num1);  //pstmt.setInt(2, 2);  pstmt.executeUpdate(sql);  new Result();  }else if(C.isSelected()){   ++num2;   String sql = \"update VoteNum set count=\"+num2+\" where num=3\";  pstmt=con.prepareStatement(sql);  //pstmt.setInt(1, num2);  //pstmt.setInt(2, 3);  pstmt.executeUpdate(sql);  new Result();  }else if(D.isSelected()){   ++num3;  String sql = \"update VoteNum set count=\"+num3+\" where num=4\";  pstmt=con.prepareStatement(sql);  //pstmt.setInt(1, num3);  //pstmt.setInt(2, 4);  pstmt.executeUpdate(sql);  new Result();  }else if(E.isSelected()){   ++num4;  String sql = \"update VoteNum set count=\"+num4+\" where num=5\";  pstmt=con.prepareStatement(sql);  //pstmt.setInt(1, num4);  //pstmt.setInt(2, 5);  pstmt.executeUpdate(sql);  new Result();  }   } catch (SQLException e1) {  // TODO Auto-generated catch block  e1.printStackTrace();  }  }    ```  위가 DB에 값을 삽입하는 다른 클래스 부분인데  사실 값이 잘 안 들어가서 DB에 넣은 값인데도 값이 계속 변하는 것도 고민입니다  ;   ```   stmt.executeQuery(\"select * from VoteNum\");      while(rs.next()){    str=str+\"\\\\n\"+rs.getInt(\"count\");    sum=sum+rs.getInt(\"count\");     }    JLabel A.setText(str.charAt(1)+\"\");    JLabel B.setText(str.charAt(3)+\"\");    JLabel C.setText(str.charAt(5)+\"\");    JLabel D.setText(str.charAt(7)+\"\");    JLabel E.setText(str.charAt(9)+\"\");     try {    rs.close();    } catch (SQLException e) {    e.printStackTrace();    }   } catch (SQLException e) {   e.printStackTrace();   }  } } ```   간단한 투표형식을 프로그램에 추가하고 싶습니다 아래 소스코드 부분이 출력하는 부분인데 어떻게 넣어야할지 모르겠어서  위의 내용은 꾸역꾸역 일단 오류만 나지않게 값을 넣었더니 str에 계속 null값이 들어가는 중이고 그렇다고 next 안에 바로 label값을 넣자니 계속 레이블 5개에 전부 A값이 들어가서...  어떻게 해야할지 잘 모르겠습니다 ..  조언 부탁드립니다.'],\n",
       " ['1',\n",
       "  '  배열이름 질문합니다. 안녕하세요.  를 공부하고 있는 학생입니다.   배열이름에 관해서 궁금증이 생겼는데.  int arr[3] = {99, 77, 55}; 라는 배열을 선언했다고 가정을 하면  arr이라는 변수는 arr[0]의 주소를 가지게 되는 것은 알았습니다.  1) 그런데 arr이라는 변수는 어디에 저장되어있는 건가요? 메모리상에 arr[0] 변수 앞에 있는건가요?  2) arr은 변수가 아닌건가요? &(arr)을 출력해본결과 arr[0]의 주소값하고 똑같이 나오더군요...  결론적으로 arr이라는 변수가 메모리상에 있는 것인지, 있으면 어디에 위치한건지 알고 싶습니다. '],\n",
       " ['4',\n",
       "  '반복문 작성 ```  (\".list a:nth-child(1)\").mouseover(function(){   (\".cursor li\").hide();   (\".cursor li:nth-child(1)\").show();  }); ```   저 **nth-child(1)**부분의 숫자가 1씩 늘어나면서 계속 반복되려면 어떻게 작성할 수 있나요? '],\n",
       " ['2',\n",
       "  '벡터에 레퍼런스를 저장하려면? `std::vector<int &> hello;` 같이 int의 레퍼런스를 저장하려고 하면  `\"error C2528:  pointer  : pointer to reference is illegal\"` 에러가 뜹니다.  제가 포인터를 잘 못써서 레퍼런스로 하려는 건데 왜 이런 에러가 뜨는 거죠? 꼭 포인터를 써야 하나요?    '],\n",
       " ['1',\n",
       "  '이분검색-low,high 두값을 파라미터만 받아 재귀로 구현  include<stdio.h> int location(int low,int high);  int main(void) {    int n, num, x, i = 0;  //int arr[3];  //printf(\"순서대로 입력해주세요\");  //for (i = 0; i < 3; i++) {  // scanf(\"%d\", arr[i]);  //}    printf(\"검색할 숫자를 입력해주세요\");  scanf(\"%d\", &x);  printf(\"%d\\\\n\",location(0,2));  return 0; } int location(int low,int high) {   int mid;  if (low > high)   return 0;  else {   mid = (low + high) / 2;      if (x == arr[mid])    return mid;   else if (x < arr[mid])    return location(low, mid - 1);   else    return location(mid + 1, high);   } }  파라미터로 low,high 두값만을 인자로받아 이분탐색을 재귀로 구현하는것인데... 파리미터로 x와arr을 받지않았는데..어떻게 구현해야할까 ? 도움 받고싶습니다. '],\n",
       " ['5',\n",
       "  '  ( )를 사용해서 웹사이트를 만들려고 합니다. 안녕하세요. 웹사이트(웹서비스)를 만들기 위해 도움을 얻고자 가입하게 되었습니다 전 프로그램에 관한 분야에 대해서는 전공자도 아니고 완전 초보 입니다. 제가 원하는 웹서비스를 만들고 싶어서 정보를 찾던중   이라는 언어가 초보자가 배우기 쉽고   라는 프레임워크라는 툴을 이용해 빠르게 웹 을 만들수 있다는 글을 읽게 되었습니다 그래서 유튜브로  를 이용한 웹사이트 만드는 동영상을 보면서 따라하는데 잘 안되더라고요. 똑같이 따라하는데도 매번 오류 나서 진도도 잘 못나가겠고   ( ) 언어가 쉽다고 하는데, 저 한테는 어렵더라고요 쉽다는 언어도 저한테는 익숙지 못해서 제대로된 공부방법을 알고 싶고  요즘 무료로 코딩을 배울수 있는 싸이트가 많아서 저 처럼  (  )를 이용해 빠르게 웹서비스를 만들수 있는 괜찮은 싸이트를 알려주시면 감사하겠습니다. 끝으로 저의 방향은 각 언어에 대하여 깊고 심도 있게 배우는게 아니고 웹서비스를 만드는 결과물을 얻기 위하는 방향이기에 저같은 초보가 필요한게 무엇인지, 어떤 정보가 필요한지, 제가 원하는 웹서비스를 만드는데 어느정도 시간이 필요 한지에 대해 알려주셨면 합니다.  긴글 읽어주셔서 감사합니다.   '],\n",
       " ['3',\n",
       "  'ArrayList와 Vector의 차이는 뭔가요? ArrayList와 Vector 두 자료구조 사이의 차이는 뭔가요? 각각 어디에 사용하면 좋을까요? '],\n",
       " ['5',\n",
       "  ' 으로 표현한 다익스트라 알고리즘 코드 예시가 이해가 안되서 질문드립니다. ![이미지][1]  ``` //여기에 코드를 입력하세요 graph = {} graph[\"start\"] = {} graph[\"start\"][\"a\"] = 6 graph[\"start\"][\"b\"] = 2 graph[\"a\"] = {\"fin\": 1}   graph[\"a\"][\"fin\"] = 1 graph[\"b\"] = {\"a\": 3, \"fin\": 5}   graph[\"b\"][\"a\"] = 3 graph[\"b\"][\"fin\"] = 5 graph[\"fin\"] = {}    노드의 가격을 저장하는 해시테이블 infinity = float(\"inf\")    에서 무한 표현 방법은 float( inf ) 를 사용한다. costs = {} costs[\"a\"] = 6 costs[\"b\"] = 2 costs[\"fin\"] = infinity    부모를 위한 해시테이블 parents = {} parents[\"a\"] = \"start\" parents[\"b\"] = \"start\" parents[\"fin\"] = None  processed = []   각 노드는 한번씩만 처리해야하므로 이미 처리한 노드를 기록해놓을 리스트가 필요하다.    가장 싼 노드를 찾는 함수 def find_lowest_cost_node(costs):  lowest_cost = float(\"inf\")  lowest_cost_node = None    for node in costs:   비용 테이블에서 노드를 하나씩 돌면서  cost = costs[node]   if cost < lowest_cost and node not in processed:   확인중인 노드의 비용이 최저 비용보다 낮고 그 노드가 처리되지 않은 노드일 때  lowest_cost = cost   최저 비용 갱신  lowest_cost_node = node   최저 비용 노드 갱신    return lowest_cost_node   node = find_lowest_cost_node(costs)   아직 처리하지 않은 가장 싼 노드를 찾는다.   모든 노드를 처리하면 반복문 종료 while node is not None:   cost = costs[node]  neighbors = graph[node]   node =  a  -> { fin  : 1} node =  b  -> { a  : 3,  fin  : 5} node =  fin  -> {}    for n in neighbors.keys():   모든 이웃에 대해 반복  new_cost = cost + neighbors[n]    if costs[n] > new_cost:   새 노드를 지나는 것이 가격이 더 싸다면  costs[n] = new_cost   노드의 가격을 새 노드의 가격으로 갱신  parents[n] = node   부모를 이 노드로 새로 설정    processed.append(node)   노드를 처리한 사실을 기록  node = find_lowest_cost_node(costs)   다음으로 처리할 노드를 찾아 반복   ```  위 코드에서,    1. while문 안에서 초기에 선언된 변수 neighbors에 저장된 원소를 나열한다면  어떻게 되죠? 일단, graph[node]를 대입했으니  node =  a  -> { fin  : 1} node =  b  -> { a  : 3,  fin  : 5} node =  fin  -> {} 이런식인건 알겠는데 제대로 나타낸다면 어떻게 할지 모르겠습니다     2. while문 안의 for문 for n in neighbors.keys()이 n이 a, b ,fin이 된다는 얘기인가요?   3. neighbors[a], neighbors[b], neighbors[fin]이 무슨값이죠?   4. find_lowest_cost_node(costs) 함수에서 처음에  lowest_cost 를 float(\"inf\") (무한대)로 초기화하는 이유가 뭐죠?  그리고, lowest_cost_node 를 None으로 초기화하는 이유가 뭐죠?   5. while문 바로 전에 node = find_lowest_cost_node(costs)라고 선언했는데,  while문 안의 마지막에 왜 node = find_lowest_cost_node(costs)를 또 선언하는 이유가 뭐죠?   [1]: https://res.cloudinary.com/eightcruz/image/upload/v1533834635/syeikvev8qh8orhwp1o5.png'],\n",
       " ['3',\n",
       "  ' 에서 string비교는 어떻게 하나요?  에서 string비교는 어떻게 하나요? 저는 지금까지 string을 비교할 때 == 연산자를 사용해왔습니다. 근데 계속 사용하다보니 bug가 발생하는 상황이 자주있었고, 일부분을 .equals()로 변경한 후에 bug를 해결했습니다. == 연산자가 문제인건가요? ==연산자는 언제 사용해야만하고 언제 사용하면 안되는 거죠? ==와 .equals의 차이점이 뭔가요?'],\n",
       " ['4',\n",
       "  'mongodb에서 subDocument에 대한 find 쿼리는 어떻게 하나요?  ``` var subSchema = mongoose.Schema({  main:Number,  sub:Number,  color:Number },{ _id : false });  var testSchema = new Schema({  userId:{  type : String,  index : true  },  itemTag: [subSchema] }, { versionKey: false }); ```  위와 같은 형식의 스키마를 가진 Document를 만들었는데요.  클라이언트에서  ``` {   \"userId\":\"aaabbb\",  \"itemTag\":[{   \"main\":3,   \"sub\":7,   \"color\":1  },{   \"main\":4,   \"sub\":4,   \"color\":1  }] } ``` 이와 같은 형식으로 json 데이터를 보내면 서버에서 mongodb의 item 도큐먼트를 뒤져서 userId가 같고 itemTag가 받은 json데이터와 정확히 일치하는 데이터를 리턴하는 코드를 작성하려고 합니다.   제가 원하는 결과 값은 ``` [{   \"userId\":\"aaabbb\",  \"itemTag\":[{   \"main\":3,   \"sub\":7,   \"color\":1  },{   \"main\":4,   \"sub\":4,   \"color\":1  },{   \"main\":1,   \"sub\":1,   \"color\":1  },{   \"main\":2,   \"sub\":2,   \"color\":2  }] },{   \"userId\":\"aaabbb\",  \"itemTag\":[{   \"main\":3,   \"sub\":7,   \"color\":1  },{   \"main\":4,   \"sub\":4,   \"color\":1  },{   \"main\":7,   \"sub\":3,   \"color\":2  },{   \"main\":5,   \"sub\":5,   \"color\":5  }] },{   \"userId\":\"aaabbb\",  \"itemTag\":[{   \"main\":3,   \"sub\":7,   \"color\":1  },{   \"main\":4,   \"sub\":4,   \"color\":1  },{   \"main\":6,   \"sub\":6,   \"color\":4  },{   \"main\":5,   \"sub\":5,   \"color\":2  }] } ] ```  이런 식으로 받은 json 데이터를 포함하는 값입니다.     근데 문제는  all이나  elemMatch를 사용하라는데 비교하는 데이터가 document일경우는 어떤 식으로 작성해야할지 감이 오질 않습니다...  ``` Item  .find({  and: [  { userId: req.body.userId },  { itemTag: {  all: req.body.itemTag} }  ]})  .sort(sortQuery)  .exec(  function (err, data) {  if (err) res.json(err);  res.json(data);  }  ); ```  보통의 경우는 단일 값을 비교해주면 되지만 받은 데이터가 배열의 형태라 머리가 아픕니다. 아무리 검색해봐도 비슷한 케이스를 찾을 수 없어 여기에 질문 남깁니다..  어떻게 하면 될까요?       '],\n",
       " ['5',\n",
       "  '딕셔너리 값으로 문장을 만들려면 어떻게해야하나요? ``` dic = { H :1,  e :1,  l :3,  o :2,  :1,  w :1,  r :1,  d :1} ```  `Hello world`로 만들려고 하는데.. 딕셔너리만 이용해서 만들려고하니 어떻게 해야할지 잘모르겠습니다... 조언부탁드립니다'],\n",
       " ['3',\n",
       "  '  컴파일 관련 또다시 드려서 죄송합니다. http://www. 2s.com/Code/ API/ x.tools/ToolrunInputStreaminOutputStreamoutOutputStreamerrStringarguments.htm   import  .io.IOException;  import  x.tools. Compiler; import  x.tools.ToolProvider;  public class Main {  public static void main(String args[]) throws IOException {   Compiler compiler = ToolProvider.getSystem Compiler();  int results = compiler.run(null, null, null, \"Foo. \");  System.out.println(\"Success: \" + (results == 0));  } }   해당 소스를 테스트 해보고싶은데 \"Foo. \"부분에 직접 path를 넣어줘도 널익셉션이 뜹니다    혹시 해당소스로 테스트가능하신분 있으신가요?  '],\n",
       " ['3',\n",
       "  '간단한   Array 질문입니다! 밑의 코드가 실행되지 않는 이유는 뭔가요? 원래 i에 할당된 값이 없어서 새로 할당한 후에도 실행이 불가하다고 표시되네요.    public class Main {  public static void main(String[] args) {   int[] x = new int[5];  int i=0;  while (i <x.length) {  x[i++] = i;  }  System.out.println(x[i]);  }  }  오류 내용:  Exception in thread \"main\"  .lang.ArrayIndexOutOfBoundsException: 5  at Main.main(Main. :11)'],\n",
       " ['5',\n",
       "  '[  크롤링] 결과 값을 엑셀파일에 누적해서 저장하고 싶은데, 어떻게 해야할까요?? 웹 페이지 크롤링을 했는데,  이 결과를 엑셀로 저장하고 싶습니다.. 여러 방법으로 시도해 봤는데, 크롤링 결과 중 첫번째 항목만 저장이 되네요... 완전 초보인지라 더이상의 해결방법이 떠오르지 않아 질문남깁니다..!!  ※참고 : 엑셀파일은 트렌드 파악 자료로 활용하려 합니다. 그러므로 크롤링 결과를 꾸준히 누적하고 싶어요!!     import requests  from bs4 import BeautifulSoup  import pandas as pd  import numpy as np  import codecs    req = requests.get(\"https://spri.kr/posts?code=industry_trend\")  con = req.content  html = BeautifulSoup(con,\"html.parser\")  div = html.find_all(\"div\",{\"class\":\"panel\"})   for h in div:   SW산업동향 title  def dataA() :  h3 = h.find(\"h3\",{\"class\":\"panel-title\"})  a = h3.find(\"a\").text    aList = list(a)  print(a)  dataA()     작성날짜  def dataP() :  date = h.find(\"div\",{\"class\":\"post-meta\"})  p = date.find(\"p\",{\"class\":\"date\"}).text  print(p)  dataP()     엑셀저장시도  def makeexcel(items, spri_18):  result = []  for item in items:  result.append([a] + [p])  table = pd.DataFrame(result, columns=( title ,  date )  table.to_csv(spri_18, encoding=\"cp949\", mode= a ,index=True)    '],\n",
       " ['5',\n",
       "  '  윈도우 프로그램 개발, 값 전달 -Window program Making- ==test. == import os  os.system( ex2.  ) ---  test.  를 실행시 결국, ex2.  를 실행하게 됩니다. 하지만 여기서 ex2.  를 실행할 때, 변수를 넘기고 싶다. 이럴 때는 어떻게 해야 할까요?   그래서 저는 ex2.  에서 변수를 사용하고 싶습니다.(마치 HTML 의 GET이나 POST)'],\n",
       " ['2',\n",
       "  '  배열 중복 숫자 제거 문제 뭐가 문제일 까요.. int *arr2;  int SIZE2;   cout << \"Enter array size: \";  cin >> SIZE2;  arr2 = new int[SIZE2];   int *RArr;  int size2 = SIZE2;  RArr = new int[size2];   for (int i = 0; i < SIZE2; i++)  {    cout << \"Enter a integer: \";   cin >> RArr[i];    for (int j = 0; j < i; j++)   {    if (RArr[i] == arr2[j])    {     break;    }   }   }   arr2 = RArr;  숫자를 입력받고 그 숫자가 새로운 숫자이면 배열에 저장하고, 이미 존재하면 그 수를 버리게 해서, 입력 후 배열이 중복 없이 고유 숫자만 포함되게 하는 알고리즘을 짜봤는데,,, 계속 막히네요..  백터쓰는 법도 있다고하나 백터 없이 순수 알고리즘으로 짜는 법 있을까요...  중복 없는 고유 숫자를 배열에 입력하는 과정을 어떻게 짜야 할 지 모르겠어요...'],\n",
       " ['2',\n",
       "  '부모 클래스의 소멸자를 꼭 불러줘야 하나요?   클래스에서 가상 소멸자를 overriding하고 있는데요 소멸자 안에 부모 클래스의 소멸자를 불러줘야 하나요?   소스코드  ``` MyChildClass::~MyChildClass() {  //부모 클래스 소멸자 부르기  this->MyBaseClass::~MyBaseClass();    MyChildClass의 값 정리 } ``` '],\n",
       " ['5',\n",
       "  ' ) 리스트 정렬 관련해서 질문합니다. ``` numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9] output = [[], [], []]   for number in numbers:  output[(number+2)%3].append(number)  print(output) ``` 의 소스코드를 실행하면 나머지값 `0`,`1`,`2`가 나오는 요소대로 묶은상태로 출력되는데요.  ``` [1, 4, 7], [2, 5, 8], [3, 6, 9] ```  이상태에서 `[1, 2, 3], [4, 5, 6], [7, 8, 9]` 순서대로 정렬하고 싶습니다.  가능하면 `sort()`함수를 이용하는 방법도 궁금합니다.'],\n",
       " ['4',\n",
       "  '  라이브러리 질문 있습니다.  를 공부할때  라이브러리 중에    Library와 jQuery가 있더라구요.  Kahnacademy 에서 자바스크립트를 공부중인데    Library와 jQuery 중에 어느것을 먼저 공부하는게 좋나요?    또,   Library는 원래 있는 라이브러리 인가요? 구글링 해도 잘 모르겠네요.  '],\n",
       " ['3',\n",
       "  '( )API 와 JSON 파싱 관련 질문입니다. {  \"success\": true,  \"message\": null,  \"code\": null,  \"elapsed\": 0.1291,  \"data\": {  \"CSPA:BTC\": {  \"cspa\": 8012.00601685,  \"cspa_change_24h\": -467.52638691,  \"cspa_change_24h_pct\": -5.51,  \"volume_btc_24h\": 634847.37,  \"volume_usd_24h\": 5086400987.27,  \"updated\": 1522132576  }  } }  api 코드를 실행시키면 나오는 JSON 데이터 입니다.  JSON파싱을 하고 싶은데,  JSON파싱을 하는 코드를 어디다가 작성해야 되는지를 모르겠습니다.  같은 패키지 안에 다른 클래스로 해야되는지,  아니면 따로 클래스를 메인에서 빼서 작성해야되는지 궁금합니다.  또, 데이터 안에 cspa라는것을 추출하기 위해서   JSONArray bodyArray = (JSONArray) object.get(\"CSPA:BTC\");  for(int i = 0 ; i < bodyArray.size(); i++)   {  JSONObject data = (JSONObject) bodyArray.get(i);   System.out.println(data.get(\"cspa\").toString());  System.out.println(data.get(\"cspa_change_24h\").toString());  System.out.println(data.get(\"cspa_change_24h_pct\").toString());   }  이런식의 코드가 맞는건가요?   를 배우지 않고 주먹구구식으로 필요한것만 습득하고   짜집기하다보니     고수님들의 도움이 필요합니다.'],\n",
       " ['3',\n",
       "  '선택등록 기능 추가후 등록시 Data too long for column에러가 뜨는데 데이터길이 문제가 아닌거같습니다. 감사합니다'],\n",
       " ['5',\n",
       "  'date를 datetime으로 변환하려면? `datetime`은 `datetime.date()`를 써서 `time`형으로 바꿔줄 수 있는데  `date`를 `datetime`으로 바꿔주는   내장 함수가 있을까요? `datetime(date.year, date.month, date.day)`으로 부르는 건 알고 있습니다.  제가 원하는 건 `dateToDatetime(date)`이렇게 부르면 `datetime`형 객체가 return 됐으면 좋겠습니다. 시간 부분은 그냥 00:00:00같이 딱 24시 정각으로요.  '],\n",
       " ['2',\n",
       "  '2진수를 8진수로 변환하는 코드 뭐가 문제일까요? ```  include <iostream>  include <algorithm>  include <string> using namespace std;  int main() {  string input, output;  cin>>input;  reverse(input.begin(), input.end());  int sum;  int cnt = 3-(input.length()%3);  while(cnt--){   input +=  0 ;  }  for(int i=0; i<input.length()+cnt; i+=3){   sum=0;   sum += (input[i]- 0 );   sum += (input[i+1]- 0 )*2;   sum += (input[i+2]- 0 )*2*2;   output+=sum+ 0 ;  }  int idx=1;  while(output[output.length()-idx] ==  0 ){   output.erase(output.length()-idx);   idx++;  }    reverse(output.begin(), output.end());  cout<<output<<endl;  return 0; }  ```  뭐가 문제일까요... 다 맞게한거 같은데.. 백준에서 안되네요..'],\n",
       " ['4',\n",
       "  ' 에서 ==랑 ===의 차이가 뭔가요?   를 쓰고 있는데 다른 사람들이 작성한 코드를 참고하면서 공부를 하는데 ==말고도 ===라는 연산자를  엄청 많이 사용하고있더라고요. 근데 저는 ===라는 연산자는 처음보고 이게 무슨 역할을 하는지 궁금해서  질문드립니다. '],\n",
       " ['4',\n",
       "  'node.js callback 함수 질문입니다. var i = 0; function a(callback){  i +=1;  callback(i); }; setInterval(a((num)=>{  console.log(num); }),1000);  위는 제가 짠 코드입니다. 저는 저게 실행되면 1초마다 1,2,3... 으로 나올 것이라고 예상했는데 TypeError: \"callback\" argument must be a function 이라는 에러가 나오면서 1만 출력되고 끝납니다.  왜 이런 현상이 발생하는 걸까요?'],\n",
       " ['3',\n",
       "  '이클립스 설치 질문 이클립스를 노트북에 설치할려고 하는데  가 인식이 안된다고 뜨네요   뭘 해야 이클립스를 설치 할 수 있을까요?  는 설치했고 이클립스 설치할려고 하면 홈페이지로 넘어가요![이미지][1]   저렇게 뜨면   설치랑 환경변수 된거라던데![이미지][2]    [1]: https://res.cloudinary.com/eightcruz/image/upload/v1567568119/ufha07uppprjeo4wpq8m.jpg  [2]: https://res.cloudinary.com/eightcruz/image/upload/v1567568162/gw7ujigoxpkqkezmj3pe.jpg 자꾸 이클립스 설치할려고하면 여기로 넘어가요'],\n",
       " ['5',\n",
       "  'return값은 두개인데 plot그림은 한개밖에 없어요 ``` import matplotlib.pyplot as plt decisionNode = dict(boxstyle=\"sawtooth\",fc=\"0.8\") leafNode = dict(boxstyle = \"round4\",fc=\"0.8\") arrow_args = dict(arrowstyle = \"<-\")  def plotNode(nodeTxt, centerPt, parentPt, nodeType):  createPlot.ax1.annotate(nodeTxt, xy=parentPt,  xycoords=\"axes fraction\",  xytext=centerPt,textcoords=\"axes fraction\",  va=\"center\",ha=\"center\",bbox=nodeType,  arrowprops=arrow_args) def createPlot():  fig = plt.figure(1,facecolor=\"white\")  fig.clf()  createPlot.ax1 = plt.subplot(111,frameon=False)  return plotNode( a decisin node ,(0.5,0.1),(0.1,0.5),decisionNode)  return plotNode( a leaf node ,(0.8,0.1),(0.3,0,8),leafNode)  plt.show() ```  ``` import treePlotter treePlotter.createPlot() ```  createPlot 함수에서 return값이 두개인데 그래프를 그리면  ![이미지][1]  이렇게 하나만 나와요.   뭐가 잘못된걸까요..?   [1]: https://res.cloudinary.com/eightcruz/image/upload/v1578540811/rxjhxx4xamsnwu7bdhcl.png'],\n",
       " ['5',\n",
       "  '이미지 업로드에 관한 질문입니다. ![이미지 선택시 화면][1]     [1]: http://res.cloudinary.com/eightcruz/image/upload/v1464659500/eylkkm5bjt1gxcua3azu.jpg  안녕하세요. 계속 질문드리네요. 이미지 선택하고 파일업로드 버튼을 누르면 저런 화면이 나오고 다음화면으로 이동이 안되는데요.  model.  ``` class image(models.Model):  image1=models.ImageField(upload_to= pic_folder/%Y/%m/%d )  image2=models.ImageField(upload_to= pic_folder/%Y/%m/%d )  image3=models.ImageField(upload_to= pic_folder/%Y/%m/%d )   class Meta:  db_table=\"tableau_image\"  ```   foms.  ``` class imageForm(forms.ModelForm):  class Meta:  model = image  fields = ( image1 , image2 , image3 ,)    ``` views.  ```  def index(request):  if request.method == \"POST\":  upimage=imageForm(request.POST, request.FILES)  if upimage.is_valid():  Tableau=image()  Tableau.image1 = upimage.cleaned_data[\"image1\"]  Tableau.image2 = upimage.cleaned_data[\"image2\"]  Tableau.image3 = upimage.cleaned_data[\"image3\"]  Tableau.save()  return HttpResponseRedirect( /result/ )  else:  upimage = imageForm()  return render(request,  upload.html , { upimage : upimage})  ``` 로 만들어놓았습니다. '],\n",
       " ['5',\n",
       "  '  리스트 한글,영어 정렬   리스트를 정렬 할 때, 영어가 먼저 오게 되는데, 한글이 먼저 오게 하는 방법이 있을까요??  ``` names = [  C ,  A B ,  ㄴ ,  ㄱ ,  D A ,  A A  ,  ㄷ ] sorted(names)    Output [ A A ,  A B ,  C ,  D A ,  ㄱ ,  ㄴ ,  ㄷ ]    Desired Output [  ㄱ ,  ㄴ ,  ㄷ ,  A A ,  A B ,  C ,  D A ] ``` 감사합니다.'],\n",
       " ['3',\n",
       "  ' 에서 객체를 복사하는법 ``` DummyBean dum = new DummyBean(); dum.setDummy(\"foo\"); System.out.println(dum.getDummy()); // prints  foo   DummyBean dumtwo = dum; System.out.println(dumtwo.getDummy()); // prints  foo   dum.setDummy(\"bar\"); System.out.println(dumtwo.getDummy()); // prints  bar  but it should print  foo  ``` 위의 코드에서 `dum`을 `dumtwo`에 복사하잖아요. 그리고 `dum`의 값을 바꿀때 `dumtwo`에 영향을 주지 않았으면 좋겠어요. 근데 위에 코드에서는 제가 `dum`을 바꾸면 `dumtwo`도 똑같이 바뀌잖아요.   제가 원하는건 값만 복사하는건데 `dumtwo = dum`는 dumtwo가 dum과 똑같은 객체를 가리키게 하는것 같아요..  dumtwo = dum 문장에서 문자열 값만 복사하게 할 수 없을까요?'],\n",
       " ['5',\n",
       "  '  beutifulsoup 크롤링 중 데이터를 받아오지 못합니다. selenium 이용해서 자바스크립트 포함된 웹페이지 크롤링 하는 법좀 알려주세요! https://mensaar.de/ /menu/sb  위의 웹페이지에서 식단 데이터를 가져와서 출력하고 싶은데 잘 안되네요.. 제가 쓴 코드는 아래와 같습니다.  ``` // encoding = utf-8  import urllib.request from urllib.request import urlopen from bs4 import BeautifulSoup  url = \"https://mensaar.de/ /menu/sb/\" html=urlopen(url).read() soup = BeautifulSoup(html,  html.parser )  meal_list=soup.findAll(\"div\") print (meal_list)  ``` 테스트 용으로 모든 div태그를 출력해 보는데 결과값이 아래와 같이 많이 생략된 채로 나옵니다.  ``` [<div class=\"navbar-header\"> <button class=\"navbar-toggle\" data-target=\" mensaar-navbar-collapse\" data-toggle=\"collapse\" type=\"button\"> <span class=\"sr-only\">Toggle navigation</span> <span class=\"icon-bar\"></span> <span class=\"icon-bar\"></span> <span class=\"icon-bar\"></span> </button> </div>, <div class=\"container-fluid\"> <div class=\"collapse navbar-collapse\" id=\"mensaar-navbar-collapse\"> <ul class=\"nav navbar-nav\"> <li data-match-route=\"^/ \"><a class=\"mensaar-brand\" data-ng-click=\"collapseNavbar()\" href=\" /\">MenSaar.de</a></li> <li data-match-route=\"^/menu(/\\\\w+)? \" data-ng-cloak=\"\"><a data-ng-click=\"collapseNavbar()\" href=\" /menu\">Speiseplan</a></li> </ul> <ul class=\"nav navbar-nav navbar-right\"> <li><a data-match-route=\"^/privacy \" data-ng-click=\"collapseNavbar()\" href=\" /privacy\">Datenschutz</a></li> <li><a href=\"http://www.studentenwerk-saarland.de/de/Impressum-(2)/Impressum\">Impressum</a></li> </ul> </div> </div>, <div class=\"collapse navbar-collapse\" id=\"mensaar-navbar-collapse\"> <ul class=\"nav navbar-nav\"> <li data-match-route=\"^/ \"><a class=\"mensaar-brand\" data-ng-click=\"collapseNavbar()\" href=\" /\">MenSaar.de</a></li> <li data-match-route=\"^/menu(/\\\\w+)? \" data-ng-cloak=\"\"><a data-ng-click=\"collapseNavbar()\" href=\" /menu\">Speiseplan</a></li> </ul> <ul class=\"nav navbar-nav navbar-right\"> <li><a data-match-route=\"^/privacy \" data-ng-click=\"collapseNavbar()\" href=\" /privacy\">Datenschutz</a></li> <li><a href=\"http://www.studentenwerk-saarland.de/de/Impressum-(2)/Impressum\">Impressum</a></li> </ul> </div>, <div data-ng-view=\"\" id=\"view\"></div>]  Process finished with exit code 0  ```  검색 해 보니 자바스크립트가 포함된 페이지의 경우 따로 처리를 해 주어야 데이터를 온전히 가져올 수 있다고 하는데 혹시 해결 방법을 아시는 분 계시면 답변 부탁드립니다...!   '],\n",
       " ['1',\n",
       "  ' 로 부분집합(멱집합) 구상하기 중 질문드립니다 ! ![이미지][1] ![이미지][2] ![이미지][3] ![이미지][4]    [1]: https://res.cloudinary.com/eightcruz/image/upload/v1523362827/yn1y5xfnw8twdvvkis6f.png  [2]: https://res.cloudinary.com/eightcruz/image/upload/v1523362837/kgvrbq7pzxw5eiu3wg5f.png  [3]: https://res.cloudinary.com/eightcruz/image/upload/v1523362849/expdrjxpcvvm0rarr7c1.png  [4]: https://res.cloudinary.com/eightcruz/image/upload/v1523362860/uevkavivkop3dwykx9gk.png      로만 부분집합을 구하는 코드를 구현하는 도중 ... 거의 결승지점까지 다 다른것 같은데...  배열의 값을 인식하게 해서 나오게하고싶은데 자꾸 같은값이 저렇게 결과값처럼 나오네요...  어떻게 해야될지 도저히 감이안와서 질문드립니다...  어떻게 해야될까요 ???'],\n",
       " ['4',\n",
       "  '파이어베이스(firebase) 쿼리 질문입니다..   ``` \"posts_jp\" : {  \"-KadvRpxnZOYiH0nuE7r\" : {  \"country\" : \"JP\",  \"createdAt\" : 1455193080,  \"likeCount\" : 5,  \"timeLike\" : \"0005~1455193080\",  \"title\" : \"안녕하세요\"  },  \"-KadvRpzeCFE4wGYuIts\" : {  \"country\" : \"JP\",  \"createdAt\" : 1456062236,  \"likeCount\" : 1,  \"timeLike\" : \"0001~1456062236\",  \"title\" : \"누나\"  },  \"-KadvRq-orVwFOFOf4Lw\" : {  \"country\" : \"JP\",  \"createdAt\" : 1457137731,  \"likeCount\" : 6,  \"timeLike\" : \"0006~1457137731\",  \"title\" : \"준호\"  },  \"-KadvRq0BJMydFTfDfBS\" : {  \"country\" : \"JP\",  \"createdAt\" : 1457212491,  \"likeCount\" : 23,  \"timeLike\" : \"0023~1457212491\",  \"title\" : \"방탄소년단 전정국 집착 ver.\"  }  } ```  **쿼리 작성에 어려움이 있네요 고수님들의 답변 부탁드립니다**  좋아요가 많은순으로 정렬해서 가져오고 싶습니다. 단 1개월 이내의 최근 20개만 가져오고 싶으면 어떻게 쿼리를 작성해야 할까요?  감사합니다. '],\n",
       " ['3',\n",
       "  '안드로이드 구글 맵 api 실행하자마자 현재 위치로 줌하기 현제 안드로이드로 구글 맵 api를 사용해서 어플실행하자마자 현재 위치로 줌하는 기능을 추가했습니다만 다른위치로 스크롤해서 이동해놓으면 갑자기 자동으로 또 현재위치로 카메라 포지션이 이동하게 됩니다. 그래서 줌하는 기능을 어플실행시에만 한번만 기능을 실행하려는데 어떻게 구현을 해야할까요??'],\n",
       " ['1',\n",
       "  '문자열 포인터 질문 두 코드의 차이점이 궁금합니다.    1. ```  include <stdio.h>  include <string.h>  include <stdlib.h>  void hstrrev(char* str);  int main() {   char str[100] = \"program을 실행하기 전에 compile를 해야 한다.\";   puts(str);   hstrrev(str);   puts(str);   return 0; }  void hstrrev(char* str) {   char* pstr;  char* s = str;   pstr = (char*)malloc(strlen(str) + 1);  pstr = pstr + strlen(str);   *pstr = NULL;  pstr--;   while (*s) {  if (*s & 0x80) {  *pstr-- = s[1];  *pstr-- = s[0];  s += 2;  }  else {  *pstr-- = *s++;  }  }  strcpy(str, pstr);  free(pstr); } ```    2.  ```  include <stdio.h>  include <string.h>  include <stdlib.h>  void hstrrev(char* str);  int main() {   char str[100] = \"program을 실행하기 전에 compile를 해야 한다.\";   puts(str);   hstrrev(str);   puts(str);   return 0; }  void hstrrev(char* str) {   char* pstr, * p;  char* s = str;   pstr = (char*)malloc(strlen(str) + 1);  p = pstr + strlen(s);   *p-- = NULL;   while (*s) {  if (*s & 0x80) {  *p-- = s[1];  *p-- = s[0];  s += 2;  }  else {  *p-- = *s++;  }  }    strcpy(str, pstr);  free(pstr); } ```   문자열을 한글영어 구분 없이 거꾸로 출력하는 함수 hstrrev에서  1.번 코드에서 함수 hstrrev에서 pstr을 str과 크기가 같게 동적 할당을 하게 한 후 pstr=pstr+strlen(str)을 하게 되면 현재 pstr은 메모리상에서 크기가 4인 포인터 변수가 생성 되고(포인터 변수는 항상 크기 4이기때문에) pstr이 이름없는 메모리(크기가str과 같은)의 시작번질를 가리키게 되는데    ![이미지][1]       그럼 `pstr=pstr+strlen(str)`이라고 하면 pstr은 pstr이 가리키는 이름없는 메모리의 끝을 가리 키게 되지 안나요?(이게 질문입니다)  ![이미지][2]  그후엔 그냥 아래 코드대로 실행 되게 되면 문자열이 거꾸로 출력이 될거라고 예상됬는데 이상한 오류가 뜨더라구요...  오류 내용 ``` Debug Assertion Failed!  Expression:_CrtlsValidHeapPointer(block)  for information on how your program can cause an assertion failure, see the Visual   documentation on asserts.  (Press Retry to debug the application) ```  그럼 이제 2.번 코드에선 위처럼 pstr을 동적 할당 하고나서 다른 포인터 변수하나를 만들어서(`p`) `p=pstr+strlen(str)` 라고하게 되면 마찬가지로, 동적 할당한 후 str길이와 같은 이름없는 메모리를 pstr이 가리키게 되는데 `p=pstr+strlen(str)` 이 식에 의해서 포인터 변수 p는 pstr이 가리키는 메모리의 끝을 가리키게 되고 결국 `pstr=pstr+strlen(str)`과 다를게 없다고 생각 하였습니다.    ![이미지][3]  하지만 1.번코드는 오류가 생기고 2.코드는 잘 실행이 되더라구요...  두코드에서 차이점은 포인터 변수 p를 만들어서 pstr이 가리키는 메모리의 끝을 읽냐 아니면 바로pstr에 pstr이 가리키는 메모리의 끝을 읽냐 인 것 같은데 즉, ``` p=pstr+strlen(str) pstr=pstr+strlen(str) ``` 이 두 식의 차이를 모르겠습니다.    아직 모르는게 너무도 많고 필력도 안좋아서 항상 수준낮은 질문만 하는 것 같은데 항상 답변 해주시는 분들께 진심으로 감사드립니다!    [1]: https://res.cloudinary.com/eightcruz/image/upload/v1579258502/ck3ob11exwvnuygwvrec.jpg  [2]: https://res.cloudinary.com/eightcruz/image/upload/v1579258519/k0s5nkv7xgmozdybf2o2.jpg  [3]: https://res.cloudinary.com/eightcruz/image/upload/v1579258810/vrjgg2rnynku3r5hc5on.png'],\n",
       " ['5',\n",
       "  'string을 datetime형식으로 바꾸는 방법 리스트 안에 `\"Jun 1 2005 1:33PM\"` `\"Aug 28 1999 12:00AM\"`  같은 스트링이 엄청 많이 있고 이 스트링을 전부 datetime 형식으로 바꿔 DB에 저장하려고 합니다.  스트링을 datetime형식으로 으로 바꾸려면 어떻게 해야 하나요?'],\n",
       " ['5',\n",
       "  'if-else문을 한 줄에 쓰는 법 ``` if count == N:  count = 0 else:  count = N + 1 ```  이 코드를 한 줄에 쓰는 방법이 없나요?  object-C에서는  ``` count = count == N ? 0 : count + 1; ``` 같이 쓸 수 있었는데 저걸 정확히 뭐라고 하는지 모르겠어요.. '],\n",
       " ['1',\n",
       "  '위치를 기록하는동안 액세스 위반이 발생했습니다 이렇게 코드를 짰는데 자꾸 \"0xC0000005: 0x0033B000 위치를 기록하는 동안 액세스 위반이 발생했습니다.\"라고 뜨네요 ``` while (result != -1) {  a++;  sprintf(s, \"%d\", a);  strcat(hanu, s);  strcat(name, hanu);   } ``` 참고로 변수들 선언은 이렇게 했고, result 변수 관련 코드는 그 밑에 더 있습니다... ``` int a = 0;//숫자올리기에 쓸 것 char s[256];//a를 문자열로 변환할 변수 char name[10] = \"kimhanu\"; char hanu[10] = \".hanu\"; ```'],\n",
       " ['3',\n",
       "  '안드로이드 스튜디오   배열 저장 ``` public void handleMessage(android.os.Message msg){  Timer buttonTimer = new Timer();   if(msg.what == BT_MESSAGE_READ){  String readMessage = null;  try {  readMessage = new String((byte[]) msg.obj, \"UTF-8\");  } catch (UnsupportedEncodingException e) {  e.printStackTrace();  }   String[] readMessage1;  String[] array_word = new String[64];  readMessage1 = readMessage.split(\"\");  int j;   for(int i=0;i<readMessage1.length;) {  if(readMessage1[i]==\"7\") {  i++;  }  j=0;  array_word[j]=readMessage1[i];  j++;  i++;  }  ~~후략~~  ```  readMessage라는 String 변수로 아두이노에서 보내져온 64개의 값을 분리하는 소스를 만드려고 합니다.  시작과 끝을 모르기 때문에 아두이노에서 임의로 시작할 때  7 을, 끝난 이후에는  5 를 보냅니다. 즉, 7과 5 사이에는 64개의 1과 0으로 이루어진 값이 존재하는 것이죠. 그건 고정입니다.  이를 판단하기 위해서 readMessage1이라는 배열을 만들어서 readMessage를 먼저 찢었습니다.  그리고 array_word라는 배열을 만들고 readMessage1에서 먼저 i값을 증가시켜서 7을 찾습니다. 7을 찾았다면 바로 i값을 1 증가시키고 그 값을 array_word[0]부터 넣는 함수를 만드려고 합니다.  하지만 저렇게 하니까 튕기더군요....   조언 부탁드립니다.'],\n",
       " ['3',\n",
       "  '객체지향적으로 프로그래밍하기 질문 드립니다.( )  로 프로그래밍을 하다 궁금한게 있어서 질문 드립니다.  A.  , B. , C.  파일이 존재하고 있고,  A에는   ` public int a;` , `public int b;` 가 정의 되어있습니다.  위 두개는 B,C에서도 사용하고 싶습니다.  그래서 두 변수를 static 변수로 설정하여 B,C에서 A.a, A.b로써 사용하였습니다.  하지만 static변수는  객체지향적  이지 않다고 하더라구요.  그 이유는 뭔가요?   또, static을 사용하지 않고 객체지향적으로 위의 문제를 해결 할 수 있는 방법은 뭔가요?'],\n",
       " ['3',\n",
       "  '숫자왼쪽에 0붙여서 출력하고싶어요  발생하는 문제 및 실행환경 0001 ~ 9999까지  1을 0001로 출력하고 싶은데 가능할까요??'],\n",
       " ['3',\n",
       "  'jsp, dao로 값이 넘어갈때 오류 bbs. jsp   <%  BbsDAO bbsDAO = new BbsDAO();   ArrayList<Bbs> list = bbsDAO.getList(pageNumber);   for (int i = 0; i < list.size(); i++) {  %>   <tr>    <td><%=list.get(i).getBbsID()%></td>  <td>sdfsdfsdfsd</td>  <td><a href=\"view.jsp?bbsID=<%=list.get(i).getBbsID()%>\">  <%=list.get(i).getBbsTitle()%></a></td>   <td><%=list.get(i).getUserID()%></td>   <td><%=list.get(i).getBbsDate()%></td>   </tr>       BbsDAO.     public ArrayList<Bbs> getList(int pageNumber) {  String SQL = \"SELECT * FROM(SELECT BBS.*,ROW_NUMBER() OVER (ORDER BY BBSID) LIMIT_NUM FROM BBS )WHERE BBSID<? AND BBSAVAILABLE =1 AND LIMIT_NUM BETWEEN 1 AND 10\";  ArrayList<Bbs> list = new ArrayList<Bbs>();  try {  PreparedStatement pstmt = conn.prepareStatement(SQL);  pstmt.setInt(1, pageNumber);  rs = pstmt.executeQuery();  while (rs.next()) {     Bbs bbs = new Bbs();  bbs.setBbsID(rs.getInt(1));  bbs.setBbsTitle(rs.getString(2));  bbs.setUserID(rs.getString(3));  bbs.setBbsDate(rs.getString(4));  bbs.setBbsContent(rs.getString(5));  bbs.setBbsAvailable(rs.getInt(6));  list.add(bbs);  }    } catch (Exception e) {  e.printStackTrace();  }  return list;  }  bbs.jsp에서 BbsDAO로 list를 호출해서 게시판을 보여주는 코드입니다. 그런데 게시물 등록한 뒤에 보면 게시물이 안보여요 여기 부분이 문제인거같은데 제가 실험해본 결과 list.size()에서 add가 안되서 리스트 크기가 0인거거 같습니다.  전제조건 : 1. 쿼리문은 디비에서 실행했을 때 잘 돌아갑니다.  2. 변수의 int, string 형식은 모두 일치 합니다.   3. 콘솔 창에는 어떠한 오류도 일어나지 않습니다.'],\n",
       " ['4',\n",
       "  'flask와     flask를 통해 웹페이지를 구현중입니다. flask의 app에  에서 동적으로 값을 받아올 방법이 있나요? 혹은  에서 db에 연결하는 방법이 있나요?  html에서 값을 받아오면 동적으로 값을 받아오지 못하는 것 같고, html에서 db에 연결하려면 php를 거쳐야 해서 불가능합니다.   -  에서 flask에 값을 전달하는 방법 혹은  -  에서 mysql에 연동하는 방법  이 있다면 알려주세요!    '],\n",
       " ['2',\n",
       "  '자식 클래스에서 부모 클래스 함수를 어떻게 부르죠? 자식 클래스에서 부모 클래스의 멤버 함수를 부를 수 있는 방법이 있나요? 밑에서 `call_print_in_Base`를 어떻게 구현할 수 있나요?   소스코드 ``` class Base{ public:  void print() { cout << \"i m base!\" << endl; } };  class Derived : public Base{ public:  void print() {  call_print_in_Base() ///<-여기  cout << \"i m Derived!\" << endl;  } }; ```'],\n",
       " ['5',\n",
       "  '  문자열을 정수로 변환하려고 할 때, 숫자가 아닌 문자가 있으면 에러가 발생 while(correct_count<10):   question(name)   answer = int(input(\"답을 입력하세요: \"))  count = count + 1  if(answer == None):  -------------> 여기 이거 고쳐야하는데    print(\"입력 에러\")  정수입력을 하지않고 엔터를 눌렀을때  ![이미지][1]    [1]: https://res.cloudinary.com/eightcruz/image/upload/v1498209061/ig8ezch6cbi4ognmuyij.png  이렇게 되요..혹시 어떻게 해야할까요?'],\n",
       " ['4',\n",
       "  '  이미지 슬라이드 질문입니다 ``` function right1() {  var x = document.getElementsByClassName(\"aa\");  var i;  for(i = 0; i < x.length; i++) {  x[i].style.transform += \"translateX(167px)\";  } } ```  이미지 슬라이드를 이렇게 만들었는데 궁금한게 마지막 이미지가 그 이미지들을 감싸고 있는 `div`끝에 도착하면 다시 처음 이미지부터 이동을 시키도록 하고 싶은데 `if`문으로 돌아갈 방법을 잘 모르겠습니다. 도와주세요!'],\n",
       " ['5',\n",
       "  '  질문이요. ![이미지][1] ![이미지][2]  안녕하세요. 지금 라즈베리를 이용해서  을 공부중인 학생입니다.  지금 제가 파일을 읽어와서 그 파일안의 xml 태그들중에서 위에있는 특정문장들을   불러와서 출력을 하고싶은데요.  위 문장처럼 되있는게 여러개가 있어서 그림과같이 코딩을 해서   ROUTE_NO 나 EXTIME_MIN 한종류씩은 불러와지는데   두종류를 한번에 불러오고 싶은데   어떤식으로 코딩해야 한번에 불러올수 있나요..제가 시작한지 몇일 안된 초보라   질문이 허접한점 죄송합니다.    [1]: https://res.cloudinary.com/eightcruz/image/upload/v1509619307/xvk27xgvbpshrnya1t3m.png  [2]: https://res.cloudinary.com/eightcruz/image/upload/v1509619953/cneu8syqaffzuapyo241.png'],\n",
       " ['5',\n",
       "  '파이썬 BeautifulSoup 정규표현식으로 찾기 ![이미지][1]  사진과 같은 QTY칸의 숫자를 일괄 수정하고 싶습니다.  각 QTY칸의 코드는 txtAvailableQTY_0, txtAvailableQTY_1,txtAvailableQTY_2 처럼 뒷자리 숫자만 바뀌는 코드입니다.  해서 정규표현식을 사용하여 코드를 만들었는데 계속 에러만 납니다.  ``` html = driver.page_source soup = BeautifulSoup(html, html.parser ) QTY = soup.find(id=re.compile( rpQuickEdit_txtAvailableQTY_[0-9]{1,2} ))   for i in range(5):  if QTY is True:  driver.find_element_by_css_selector(QTY).click()  action = ActionChains( driver )  action.send_keys( Keys.BACKSPACE ).send_keys( 0 ).perform() ``` 코드를 이렇게 만들었는데 어느 부분이 문제인가요?  QTY칸의 숫자를 일괄 수정하고 싶습니다.  코드가 너무 길어서 짤랐는데 셀레니움과 웹드라이브도 사용중입니다.   [1]: https://res.cloudinary.com/eightcruz/image/upload/v1578447920/hms2zkuqhidrbjylokul.jpg'],\n",
       " ['3',\n",
       "  'delegation이 우리말로 해석하면 어떤 단어인가요?   Securtiy 관련 글을 읽고 있습니다.  delegate , delegation 단어가 많이 나오는데, 우리말로 뭐라고 해석하나요?   영어로 검색하니깐 클래스 간의 어떤 관계인것 같은데 잘 모르겠습니다. 아래는 원문입니다.  *** The most commonly used implementation of `AuthenticationManager` is `ProviderManager`, which ***delegates*** to a chain of `AuthenticationProvider` instances.   An `AuthenticationProvider` is a bit like an `AuthenticationManager` but it has an extra method to allow the caller to query if it supports a given Authentication type: *** [원문:  -security-architecture](https:// .io/guides/topicals/ -security-architecture/)'],\n",
       " ['3',\n",
       "  '윈도우에서 진행중인 프로젝트파일을 맥으로 불러왔습니다 ![이미지][1]    [1]: https://res.cloudinary.com/eightcruz/image/upload/v1493132898/jewc0izssmzj4pf7mtlb.png   윈도우에서 이클립스로 간단한 로그인체크 jsp을 구현한 것인데  맥에서 불러오니 스크립틀릿 부분만 저렇게 빨간줄이 나와서 실행이 안됩니다.  톰캣은 같은버전을 사용했고 mysql 커넥터 jar 파일도 다 추가했습니다.  스크립틀릿 코드가 들어간 jsp파일만 저렇게 빨간줄이 나오고  스크립틀릿 없이 html으로 이루어진 jsp파일은 실행이 가능합니다.  무엇이 문제일까요?  답변해주셔서 고맙습니다.'],\n",
       " ['4',\n",
       "  '함수의 arguments 객체와 3항 조건 식 사용에 대해 질문드립니다. 그림1. ![이미지][2]  그림2. ![이미지][1]   그림 1처럼 만약 빨간네모 처럼 selector 문자(예 : -=- ) 가 오지 않도록  그림 2처럼 소스코드를 변경/추가했는데,,  어떤 이유에서 조건식을 썼는지 궁금합니다.  [질문] 1) *l -1 은 배열의 마지막을 의미하는 건가요? (예 : [0,1,2] 에서 l -1 은 2 ) (l은 영어 소문자 \"엘\" 입니다)  2) i < l - 1 이 참이라는 의미가 무엇인가요?  3) 그래서, 참이면 selector, 거짓이면 \" \" 은 어떤 의미를 말하는 건가요?     [1]: https://res.cloudinary.com/eightcruz/image/upload/v1537259681/eb26zlngzb5fyo2fkqry.png  [2]: https://res.cloudinary.com/eightcruz/image/upload/v1537284552/jgydi86mylsmhabx7piv.png'],\n",
       " ['3',\n",
       "  '  정규식 관련 질문드립니다.  로 \"(한글,한글자음,영어,숫자,특수문자) + / + 품사태그\" 이런 형식만 추출을 하려고 하는데요  다른건 다 문제가 없는데 한글 자음이 추출이 안되서 질문드립니다. 혹시나 해서 유니코드로 바꿔서 추출하려고 했는데 그것도 마땅치가 않네요.. 도와주시면 감사하겠습니다! ``` package text;  import org.jetbrains.annotations.NotNull;  import  .io.*; import  .util.StringTokenizer; import  .util.regex.Matcher; import  .util.regex.Pattern;  public class makeWord2Vec {   public static void main(String[] args) throws IOException {   String path=\"C:\\\\\\\\Users\\\\\\\\skarl\\\\\\\\Desktop\\\\\\\\형태분석 말뭉치\\\\\\\\전체\";  File dirFile=new File(path);  File []fileList=dirFile.listFiles();  for(File tempFile : fileList) {  if(tempFile.isFile()) {  String name=tempFile.getName();  BufferedReader br = new BufferedReader(new FileReader(\"C:\\\\\\\\Users\\\\\\\\skarl\\\\\\\\Desktop\\\\\\\\형태분석 말뭉치\\\\\\\\전체\\\\\\\\\"+name));  BufferedWriter fw = new BufferedWriter(new FileWriter(\"C:\\\\\\\\Users\\\\\\\\skarl\\\\\\\\Desktop\\\\\\\\전체.txt\",true));  while (true) {   String line = br.readLine();  if (line == null) break;  if(line.contains(\"<\")||line.contains(\">\")) line = \"\";   //fw.write(line);  //if(line!=\"\")fw.write(\"\\\\r\\\\n\");   String matchLine = null;  Pattern regex=Pattern.compile(\"([a-zA-Z0-9!   %^&*()_+/., ?~…]|[\\\\\"]|[가-힣ㄱ-ㅎㅏ-ㅣ])+\\\\\\\\/+[A-Z]+\");  Matcher regexMatcher=regex.matcher(line);  while(regexMatcher.find()) {  matchLine = regexMatcher.group();  fw.write(matchLine + \" \");  }  }  br.close();  fw.close();  }  }  } }  ```'],\n",
       " ['3',\n",
       "  ' 로 XML 파일 작성 질문입니다. ``` //여기에 코드를 입력하세요  import org.w3c.dom.Attr; import org.w3c.dom.Document; import org.w3c.dom.Element; import org.w3c.dom.NodeList;   import javax.xml.parsers.DocumentBuilder; import javax.xml.parsers.DocumentBuilderFactory; import javax.xml.parsers.ParserConfigurationException; import javax.xml.transform.OutputKeys; import javax.xml.transform.Transformer; import javax.xml.transform.TransformerException; import javax.xml.transform.TransformerFactory; import javax.xml.transform.dom.DOMSource; import javax.xml.transform.stream.StreamResult; import java.io.*;  public class Xml2Csv_2 {  public static void main(String[] args) {   String csvFile = \"bookinfo.csv\";  BufferedReader bfReader = null;  String line = \"\";  String csvSplit = \",\";   try {   DocumentBuilderFactory dbFactory = DocumentBuilderFactory.newInstance();  DocumentBuilder domBuilder = dbFactory.newDocumentBuilder();  Document dom = domBuilder.newDocument();   bfReader = new BufferedReader(new FileReader(csvFile));  while ((line = bfReader.readLine()) != null) {   String[] bookArry = line.split(csvSplit);   String bi0 = bookArry[0];  String bi1 = bookArry[1];  String bi2 = bookArry[2];  String bi3 = bookArry[3];  String bi4 = bookArry[4];  String bi5 = bookArry[5];   Element booklist = dom.createElement(\"bi0\");  dom.appendChild(booklist);   /* Element book = dom.createElement(bi1);  booklist.appendChild(book);   Attr titleAttr = dom.createAttribute(bookArry[2]);  Attr authorAttr = dom.createAttribute(bookArry[3]);  Attr translatorAttr = dom.createAttribute(bookArry[4]);  Attr publisherAttr = dom.createAttribute(bookArry[5]); */   TransformerFactory tfFactory = TransformerFactory.newInstance();  Transformer tr = tfFactory.newTransformer();   tr.setOutputProperty(OutputKeys.ENCODING, \"UTF-8\");  tr.setOutputProperty(OutputKeys.INDENT, \"yes\");  DOMSource source = new DOMSource(dom);  StreamResult result = new StreamResult(newFileOutputStream(newFile(\"test_xml.xml\")));   tr.transform(source, result);   }   }catch (FileNotFoundException e) {  e.printStackTrace();  } catch (IOException e){  e.printStackTrace();  } catch (ParserConfigurationException e){  e.printStackTrace();  } catch (TransformerException e){  e.printStackTrace();  }  finally {  if (bfReader != null);  try {  bfReader.close();  } catch (IOException e) {  e.printStackTrace();  }  }  } }  ```   CSV파일을 읽어서 배열에 넣은 뒤 그 값을 XML 파일을 만들면서 Element에 넣고싶은데 createElement 및 createAttribute가 먹지 않습니다.  어떻게하면 배열에 있는 값을 넣을 수 있을까요??'],\n",
       " ['3',\n",
       "  '  캔버스를 패널에 붙일 수 있을까요?   setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);   setBounds(100, 100, 500, 500);      contentPane = new JPanel();   contentPane.setBorder(new EmptyBorder(5, 5, 5, 5));   setContentPane(contentPane);   contentPane.setLayout(new BorderLayout(0, 0));      JTabbedPane tabbedPane = new JTabbedPane(JTabbedPane.TOP);   contentPane.add(tabbedPane);      JPanel panel = new JPanel();   tabbedPane.addTab(\"사진 효과\", null, panel, null);      JPanel panel_1 = new JPanel();   tabbedPane.addTab(\"그림판\", null, panel_1, null);   panel.setLayout(new BorderLayout(0, 0));  JTabbedPane을 이용해서 두 가지 패널을 나누어 만들었습니다.   public class JYCanvas extends Canvas{   int x=50;   int y=50;   int width=7;   int height=7;      Color color=Color.black;      public void paint(Graphics g){    g.setColor(color);    g.fillOval(x, y, width, height);   }      public void update(Graphics g){    paint(g);   }  }   panel_1에 canvas를 add하고 싶은데 안 되네요. 혹시 방법이 있을까요?'],\n",
       " ['4',\n",
       "  'localStorage에 배열을 저장하고싶은데 어떻게해야하죠?  ``` var names=new Array();  names[0]=prompt(\"New member name?\"); ``` 그냥 이렇게해도되지만 지금 localStorage에 저장해야해서  ``` var localStorage[names]=new Array(); localStorage.names[0]=prompt(\"New member name?\"); ``` 이렇게했을때 안됩니다. 뭐가 잘못된건가요  '],\n",
       " ['1',\n",
       "  'stack 영역과 heap영역 질문입니다. heap영역과 stack영역에 대해서 궁금한점이 있습니다.  int main(void) { int *p2 =(int*)malloc(sizeof(char) * 10); // 40바이트 할당됨.  printf(\"%d\\\\n\",&p2); // p2주소를 100이라고 가정합니다.  int *p3 = p2 +11; // 4바이트 할당됨.  printf(\"%d\\\\n\",&p3); // p3의 주소가 111번지가 나옵니다.  return 0; }  p2는malloc에 의해 할당되어서 heap영역에 할당되고 p3는 stack에 할당이 된다고 배운것같습니다.  그렇다면 &p2와 &p3, 즉 각각의 주소가 인접한 영역이 아니여야 할텐데 visual studio에서 디버깅해보니 주소가 인접한 영역으로 나타납니다.  heap 영역과 stack 영역의 구분을  visual studio에서 어떻게 확인하는지 궁금합니다.  관련된 자료가 있을까요?'],\n",
       " ['4',\n",
       "  '  select box 사용 질문좀 드려도 될까요?  로또 추첨 만들고 있는데 막히는 부분이 있어서 질문드립니다 !  일단 첫화면에 보여지는 index.html 에    <form name=\"form\">  <select id=\"selectBox\" name=\"selectBox\" onchange=\"OnChange();\">   <option>1</option>  <script>   for(i=2;i<861;i++){   document.write(\"<option>\"+i+\"</option>\");   }  </script>  </select>  </form>   <script>bbb= (\" selectBox\").val();</script>  <script id=\"ddd\" defer=\"\" type=\"text/ \" document.write( src=\"\" )></script>  <script type=\"text/ \">   document.getElementById(\"ddd\").src=\"http://lotto.kaisyu.com/api?method=get&gno=\"+bbb+\";callback=loadlot\";  </script>  <p style=\"position:absolute;top:calc(50% + 100px);width:100%;\">   <input type=\"text\" id=\"inputnum\" value=\"5\" size=\"2\">번 <span class=\"key\" onclick=\"count()\">시작</span>  </p>   <section id=\"winner\" class=\"shadow\">   <h2 id=\"lottok\">loading...</h2>   <div class=\"output\" id=\"output0\"></div>   <div class=\"output\" id=\"output1\"></div>   <div class=\"output\" id=\"output2\"></div>   <div class=\"output\" id=\"output3\"></div>   <div class=\"output\" id=\"output4\"></div>   <div class=\"output\" id=\"output5\"></div>   <div class=\"output\" style=\"box-shadow:none; color: 000;\">+</div>   <div class=\"output\" id=\"output6\"></div>  </section>  <div id=\"stats\"></div>   <ol id=\"lottotable\"></ol>   이러한 소스가 있습니다. 처음 페이지에 접속하면 맨밑 section winner에 로또 1회 번호가 자동으로 보여지게 됩니다   이 섹션은 main.js에 있는 함수를 통하여 이루어지게 되는데 현재 제가 막히는 부분은  위에 selectbox를 통하여 1회~860회까지 박스를 만들어 둔 상태이고 만약 10회를 클릭하면 밑에 section winner에 로또 1회 번호가   로또 10회 번호로 바뀌게끔 하고 싶습니다. 그렇기에 <script>bbb= (\" selectBox\").val();</script> 를 통하여 설렉트박스에서 선택한 벨류값을  끌어와서 기존 주소와 조합해서 src로 쓰게끔 만들어두었는데 문제는 이미 페이지가 한번 로딩된 상태라 밑의 당첨번호가 바뀌질 않습니다  그래서 생각한게 첫번째 방법은 onChange를 통하여 이벤트를 발생시키는 방법인데 도저히 감이 안잡히고  두번째 방법은 설렉트 박스 선택시 해당 선택값을 저장해두고 새로고침후 그 값을 넘겨주는건데 이것도 현재 막히고 있습니다  c++만 하다가 nodejs 하려니 너무 막히네요   좋은 방법이 없을까요?'],\n",
       " ['2',\n",
       "  ' 에서 정수를 입력받을때 공백없이 한번에 입력받는법 정수입력받을때 C에서는 scanf(\"%1d\",&배열) 이런방법으로 한번에 입력받는게 가능한데 C++에서 scanf를 안쓰고 한번에 공백없이 받는방법 없나요? 문자열로 받아서 변환해주는거 밖에 모르겠는데 너무 번거로운거 같네요  '],\n",
       " ['1',\n",
       "  '  왕초보 질문드립니다 여기서 5뒤로 누르면 컴퓨터가 뭘냇는지 안나오게는 어떻게해야하나요??   include <stdio.h>  include <stdlib.h>  include <time.h>  int main(void) {  int comp = 0, user = 0;  int win = 0, draw = 0, lose = 0;   while (1) {   printf(\"입력 (1,가위, 2바위, 3보, 4종료)\");   scanf(\"%d\", &user);    if (user == 4) {    //종료조건    printf(\"Game Over\\\\n\");    break;   }    else {    //게임만들때    switch (user) {    case 1:     printf(\"당신은 가위를 냈습니다.\\\\n\");     break;    case 2:     printf(\"당신은 바위를 냈습니다.\\\\n\");     break;    case 3:     printf(\"당신은 보를 냈습니다.\\\\n\");     break;    default:     printf(\"잘못입력했습니다. 다시 입력해주세요. \\\\n\");     break;    }   }    switch (user)     srand(time(NULL));   comp = rand() % 3 + 1; // 1~3    if (comp == 1)    printf(\"컴퓨터는 가위를 냈습니다 \\\\n\");   else if (comp == 2)    printf(\"컴퓨터는 바위를 냈습니다 \\\\n\");   else if (comp == 3)    printf(\"컴퓨터는 보를 냈습니다 \\\\n\");    if (user == comp) {    printf(\"비겼습니다. \\\\n\");    draw++;   }   if ((user == 1 && comp == 3) ||    (user == 2 && comp == 1) ||    (user == 3 && comp == 2)) {    printf(\"당신이 이겼습니다 \\\\n\");    win++;   }   if ((user == 1 && comp == 2) ||    (user == 2 && comp == 3) ||    (user == 3 && comp == 1)) {    printf(\"당신이 졋습니다 \\\\n\");    lose++;   }  }   return 0; }'],\n",
       " ['5',\n",
       "  '  입력값 정수판정 함수 기초적인 질문입니다 안녕하세요 최근  을 배우기 시작한 초보입니다. def를 써서 True or False를 반환 받은 뒤에 그 반환 받은 True / False에 따라 다시 다른 값을 반환하는 함수를 만들고 싶은데 어떻게 해야되는지 모르겠습니다.  예를 들자면  ``` def isInt(x):  if int(x) == x:  return True  else:  return False  x = input(\"Enter an integer: \")  ```   여기서 x가 정수인지 아닌지를 판단한 뒤 False 값을 반환받으면(정수가 아니면) 사용자가 올바른 정수를 입력할때까지 다시 문자를 입력받게끔 하는 다음 함수를 만들고 싶습니다.  어떻게 해야할까요? 도움 주시면 감사하겠습니다. '],\n",
       " ['2',\n",
       "  '  헤더파일 관련 질문입니다! 간단한 게임을 제작하고있는데 어떤분 보니까 필요한 헤더들 <windows.h> <list> <crtdbg> 등등을 포함한 종합헤더파일을 만들더군요  필요한 헤더파일만 꼭 집어내서 포함시키는거랑 위처럼 종합헤더파일을 만들어서 포함시키는거랑 둘다 어떤 장단점이있을까요..? '],\n",
       " ['5',\n",
       "  '  행렬 계산에서 질문입니다. 선택하지 않은 항목까지 같이 값이 바뀝니다. ``` def sumMatrix(A,B):  answer = [[0]*len(A[0])]*len(A)    for i in range(len(A)):  for j in range(len(A[0])):  a=A[i][j]+B[i][j]  answer[i][j]=a  print(answer)  print(i,j,a,answer[i][j],A[i][j],B[i][j])  return answer  print(sumMatrix([[1,2], [2,3]], [[3,4],[5,6]])) ```  결과 ``` [[4, 0], [4, 0]] 0 0 4 4 1 3 [[4, 6], [4, 6]] 0 1 6 6 2 4 [[7, 6], [7, 6]] 1 0 7 7 2 5 [[7, 9], [7, 9]] 1 1 9 9 3 6 [[7, 9], [7, 9]] ```  여기서 answer[0][0]의 값만 지정되지 않고, 어째서 answer[1][0]의 내용이 바뀌는지 아무리 생각해도 모르겠습니다. 도와주십시오  '],\n",
       " ['3',\n",
       "  '파일에서 줄바꿈 지우는 방법  에서 텍스트 파일을 읽을때 모든 줄바꿈을 없애려면 어떻게해야할까요?  ``` String text = readFileAsString(\"textfile.txt\"); text.replace(\"\\\\n\", \"\"); ``` 이런식으로 해봤는데 소용이없네요.  '],\n",
       " ['3', '안드로이드에서 디바이스에 진동울리게 하는법 안드로이드 디바이스에 진동울리게는 어떻게하나요?  '],\n",
       " ['5',\n",
       "  ' 에서 대화형모드(IDLE)와 파일로 실행할 때의 차이? a= Lee   a.upper()  a.find( e )  를 IDLE에서 대화형으로 한줄한줄 실행할때는 한줄 실행하고 그 결과가 즉시 나타납니다. 위의 예에서 a.upper() 결과는 LEE, a.find( e )는 1 이렇게 나타납니다. 그런데 이 파일을 test. 로 저장후   test. 를 실행하면 아무 결과도 나타나질 않습니다.  이유가 무엇인가요?'],\n",
       " ['1',\n",
       "  '  테스크 케이스 만드는 문제 ![이미지][1]   ![이미지][2]   ![이미지][3]    [1]: https://res.cloudinary.com/eightcruz/image/upload/v1537714678/rmf5ip5pkedaidkbmrck.png  [2]: https://res.cloudinary.com/eightcruz/image/upload/v1537714686/j9px3uj7nhhypjwi1kov.png  [3]: https://res.cloudinary.com/eightcruz/image/upload/v1537714693/hecfc4oehtglfmo9jhp7.png  무슨 말인지도 잘 모르겠습니다.....  이해시켜주실 코딩 고수님들 도와주세요  '],\n",
       " ['2',\n",
       "  '  상속 변수 가려지기 부모 클래스의 a라는 변수 자식 클래스의 a라는 변수가 있으면 겹치지 않고 독립적인거죠 ?  자식 클래스에서 부모 클래스의 a 변수에 접근하려면 부모클래스명::a 로만 접근이 되는건가요? 그렇게 하지않으면 this->a, a든 자식 클래스의 a를 뜻하는거죠 ?  C 이나 다른언어처럼 this 포인터말고 base 포인터는 없나여 ?'],\n",
       " ['3',\n",
       "  ' 에서 함수포인터를 대체할만한건 뭔가요? 10줄정도 되는 메소드가 있는데요. 코드 몇줄 바꾸는것 같은 차이는 무시하고 거의 같은 일을하는 메소드를 몇개 더 만들고 싶어요. 함수포인터는 그런걸 거의 한줄로 대체하는데  에는 함수포인터가 없잖아요.  함수포인터를 대신할만한게 뭔가요?'],\n",
       " ['4',\n",
       "  'table 동적삭제 질문드립니다. 옵션을 선택하면 목록이 나오고 지우고 하는 화면을 만들고 있습니다.  옵션을 선택한 화면을 테이블로 만들었는데 검색을 해보면 테이블은 tr을 이용하여 선택한 행을 지우라고 하는데 저는 한 테이블에 여러개의 tr을 갖고 있습니다.   그래서 행을 지우는 \" buytable.deleteRow(buytable.clickedRowIndex); \" 이 부분을 여러개 추가해서 만들어 보니 한번에 지워지기는 하는데 삭제버튼이 사라지지 않습니다.   그리고 선택한 행이 아닌 처음 입력한 값부터 삭제가 되구요.  선택한 행을 이용하는 방법 말고 다른 방법은 무엇이 있나요?  div로 바꿔서도 만들어 봤는데 div는 remove함수를 사용하여 지우고 다시 목록을 클릭하면 데이터가 들어가지 않는 현상이 있었습니다..  ``` <h4>옵션</h4> <form id=\"saleForm\" action=\"/sale\" method=\"post\">  <select id=\"selectOption\" name=\"selectOption\" class=\"form-control\" style=\"display: block; width: 100%; height: 34px; padding: 6px 12px; font-size: 14px; line-height: 1.42857143; color:  555; background-color:  fff; background-image: none; border: 1px solid  ccc; border-radius: 4px;\">  <option value=\"\">선택하세요</option>  <c:forEach var=\"buyOption\" items=\" {buyOption}\">  <option id=\" {buyOption.buyOptionCode}\" value=\" {buyOption.optionPrice}\"> {buyOption.optionName} (￦   {buyOption.optionPrice})</option>  </c:forEach>  </select>  <br>  <table id=\"buytable\" border=1px cellpadding=0> </table>  <script type=\"text/ \">  var strHTML = \"\";  var count = 1;  // selectBox누르면 옵션 나오는 changefunction   (\" selectOption\").change(function () {  var option =  (\" selectOption option:selected\").text(); // 선택한 값 text(상품명)  var price =  (\" selectOption option:selected\").val(); // 선택한 값 value(가격)  var langSelect = document.getElementById(\"selectOption\");  var num = langSelect.options[langSelect.selectedIndex].id; // 선택한 값 id(상품코드)   //  strHTML += \"<table id= buytable  border= 1  cellpadding= 0 >\";  strHTML += \"<th>옵션 \" + count + \"</th>\";  strHTML += \"<tr><input type=text name=item_index id=\" + num + \" readonly value=\" + num + \" style=\\\\\"display:none\\\\\">\";  strHTML += \"<td colspan= 2 >\" + option + \"</td></tr>\";  strHTML += \"<tr bgcolor=  E2E2E2  align= center >\";  strHTML += \"<td style= width:40% >\" + price + \"</td>\";  strHTML += \"<td style= width:10% ><input class=form-control type=number name=itemnum min=1></td>\";  strHTML += \"</tr>\";  strHTML += \"<tr><button class=mybtn type=button onClick=\\\\\"delRow()\\\\\" name=dyntbl1_delRow><i class=\\\\\"fas fa-trash-alt\\\\\"></i></button></tr>\";   // strHTML += \" </table>\";   document.getElementById(\"buytable\").innerHTML = strHTML;  count++;   // onmouseover이벤트가 발생될때 fncOnMouseOver함수를 호출한다.  strHTML.onmouseover = function () { fncOnMouseOver(this.rowIndex) };    // selectbox 초기화. 옵션의 첫 번째 값 구함.(선택해주세요로 이동)   (  selectOption ).find( option:first ).attr( selected ,  selected );    });   function delRow() {  // table에서 지정한 줄(tr)을 rows 컬렉션에서 삭제한다.  // divTest.deleteRow(buytable.clickedRowIndex);  buytable.deleteRow(buytable.clickedRowIndex);  buytable.deleteRow(buytable.clickedRowIndex);  buytable.deleteRow(buytable.clickedRowIndex);  buytable.deleteRow(buytable.clickedRowIndex);  }  </script> </form> ```'],\n",
       " ['4',\n",
       "  '  앱 개발 관해서 질문 드립니다. 원래 프로그래밍할 때 주로 스위프트언어를 사용해서 했는데 요즘 보니까   얘기가 많이 나와서 리액트(React)나 퓨즈(Fuse) 같은 여러 기술들을 공부해보려고 해요. 공부하기 전에 좀 더 알아야할 게 많은 것 같아 이렇게 질문드리게 되었습니다.   *  로 앱을 개발하게 될 시 윈도우, 안드로이드, iOS 세 플랫폼에서 모두 돌아가는 앱을 만들 수 있나요?  * 네이티브 앱 만큼 리소스 사용이 효율적인가요?  * 만약 가능하다면 주로 어떤 프레임워크나 개발도구를 사용하나요? '],\n",
       " ['1',\n",
       "  '  더블링크드 리스트 더블 링크드 리스트에서의 노드 삭제에 대해서 궁금한 점이 있습니다.  소스코드)   void DLL_RemoveNode( Node** Head, Node* Remove )  {  if ( *Head == Remove )   {  *Head = Remove->NextNode;     if ( (*Head) != NULL )   (*Head)->PrevNode = NULL;   }  else // 삭제할 노드가 리스트의 헤드가 아닌 경우  {  Node* Temp = Remove;   if ( Remove->PrevNode != NULL )  Remove->PrevNode->NextNode = Temp->NextNode;   if (Remove->NextNode != NULL)  Remove->NextNode->PrevNode = Temp->PrevNode;  }    Remove->PrevNode = NULL;   Remove->NextNode = NULL;   }    출처) 뇌를 자극하는 알고리즘 - 더블 링크드 리스트 파트  -------------------------------------------------------------------------------------  노드 삭제의 경우 2가지로 나누어 처리합니다.  삭제할 노드가 리스트의 헤드일 경우와 아닐 경우로 나누어집니다.  첫번째로, 삭제할 노드가 리스트의 헤드일 경우입니다.  삭제할 노드(헤드)가 가리키는 다음 노드가 존재할 경우 삭제할 노드(헤드)가 가리키는 다음 노드가 가리키는 이전 노드 포인터를 NULL로 초기화시켜줍니다.  두번째로, 삭제할 노드가 리스트의 헤드가 아닌경우입니다.  삭제할 노드가 가리키는 다음 노드가 가리키는 이전 노드 포인터를 삭제할 노드가 가리키는 이전 노드를 가리켜줍니다. 그리고, 삭제할 노드가 가리키는 이전 노드가 가리키는 다음 노트 포인터를 삭제할 노드가 가리키는 다음 노드를 가리켜줍니다.  그런 후, 삭제될 노드가 가리키는 이전 노드와 다음 노드 포인터를 NULL로 초기화 시켜줍니다.  -----------------------------------------------------------------------------------------------------------------------   <b>여기서 궁금한 점이 생깁니다.</b>  2번쨰의 단계에서 삭제할 노드가 리스트의 헤드가 아닌 경우입니다. 여기서 삭제할 노드의 이전 노드의 존재성은 확보 된 거 아닌가요 ? 삭제할 노드의 다음 노드의 존재성은 확보를 못하구요.  그래서 소스코드에서도 삭제할 노드의 다음 노드의 존재성을 체크합니다.  해당 부분 소스코드)  if (Remove->NextNode != NULL)  그런데 전자의 경우는 소스코드에서는 삭제할 노드의 이전 노드가 있는지 없는지(NULL 체크)를 왜 하는건가요 ?  단순히 가독성때문인가요 ?   해당 부분 소스코드)  if ( Remove->PrevNode != NULL )  그리고 1~2단계를 거친 후 삭제할 노드가 가리켰던 이전 노드, 다음 노드의 포인터를 NULL로 초기화 시켜줍니다. 왜 초기화 시켜주나여 ? 어쩌피 free로 정리해줄 건데 말이죠 ? 가독성의 문제인가요 ?   해당 부분 소스코드)  Remove->PrevNode = NULL;   Remove->NextNode = NULL;   Temp라는 임시변수도 왜 쓰는지 모르겠네요. 변수 스왑할때처럼 필요한 경우도 아닌 것 같은데 말이죠. 임시변수 없이 소스코드 고쳐도 정상 작동하더라구요.'],\n",
       " ['5',\n",
       "  'flask sqlalchemy order by (sort 작업 ) ``` players = db.session.query(Player).join(Nation, Player.nation_id == Nation.nation_id).filter(Nation.nation_id == team_id).order_by(Player.position.asc(),Player.player_name.asc()).all() ```  이처럼 `players` 변수에 `sqlalchemy`를 사용하여 `position`과 `player_name`의 정보를 정렬해두었습니다.  이중에(선수중에) `entry` 컬럼의 `boolean` 값이 `1`인 아이들이 `html <table>`의`<tbody>`에서 맨위로 올라오게끔 어떻게 작성해야할까요?  예를들어 선수가 20명이고 선수명과 포지션명에 따라서 정렬 되어 있는 상태에서 `entry` 컬럼의 `boolean` 값이 1인 선수가 맨위로 11명 오게끔 하려면 어떻게 해야되나요?'],\n",
       " ['5',\n",
       "  'flask 에서 route 지정을 해도 404 에러 발생합니다. blog를 만들면서  과 flask를 공부 중입니다.  아래 이미지의 구조에서 app = Flask(__name__)와 같은 모듈이 아닌 하위 폴더(app/views/post.py)에서 사용할 경우 404 에러가 발생하고 있습니다.  route경우 from ... import app 을 통해서는 정상적으로 route를 사용하지 못하나요?  테스트를 위해 __init__.py에서 app = Flask(__name__) 아래에서 route 지정할 경우 정상 동작은 하였습니다.  ![이미지][1]    [1]: http://res.cloudinary.com/eightcruz/image/upload/v1484058323/pxjf4kztvenrjbxgpnvs.png  코드 server.py ``` from app import app if __name__ ==  __main__ :  app.run(debug-True) ``` app/__init__.py ``` from flask import Flask app = Flask(__name__) from app.views import * ``` app/views/post.py ``` from app import app  app.route( / ) def index():  return  index test  ```'],\n",
       " ['4',\n",
       "  ' 를 이용하여 html 작성할 때 특수 기호 이미지 첨부 드리는 것처럼 그냥 pc에 있는 특수 기호로 화살표를 문자열로 집어 넣어서 웹에 표시했는데 위, 아래 방향은 굵게 나오는데 대각선 화살표들은 얇게 표시가 되더라구요 혹시 다 동일하게 굵은 화살표로 표시하려면 어떤 방법이 있을까요?       ![이미지][1]  [1]: https://res.cloudinary.com/eightcruz/image/upload/v1561597629/i3ontb8fcclieri2kv2d.png'],\n",
       " ['3',\n",
       "  '이 쿼리문좀 알려주세요. 여기 있는 쿼리문들 좀 설명 좀 해주실 수 있을까요?  웹 게시글 페이징 하려고 알아본건데.   알려주실 수 있을까요?  ``` <게시글 검색 쿼리> String sql = \"SELECT * from ( \";        sql +=\"  SELECT \";        sql +=\"    rownum:= rownum+1 as rownum,t.* \";        sql +=\"  FROM \";        sql +=\"   test t,(select  rownum:=0) rownum \";        sql +=\" where 1=1\";        if(!\"\".equals(startDate)){         sql +=\" and time_stamp between ? and ? \";        }        if(!\"\".equals(fileName)){         sql +=\" and name like ?\";        }        if(!\"\".equals(word)){         sql +=\" and story like ?\";        }        sql +=\" ) a \";        sql +=\" where rownum between ? and ? \"; ```   ``` <게시글 카운트 쿼리> String sql = \"SELECT count(*) from ( \";     sql +=\"  SELECT \";     sql +=\"    rownum:= rownum+1 as rownum,t.* \";     sql +=\"  FROM \";     sql +=\"   test t,(select  rownum:=0) rownum \";     sql +=\"  where 1=1 \";     if(!\"\".equals(startDate)){      sql +=\" and time_stamp between ? and ? \";     }     if(!\"\".equals(fileName)){      sql +=\" and name like ?\";     }     if(!\"\".equals(word)){      sql +=\" and story like ?\";     }     sql +=\" ) a \"; ``` '],\n",
       " ['2',\n",
       "  'bool타입 false < true”는 항상 참인가요?  발생하는 문제 및 실행환경 * `false < false` * `false < true` * `true < false` * `true < true` 같이 bool타입의 비교는   표준으로 정해진 게 있나요?  제 컴퓨터에서는(Centos 7,  ) 이렇게 나오는데 다른 컴퓨터에서도 무조건 똑같은 결과가 나오는지 궁금합니다  * `false < false` = `false` * `false < true` = `true` * `true < false` = `false` * `true < true` = `false`    '],\n",
       " ['5',\n",
       "  ' //cmd에서  파일을 받아 클래스에서 객체를 생성하는 방법 안녕하세요.  을 공부하고 있어요.  실행창을 아직 잘 못 다룹니다.   이제 객체 지향 프로그래밍을 배우고 있는데, 보고 있는 자료를 아무리 뒤져도 알 수가 없네요!  ``` class Character(object):  pass ``` 실행창에서 위 코드가 적힌  파일을 실행한 뒤 객체를 새롭게 생성할 수 있다고 알고있는데, 어떻게 해야할 지 잘 모르겠어요.   >>> from (클래스이름) import *   >>> ch1 = ....  이런식으로 하는 방법이요!  해보려고했는데,  from 은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는 배치 파일이 아닙니다. 라고뜨네요.  도와주시면 감사합니다.^^'],\n",
       " ['5',\n",
       "  'cannot import name  keys  오류 이게 왜 뜨는걸까요?? 분명 따라했는데. ![이미지][1]    [1]: https://res.cloudinary.com/eightcruz/image/upload/v1578893767/cvdpiiqgyrrac1f6fhev.png  유튜브 보며 똑같이 따라했는데 유튜버는 잘되는데 저는 `ImportError: cannot import name  keys ` 오류가 자꾸 나요.  부탁드립니다 선생님들'],\n",
       " ['4',\n",
       "  ' 에서 부동소숫점 연산 오차를 보완 할 라이브러리가 있는지요? 보통 프로그래밍언어에서 부동소숫점 연산시 오차가 발생합니다.  ``` var x = 0.2 + 0.1; // 0.3 console.log(x) // 0.30000000000000004  var y = 0.1 * 0.2; // 0.02  console.log(y) // 0.020000000000000004  ```  이런 오차를 보완하기 위해 다음과 같은 함수를 사용합니다.  ``` var fpCalc = function (op, x, y) {  var xexp = Math.pow(10, String(x).length - String(x).indexOf( . ) - 1),  yexp = Math.pow(10, String(y).length - String(y).indexOf( . ) - 1);  var tens = Math.max(100, xexp, yexp);  var n = 0;  switch(op) {  case  * : n = x * y;  break;  case  - : n = x - y;  break;   case  + : n = x + y;  break;  case  / : n = x / y;  break;  default:   return NaN;  }  return Math.round(n * tens) / tens; };  console.log(fpCalc( + , 0.1, 0.2)); console.log(fpCalc( + , 707.4, 226.2)); console.log(fpCalc( * , 0.1, 0.2)); console.log(fpCalc( / , 214500, 1.1)); ``` 다수 복잡한데, **혹시 다른 방법이나 라이브러리가 있는지 알고 싶습니다.**'],\n",
       " ['1',\n",
       "  '  알고리즘 문제 좀 도와주세요!! 정올 준비중 입니다!! 코드 좀요!!! 깊이우선탐색과 너비우선탐색 (bfsdfs.cpp)    문제 그래프와 그래프를 이루고 있는 한 정점이 주어질 때, 그 정점으로부터 깊이 우선 탐색과 너비 우선 탐색을 하고 탐색한 순서대로 정점들을 출력하는 프로그램을 작성하시오. 만약 한 정점에서 갈 수 있는 정점이 여러 개일 경우 알파벳 순으로 빠른 정점을 우선한다.     입력 입력 파일의 첫 번째 줄에는 정의 개수 N과 간선의 개수 E가 주어진다. 정점은 A부터 차례대로 알파벳 대문자로 표현된다. 이어 E줄에 걸쳐 간선들의 정보가 주어지는데 간선의 정보는 간선의 두 양끝 정점으로 표현된다. 마지막 줄에는 탐색을 시작할 정점이 주어진다. N은 26 이하의 자연수, E는 100 이하의 자연수이며 그래프는 하나로 연결되어 있다.     출력 출력 파일의 첫째 줄에는 깊이 우선 탐색을 한 결과를, 둘째 줄에는 너비 우선 탐색을 한 결과를 출력한다.     예제 입력  7 9  A B  B E  A E  B C  E F  C F  C D  D G  G F  A      예제 출력  ABCDGFE  ABECFDG    '],\n",
       " ['5',\n",
       "  '도와주세요! IndentationError: unindent does not match any outer indentation level   발생하는 문제 및 실행환경 이 코드를 실행하면 에러가 뜹니다   왤까요?   소스코드 ``` import sys  def Factorial(n):   Return factorial  result = 0  for i in range (1,n):  result = result * i  print \"factorial is \",result  return result ```   에러내용 IndentationError: unindent does not match any outer indentation level '],\n",
       " ['2',\n",
       "  '[   fstream write ] string 작성시 마지막 글자에 \\\\0을 삽입하려면 어떻게 해야할까요? 아래 코드는 파일에 쓰여있는 Customer라는 글자를 Admin이라는 글자로 바꾸는 코드입니다.  끝이 NULL로 잘 처리가 안 된것인지 Admin이 아니라 기존의 텍스트(Customer)와 겹쳐서 Adminmer가 되어버립니다.  Customer의 글자수가 더 많기 때문에 Admin에서 Customer로 바뀌는데는 지장이 없습니다.   바꾸기 전의 글자수가 바꾸고 싶은 글자수보다 이처럼 적은 경우는 문자의 뒷 부분이 기존 글씨와 글씨가 겹치는데 어떻게 해야할까요?   NULL을 제대로 삽입을 해야할 거 같긴한데.. 어찌해야할지 모르겠네요.  (Admin + 띄어쓰기가 아니라 딱 Admin까지만 나오게 하고 싶습니다.)  ```  fstream fs;  fs.open(getLoginedID() + \".dat\", /*fstream::binary |*/ fstream::in | fstream::out);   string str((istreambuf_iterator<char>(fs)), istreambuf_iterator<char>());  size_t pos = str.find(\"Customer\");   if (pos != string::npos) {   cout << \"string found at position: \" << int(pos) << endl;   fs.seekp(pos);   fs << \"\\\\nAdmin\";   fs.put( \\\\0 );   //fs.write(\"\\\\nAdmin\\\\0\", 7); 이 방법으로도 되지 않음  }  fs.close(); } ``` '],\n",
       " ['2',\n",
       "  '스트링 공백으로 split 하기  에서 단어들이 공백으로 나눠진 스트링이 있다고 할 때  스플릿 하기 제일 괜찮은 방법이 뭔가요?  빠른 방법 말고 보기 좋은 방법이요'],\n",
       " ['4',\n",
       "  'Node.js 로 실제 서비스 운영 중 발생하는 문제  안녕하세요.  node.js 로 실제 서비스를 운영 중이며, 동시접속자 최고치는 1000명 정도까지 달성 합니다.  **어제 100명 정도 동시접속자가 발생했을 때 지인이 저희 서비스를 이용하면서 이상한 점을 느껴서 알려 주었는데요. 서비스에 로그인하여 접속하고 콘텐츠를 읽다가(로그인 해야만 콘텐츠 접근 가능) 다른 페이지로 넘어갈 때 로그인이 풀려 있는 것입니다. 즉, 자꾸 로그아웃 되는 현상을 발견하였습니다.**  passport 로 사용자 로그인/로그아웃 을 구현하였는데 왜 이런 현상이 발생하는지 원인을 찾아볼 수가 없습니다.  경험 있으시면 분들 의견 주셨으면 좋겠습니다.  감사합니다.'],\n",
       " ['5',\n",
       "  '  DataFrame 관련 질문 드립니다.  에서 간단히 DataFrame의 데이터를 매핑하려고 합니다. 아래와 같이 M과 N DataFrame을 각각 생성하고, ``` import pandas as pd M = {  x : [ a ,  b ,  c ],  y : [ 1 ,  2 ,  3 ] } N = {  i : [ 3 ,  1 ,  2 ] } M = pd.DataFrame(M) N = pd.DataFrame(N) ```  N의 i열의 특정 값과 동일한 값을 M의 y 열에서 찾은 후, 그와 대응하는(그와 같은 행에 있는) 값을 M의 x열에서 찾고 싶습니다. 예를 들어, N[ i ][2]값*( 2 )*와 동일한 값이 M[ y ][1]에 있으므로, 이에 대응하는 x열의 값, 즉 M[ x ][1]값*( b )*를 찾는 것인데, 개별적으로는 아래와 같이 입력하면  b 값을 얻을 수 있었습니다.  ``` M[ x ][N[ i ][2]==M[ y ]]  ``` 그런데, 이것을 일괄적으로 처리하여 N의 j열에 저장하고 싶은데, 아래와 같이 작성하니 j열 값이 [NaN, a, Nan]으로 표시됩니다. 원하는 것은 [c, a, b]로 표시되는 것입니다. ``` N[ j ] =   N[ j ] = N.apply(lambda e: M[ x ][e[ i ] == M[ y ]], axis=1) ```  최종적으로 N의 j열에 아래와 같은 값을 저장하는 것이 목적입니다.  | M | - | - | N | - | |---|---|---|---|---| | x | y | | i | j | | a | 1 | | 3 | c | | b | 2 | | 1 | a | | c | 3 | | 2 | b |  어떻게 수정해야 제대로 동작할지 도움 부탁 드리겠습니다. ']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_temp[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting parameters\n",
    "max_len = 64\n",
    "batch_size = 64\n",
    "warmup_ratio = 0.1\n",
    "num_epochs = 1\n",
    "max_grad_norm = 1\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2,  889, 7170, 7086, 2043, 6812, 5887,  517, 7265, 7170, 5931,\n",
       "        6150, 1460, 7443, 5663, 5782,  517,   54,    3,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1], dtype=int32),\n",
       " array(19, dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=int32),\n",
       " 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(train_temp[0:2000], 1, 0, tok, max_len, True, False)\n",
    "data_test = BERTDataset(train_temp[2000:], 1, 0, tok, max_len, True, False)\n",
    "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2, 4681, 6085, 6139, 6705, 3758, 7533, 5957,  517, 6896, 6037,\n",
       "         703,  703,  703,  517,  398,  439,  423,  517,  380,  440,  157,\n",
       "         517,  405,  423,  432,  430,  442,  637,  389,  367,  452,  405,\n",
       "         398,  447,  343,  427,  446,  432,  517,  398,  439,  423,  517,\n",
       "         450,  420,  420,  405,  380,  517,   54,  517,  437,  433,  446,\n",
       "         396,  517,  405,  423,  432,  430,  442,  517,    3], dtype=int32),\n",
       " array(64, dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       dtype=int32),\n",
       " 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5} {1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "print(set(data_train.labels),set(data_test.labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert transet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n",
    "#data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)\n",
    "#train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
    "#test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5} {1, 2, 3, 4, 5}\n"
     ]
    }
   ],
   "source": [
    "print(set(data_train.labels),set(data_test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_size = 768,\n",
    "                 num_classes=2,\n",
    "                 dr_rate=None,\n",
    "                 params=None):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = bert\n",
    "        self.dr_rate = dr_rate\n",
    "                 \n",
    "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
    "        if dr_rate:\n",
    "            self.dropout = nn.Dropout(p=dr_rate)\n",
    "    \n",
    "    def gen_attention_mask(self, token_ids, valid_length):\n",
    "        attention_mask = torch.zeros_like(token_ids)\n",
    "        for i, v in enumerate(valid_length):\n",
    "            attention_mask[i][:v] = 1\n",
    "        return attention_mask.float()\n",
    "\n",
    "    def forward(self, token_ids, valid_length, segment_ids):\n",
    "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
    "        \n",
    "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
    "        if self.dr_rate:\n",
    "            out = self.dropout(pooler)\n",
    "        return self.classifier(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_total = len(train_dataloader) * num_epochs\n",
    "warmup_step = int(t_total * warmup_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_step, t_total=t_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(X,Y):\n",
    "    max_vals, max_indices = torch.max(X, 1)\n",
    "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24a0592e5a94633a8d2fe26ec5826d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "transform: failed to synchronize: cudaErrorAssert: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: transform: failed to synchronize: cudaErrorAssert: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for e in range(num_epochs):\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    model.train()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        loss = loss_fn(out, label)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        scheduler.step()  # Update learning rate schedule\n",
    "        train_acc += calc_accuracy(out, label)\n",
    "        if batch_id % log_interval == 0:\n",
    "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
    "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
    "    model.eval()\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        out = model(token_ids, valid_length, segment_ids)\n",
    "        test_acc += calc_accuracy(out, label)\n",
    "    #torch.cuda.reset_max_memory_cached()\n",
    "    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#torch.cuda.reset_max_memory_cached()\n",
    "#torch.cuda.reset_max_memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| WARNING: ran out of memory, retrying batch <ipykernel.iostream.OutStream object at 0x7fc97dc7e588>\n"
     ]
    }
   ],
   "source": [
    "print('| WARNING: ran out of memory, retrying batch',sys.stdout)\n",
    "sys.stdout.flush()\n",
    "for p in model.parameters():\n",
    "    if p.grad is not None:\n",
    "        del p.grad  # free some memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "def make_predictions(data_loader):\n",
    "    model.eval()\n",
    "    test_preds = torch.LongTensor()\n",
    "    test_acc = 0.0\n",
    "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
    "            \n",
    "        token_ids = token_ids.long().to(device)\n",
    "        segment_ids = segment_ids.long().to(device)\n",
    "        valid_length= valid_length\n",
    "        label = label.long().to(device)\n",
    "        output = model(token_ids, valid_length, segment_ids)\n",
    "       \n",
    "        test_acc += calc_accuracy(out, label)\n",
    "        preds = output.cpu().data.max(1, keepdim=True)[1]\n",
    "        test_preds = torch.cat((test_preds, preds), dim=0)\n",
    "    torch.cuda.reset_max_memory_cached()\n",
    "    return test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/venv/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3315042eb0ea456d8f6d8b11ed26d67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=782), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 48.00 MiB (GPU 1; 11.91 GiB total capacity; 10.31 GiB already allocated; 53.19 MiB free; 89.93 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-0e4e2dac687f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_set_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-190-8267af6cc3aa>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(data_loader)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvalid_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcalc_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-9e25613a1eab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, valid_length, segment_ids)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask)\u001b[0m\n\u001b[1;32m    625\u001b[0m         encoder_outputs = self.encoder(embedding_output,\n\u001b[1;32m    626\u001b[0m                                        \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                        head_mask=head_mask)\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mlayer_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mattention_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# add attentions if we output them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1372\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 1; 11.91 GiB total capacity; 10.31 GiB already allocated; 53.19 MiB free; 89.93 MiB cached)"
     ]
    }
   ],
   "source": [
    "test_set_preds = make_predictions(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
